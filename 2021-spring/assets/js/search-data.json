{"0": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Table of contents",
    "content": ". | Overview . | Getting help | The most important trick with puppet | . | Part 1: Installing Puppet | Part 2: Using Puppet . | Part a: Making a Home Directory and a User . | Checking Part a | . | Part b: Install java . | Checking Part 2b | . | Part c: Installing the Minecraft Server configuration . | Checking Part c | . | Part d: Installing the Minecraft Server . | Checking Part d | . | Part e: Templating a systemd unit file . | Checking Part e | . | Part f: Running the service . | Checking Part f | . | Part g: Backups . | Checking Part g | . | Part h: (Bonus, optional if you want Minecraft to not Out Of Memory) . | Checking Part h | . | Part i: (Bonus, running Minecraft) | . | Part 3: Cleanup | Part 4: Submission | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#table-of-contents",
    "relUrl": "/labs/11/#table-of-contents"
  },"1": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Overview",
    "content": "NOTE: This lab is completely optional. Completing it before the late lab deadline will count as an additional completed, on-time lab (so please try it out if you weren’t able to finish a previous lab)! . For this lab, we will be installing and configuring a Minecraft server. All of this configuration can be sucessfully done without a Minecraft client or knowledge on how to play the game itself. If you want to actually be able to connect to the server: The student VMs do not have enough RAM to run a Minecraft server, so you’ll need to complete parts h) and i) if you plan on hosting your server on your VM. Alternatively, you are welcome to complete this lab on your own machine if it has at least 8GB of RAM, in which case parts h) and i) may not be necessary. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#overview",
    "relUrl": "/labs/11/#overview"
  },"2": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Getting help",
    "content": "If you want any help with any part of this lab, join the OCF slack (https://ocf.io/slack) or Discord (https://ocf.io/discord)! . The original creator of this lab is Frank Dai (fydai), and there was originally a message here telling you to ping him if you needed any help. You are still welcome to try (or, you can also ping current decal facilitators as well) :) . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#getting-help",
    "relUrl": "/labs/11/#getting-help"
  },"3": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "The most important trick with puppet",
    "content": "If you mess anything up, delete everything (in particular /home/minecraft), and just run puppet again! Puppet ensures that even starting from nothing, you can reconstruct your entire previous state. If you do this and get issues with Puppet executing things out of order than you would like them, add in a require parameter to the resource that should be defined later. For instance, if you want to create something after the /home/minecraft directory, throw in an require =&gt; File['/home/minecraft'] option. In general, capitalize the name of the resource, and put the string before the colon between the square braces. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#the-most-important-trick-with-puppet",
    "relUrl": "/labs/11/#the-most-important-trick-with-puppet"
  },"4": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part 1: Installing Puppet",
    "content": "First, we’re going to install Puppet. Feel free to simply copy the commands below to set up Puppet. Make sure to copy the whole thing! . (This step is not necessary if you already installed Puppet.) . wget https://apt.puppetlabs.com/puppet6-release-bionic.deb &amp;&amp; \\ sudo dpkg -i puppet6-release-bionic.deb &amp;&amp; \\ sudo apt-get update &amp;&amp; \\ sudo apt-get -y install puppet . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-1-installing-puppet",
    "relUrl": "/labs/11/#part-1-installing-puppet"
  },"5": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part 2: Using Puppet",
    "content": "Make a minecraft.pp file anywhere, which through the course of this lab, will eventually configure and run a Minecraft Server. To run your puppet code, use sudo puppet apply minecraft.pp. Puppet, being declarative, will do nothing if the system is already configured properly, so run puppet early and often to detect bugs as soon as possible. Useful references are this section are the Puppet documentation and there is a lot of sample code avaliable in the OCF Puppet configuration. When you are stuck, looking at existing code and see how they did things will generally be helpful. Also remember that there are code examples on the slides! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-2-using-puppet",
    "relUrl": "/labs/11/#part-2-using-puppet"
  },"6": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part a: Making a Home Directory and a User",
    "content": "Put the following code into minecraft.pp: . file { '/home/minecraft': ensure =&gt; 'directory', } . Run sudo puppet apply minecraft.pp to apply it, and ensure that the /home/minecraft directory was created. Inside minecraft.pp, write some Puppet code to create a user named minecraft, that the Minecraft server will run under. The minecraft user should have home directory /home/minecraft. Now modify the code creating /home/minecraft to set owner the owner to minecraft user you just made. Check the example code on the slides if you are unsure about how to do this. Checking Part a . Run sudo puppet apply minecraft.pp. Now run ls -l /home and verify that /home/minecraft is owned by the minecraft user. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-a-making-a-home-directory-and-a-user",
    "relUrl": "/labs/11/#part-a-making-a-home-directory-and-a-user"
  },"7": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part b: Install java",
    "content": "Add a few lines to minecraft.pp to install the default-jre package. Checking Part 2b . Run java and verify that the binary exists. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-b-install-java",
    "relUrl": "/labs/11/#part-b-install-java"
  },"8": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part c: Installing the Minecraft Server configuration",
    "content": "Copy paste the contents of https://raw.githubusercontent.com/0xcf/decal-labs/master/a10/server.properties locally into a file named server.properties . Ensure that /home/minecraft/server.properties contains the contents of the server.properties you just saved. Hint: Use the file function! Also note that in this lab, you should be using absolute file paths. Read and agree to the Minecraft EULA, and ensure that /home/minecraft/eula.txt contains the text eula=true by hardcoding the string eula=true into your minecraft.pp. Make sure that all of the above files are owned by the minecraft user. Checking Part c . Run ls -l /home/minecraft and ensure that the above files exist, contain what they’re supposed to, and they are all owned by the minecraft user, not yours. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-c-installing-the-minecraft-server-configuration",
    "relUrl": "/labs/11/#part-c-installing-the-minecraft-server-configuration"
  },"9": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part d: Installing the Minecraft Server",
    "content": "Ensure that /home/minecraft/server.jar contains the Minecraft Server, available at https://launcher.mojang.com/v1/objects/3dc3d84a581f14691199cf6831b71ed1296a9fdf/server.jar. Note that the source parameter of the file resource accepts a URL as its argument. Also make it owned by the minecraft user. Checking Part d . You know what to do! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-d-installing-the-minecraft-server",
    "relUrl": "/labs/11/#part-d-installing-the-minecraft-server"
  },"10": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part e: Templating a systemd unit file",
    "content": "Copy the following template into the same directory into your minecraft.pp file as minecraft.service.erb. Edit the file to be a proper erb template, so that &lt;INSERT YOUR RAM AMOUNT HERE&gt; becomes the value of the memory_available variable when puppet runs. You want to use the templated variable @memory_available in the .erb file, and declare the variable $memory_available it in the .pp file. Hint: In the slides), there is an example of templating a file. Now edit your minecraft.pp file, so that it sets the $memory_available variable to be the half the total amount of RAM available to the system (use Google and StackOverflow), and that it puts the templated file into /etc/systemd/system/minecraft.service. Hint: You need to figure out how to define variables and set variables in puppet. Note that variables should be prefixed by $. You can assign variables just like any other language. Don’t forget to look at the sample code on the slides (it doesn’t cover variable assignment however) and don’t forget to use absolute paths! . Note that the systemd unit file does not have a proper ExecStop, which maybe result in some world corruption. [Unit] Description=Minecraft Server Wants=network.target After=network.target [Service] User=minecraft WorkingDirectory=/home/minecraft # This should look like ExecStart=/usr/bin/java -Xmx504578 -jar server.jar ExecStart=/usr/bin/java -Xmx&lt;INSERT YOUR RAM AMOUNT HERE&gt; -jar server.jar ExecStop=/bin/kill -- $MAINPID TimeoutStopSec=5 [Install] WantedBy=multi-user.target . Checking Part e . Look at /etc/systemd/system/minecraft.service to ensure it contains the contents you want before proceeding. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-e-templating-a-systemd-unit-file",
    "relUrl": "/labs/11/#part-e-templating-a-systemd-unit-file"
  },"11": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part f: Running the service",
    "content": "Ensure that the minecraft systemd service is enabled and started. Checking Part f . This is the critical moment! If you’ve done everything before correctly, this should work (until Minecraft OOMs)! If the systemd unit fails immediately, try to run the ExecStart command manually, by going into /home/minecraft/ and running sudo -u minecraft java -Xmx1009156 -jar server.jar. You can verify that something is trying to start by running tail -f /home/minecraft/logs/latest.log. If it ever stops loading, the server has run out of memory, and “Part h” below should have a workaround. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-f-running-the-service",
    "relUrl": "/labs/11/#part-f-running-the-service"
  },"12": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part g: Backups",
    "content": "We should backup our minecraft server! . Ensure there is a directory /home/minecraft/backups/, owned by the minecraft user. Ensure there is a script, /home/minecraft/backup.sh that is executable, with the following contents however you’d like. #!/bin/sh cp -r /home/minecraft/world \"/home/minecraft/backups/world-$(date -Is)\" . The command copies the directory containing into the minecraft world into a subdirectory of backups indexed by the current date. Use puppet to add a cron entry to execute /home/minecraft/backup.sh every minute as the minecraft user. Checking Part g . Look in the /home/minecraft/backups contains backups! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-g-backups",
    "relUrl": "/labs/11/#part-g-backups"
  },"13": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part h: (Bonus, optional if you want Minecraft to not Out Of Memory)",
    "content": "We could be doing this by typing this a bunch of commands to add a swap file, and enabling it as swap, but we will do this puppet style! . Configure puppet to create a 4GB file /swapfile with the command dd if=/dev/zero of=/swapfile bs=2M count=2048. Look through the flags to the exec resource to see how you can do this. Now configure Puppet to run mkswap /swapfile &amp;&amp; swapon /swapfile unless swap is currently active, which you can check by seeing if swapon -s | grep /swapfile returns a zero code. There are two arguments that can do this, unless or onlyif. Experiment to see which one works. Checking Part h . Run swapon -s, and check that /swapfile is listed. Ensure that there is no extranous output when you run puppet, if your checks are correctly done, this shouldn’t happen. Check /home/minecraft/logs/latest.log to make sure that the server has start up properly. If it has, then congratulations! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-h-bonus-optional-if-you-want-minecraft-to-not-out-of-memory",
    "relUrl": "/labs/11/#part-h-bonus-optional-if-you-want-minecraft-to-not-out-of-memory"
  },"14": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part i: (Bonus, running Minecraft)",
    "content": "Due to security issues, the Minecraft server running is only listening to 127.0.0.1, which means by default you can only access a Minecraft client running on the VM. You have two ways to get around this. One is changing server-ip in server.properties to 0.0.0.0, which will allow access by anybody. If you do this you probably want to set up a whitelist. The other option is SSH port forwarding. The command, if run on your machine, captures traffic at port 25565 on your local computer, and forwards them to port 25565 on your VM. The command will run forever, just leave it in the background while you try to connect. ssh -NL 25565:localhost:25565 &lt;your VM&gt; . If you chose the first option, you can connect by typing your domain name or IP into minecraft, if you chose the second, you can connect to localhost. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-i-bonus-running-minecraft",
    "relUrl": "/labs/11/#part-i-bonus-running-minecraft"
  },"15": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part 3: Cleanup",
    "content": "There is currently a cronjob copying the minecraft world every minute. That might run you out of disk space. To disable that, you should run sudo crontab -e and remove the line for the backups. Trying to run a Minecraft Server constantly might also eat up some system resources. You can stop and disable the minecraft systmemd unit manually if it is causing issues. If you added the swapfile, you might want to remove that. Another way you can clean up is with puppet. By default, puppet doesn’t remove files it doesn’t know about. However, you can use ensure =&gt; absent to make sure files are gone, and similarly for the other resource types. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-3-cleanup",
    "relUrl": "/labs/11/#part-3-cleanup"
  },"16": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Part 4: Submission",
    "content": "Congratulations on finishing the lab! . To submit, copy paste the code you have for each section into the gradescope submission. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/#part-4-submission",
    "relUrl": "/labs/11/#part-4-submission"
  },"17": {
    "doc": "Lab 11 - Bonus Lab!",
    "title": "Lab 11 - Bonus Lab!",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/11/",
    "relUrl": "/labs/11/"
  },"18": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Table of contents",
    "content": ". | A Note on Labs . | Workflow | . | Question 1 | Question 2 | Question 3 | Question 4 (Extra) | Submission | Footnotes | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#table-of-contents",
    "relUrl": "/labs/a1/#table-of-contents"
  },"19": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "A Note on Labs",
    "content": "Labs are graded on completion. As long as you give your best effort and submit an answer to each question, you will receive full credit. Treat them as seeds of exploration instead of just a grade. As this is the first lab, we have done our best to make it relatively straightforward. (If something seems overly difficult, there is probably a simpler way to do it!) Bash scripting isn’t the main goal of the DeCal but this lab should introduce you to some fun bash features you may not have encountered before, such as loops and shell expansions, that you’ll probably find useful in the future. If you ever find yourself confused, stuck, and/or curious to learn more, talk to us about it! The best way to connect with us (and your peers) is through our Slack channel. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#a-note-on-labs",
    "relUrl": "/labs/a1/#a-note-on-labs"
  },"20": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Workflow",
    "content": "This lab can be done on your own UNIX-like machine, or you can ssh into tsunami.ocf.berkeley.edu using your OCF account to finish the lab there. As always, man and Google will be your friends. If you’d like to test your scripts for correctness, feel free to run the provided examples or make some of your own! Since labs are graded on completion, there are no autograder tests or anything of the sort to worry about (which will also be true for the following labs). We will release sample solutions after the lab is due, but keep in mind that there are many ways to solve these problems. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#workflow",
    "relUrl": "/labs/a1/#workflow"
  },"21": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Question 1",
    "content": "At some point, everyone has looked at a problem and thought to themselves: “Hey, I can do this in one line!” . Lets find out if you can. I need to sort out some of my most listened to albums by making directories for each of them, specifically for my favorite artist Future. I have hosted a list of my favorite albums followed by their respective artist at https://raw.githubusercontent.com/0xcf/decal-labs/master/a1/albums.txt, in a comma delimited format like Die Lit, Playboi Carti. For the GOAT artist Future, I want to create a folder for each of his albums. For example, for an entry like SUPER SLIMEY, Future I would expect a directory called SUPER SLIMEY to be created. TLDR: You need to fetch the list from the web, filter out the albums we want, trim out the album name, and then make a directory for each one, all in one line. $ cat albums.txt ... Drip or Drown 2, Gunna Playboi Carti, Playboi Carti DS2 (Deluxe), Future &lt;-- GOAT album detected! Drip Harder, Lil Baby The WIZRD, Future &lt;-- GOAT album detected! What a Time To Be Alive, Drake ... # After our magic one liner... $ ls 'DS2 (Deluxe)' 'The WIZRD' ... # We got our new directories! . Hints: . | What common text manipulation commands can help you solve this? | As always, be aware that there isn’t one unique solution to this problem! | Also be aware that xargs behaves differently on different platforms. | . Submit your one line solution on Gradescope! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#question-1",
    "relUrl": "/labs/a1/#question-1"
  },"22": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Question 2",
    "content": "I like Lisp and Scheme, and miss car and cdr in my usual programming tasks.1 . In bash, implement car and cdr (aka head and tail) such that they operate on file paths. e.g. $ ./car /home/a/ab/abizer/some/path home $ ./cdr /home/a/ab/abizer/some/path a/ab/abizer/some/path . You may assume that only absolute paths2 will be given. Hint: There’s no need to use complicated string manipulations such as regex’s for this task. The easiest way to do this is with one very short command. As an optional bonus challenge: generalize this solution to work for cadr, caddr, etc. $ ./cadr /home/a/ab/abizer/some/path a $ ./cddr /home/a/ab/abizer/some/path ab/abizer/some/path . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#question-2",
    "relUrl": "/labs/a1/#question-2"
  },"23": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Question 3",
    "content": "With the invention of the .norm file format, file extension innovation is at its peak!3 . However, your computer is old and doesn’t support it, so we’ll need to convert all of the files ending in .norm into .docx files. Using Bash functions and shell wildcard expansion, write a shell script rename.sh to batch rename file extensions in a particular directory. Here is some more specific info about this function: . | It should take in 3 arguments: the directory, the original extension, and the new extension. | It should print the line renaming &lt;old file&gt; to &lt;new file&gt; for each renamed file. | It should not modify any files in the directory that do not have the specified extension. | . Example: . $ ls Documents/ cats.norm data.norm dogs.norm ... $ ./rename Documents norm docx # Run your script! renaming Documents/data.norm to Documents/data.docx renaming Documents/cats.norm to Documents/cats.docx renaming Documents/dogs.norm to Documents/dogs.docx ... $ ls Documents/ cats.docx data.docx dogs.docx ... Your script should be able to convert between any arbitrary file formats, not just .norm and .docx! For example: . $ ls # Creates a new directory tmp and adds 26 new files a.dat, b.dat ... to z.dat into it $ mkdir tmp &amp;&amp; touch tmp/{a..z}.dat $ ./rename.sh tmp dat txt renaming tmp/a.dat to tmp/a.txt ... # 24 more lines renaming tmp/z.dat to tmp/z.txt $ ls -lAh tmp | grep .txt | wc -l # Gets the number of lines in ls which contain .txt 26 . for bonus points, instead of using something like sed to affect the rename, use shell parameter expansion. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#question-3",
    "relUrl": "/labs/a1/#question-3"
  },"24": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Question 4 (Extra)",
    "content": "This question is optional but it’s quite fun and you should do it if you have the time! . Using Bash functions, write a script mkrandom.sh that generates a user-specified number of files of user-specified size filled with random content. e.g. $ ./mkrandom.sh 10 100 # create 10 100 byte random files $ ls -lAh total 44K -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 1 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 10 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 2 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 3 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 4 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 5 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 6 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 7 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 8 -rw-r--r-- 1 abizer ocf 100 Sep 16 21:57 9 -rwxr-xr-x 1 abizer ocf 147 Sep 16 21:56 mkrandom . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#question-4-extra",
    "relUrl": "/labs/a1/#question-4-extra"
  },"25": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Submission",
    "content": "Submit your solutions on Gradescope! There’ll be some extra feedback questions as well that we would appreciate you filling out. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#submission",
    "relUrl": "/labs/a1/#submission"
  },"26": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Footnotes",
    "content": "You may want to look into dd4 and the iflag=fullblock argument, seq, and /dev/random5. | Aren’t too familiar with car and cdr? Here’s a brief article about it.. If you take CS61A, you’ll see it there as well! &#8617; . | As a quick reminder, absolute paths always start from the root directory (/), whereas relative paths start from the current directory. &#8617; . | Relevant xkcd: https://xkcd.com/2116/ &#8617; . | dd is a command used to copy files.6 It’s most commonly used to clone data from one device to another, such as when you want to generate a bootable Linux USB drive. &#8617; . | A curious individual might find the device file /dev/urandom as well. What’s the difference? True randomness is a rather difficult problem for computers, as they’re expected to do the same thing given the same state, so they pull in random data from metrics like internal temperature and mouse movement. Unfortunately, such entropy may not exist in certain machines and gathering entropy may be prohibitively long. Thus, /dev/urandom, or “unlimited random”, is a useful source when such randomness is not cryptographically critical. &#8617; . | “But wait,” a nearby straw-man asks, “isn’t that what cp does?”7 &#8617; . | They are indeed right, but dd has some useful features such as partial writing and reading that make it handy in weirder scenarios, such as devices. StackOverflow has a good explainer and the ArchWiki has some common examples. &#8617; . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/#footnotes",
    "relUrl": "/labs/a1/#footnotes"
  },"27": {
    "doc": "Lab a1 - Shell Scripting",
    "title": "Lab a1 - Shell Scripting",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a1/",
    "relUrl": "/labs/a1/"
  },"28": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Table of contents",
    "content": ". | Intro to Docker . | Installing Docker | Creating your first Docker container | Running an interactive container | Questions (answer on Gradescope) | . | Basic Management . | Dockerfiles . | Questions | . | Detached Containers and Ports | . | Dungeons and docker-compose . | About docker-compose . | Installing | The web application | . | Putting it all together | Questions | . | Submission | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#table-of-contents",
    "relUrl": "/labs/a10/#table-of-contents"
  },"29": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Intro to Docker",
    "content": "This exercise is designed to give you some hands-on experience with Docker! By the end of this assignment, you should be able to: . | Create and use a Docker container interactively | Create a Dockerfile, which allows you to declaratively define your containers | Run detached containers and understand port forwarding | Use docker-compose to run a multi-container web application | . Just a forewarning: this lab holds your hand until the last section. Not that the last part is super hard, but it’ll have a lot less instruction than previous portions which are designed to gently introduce you to Docker. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#intro-to-docker",
    "relUrl": "/labs/a10/#intro-to-docker"
  },"30": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Installing Docker",
    "content": "Install Docker from the Ubuntu repositories using sudo apt install docker docker.io. After installing, check on the status of the docker systemctl service by running sudo systemctl status docker. If the service is inactivate and/or disabled, run systemctl enable and systemctl start to start it up. I recommend running the command sudo usermod -aG docker $USER so you can use Docker as a non-root user. This means you won’t have to type sudo docker all the time. This is optional but for the rest of this exercise I’m going to assume that you did this. If you see some output like . sent invalidate(passwd) request, exiting sent invalidate(group) request, exiting . This is normal, it’s just adding a user to a group. You’ll have to log out and then log back into your SSH session for the group change to take effect. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#installing-docker",
    "relUrl": "/labs/a10/#installing-docker"
  },"31": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Creating your first Docker container",
    "content": "To verify that you installed things correctly, try running . docker run hello-world . You should see some friendly output like so (hashes are probably different, don’t worry about it): . Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world b04784fba78d: Already exists Digest: sha256:f3b3b28a45160805bb16542c9531888519430e9e6d6ffc09d72261b0d26ff74f Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/ For more examples and ideas, visit: https://docs.docker.com/engine/userguide/ . If you’re running into an out-of-memory error, the vagrant VM from a6 is probably still running. Try to cd into the directory where you started the VM, and run vagrant halt to stop it. Some quick definitions from Docker’s website: . An image is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files. Images are useful primarily for their speed, but images can also be used as a base to be built on top of in future images, as you’ll see later with Dockerfiles. In the last example hello-world was the image used to test our docker installation. A container is a runtime instance of an image—what the image becomes in memory when actually executed. It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so. A container gets created upon executing docker run on an image. This is similar to the distinction between objects and classes in Object Oriented Programming. Images would be classes, and containers would be objects. Be sure to read through the output from running the hello-world image to get an understanding of what the Docker daemon was doing. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#creating-your-first-docker-container",
    "relUrl": "/labs/a10/#creating-your-first-docker-container"
  },"32": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Running an interactive container",
    "content": "We’re now going to walk you through running a container interactively. This is useful if you ever need to play around and install stuff on a bare system without messing up your current system. Try running the following command: . docker run -it ubuntu:xenial /bin/bash . The -i flag tells docker to keep STDIN open to your container, and the -t flag allocates a pseudo-TTY for you. Basically you need both for you to have a way to enter text and have this display properly. At the end of the command, /bin/bash is just the command you want to run once the container starts up. Try installing some packages from apt or just play around. It should look like a bare Linux system. You can exit the container with CTRL+D. Notice how even though your VM is running the Bionic version of Ubuntu, you were able to run the Xenial version of Ubuntu in a container. If you are curious about other variants of Linux, you can run a lot of them inside containers as well! This all works because Linux distributions all share the Linux kernel. For that same reason, you won’t be able to run MacOS or Windows in a container. You can try running Fedora (*tips hat* M’Linux), another long-running Linux distribution: . docker run -it fedora:latest /bin/bash . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#running-an-interactive-container",
    "relUrl": "/labs/a10/#running-an-interactive-container"
  },"33": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Questions (answer on Gradescope)",
    "content": ". | What user are you logged in as by default? | If you start and then exit an interactive container, and then use the docker run -it ubuntu:xenial /bin/bash command again, is it the same container? How can you tell? | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#questions-answer-on-gradescope",
    "relUrl": "/labs/a10/#questions-answer-on-gradescope"
  },"34": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Basic Management",
    "content": "The Docker CLI (Command Line Interface) has some basic commands for you to monitor running and stopped containers, downloaded images, and other information. We’ll go over the basic commands you’ll probably use, but be sure to check out the full reference if you’re interested. Firstly, you might want to see the running containers on a system. Use the following command: . docker ps . Since you (likely) have no containers running, you probably won’t see anything interesting. However, if you pass in the -a flag, you’ll also be able to see containers that have stopped (make your terminal wider or it’ll display weird): . baisang@rapture ~/d/labs&gt; docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 35c048c03588 fedora:latest \"/bin/bash\" 7 minutes ago Exited (130) About a minute ago mystifying_edison dd8f7cc2e0cd fedora:latest \"/bin/bash\" 10 minutes ago Exited (1) 8 minutes ago romantic_mahavira . This lets you see a lot of useful information about the container. Observe that each container has a unique container id and a unique human-readable name. To get more information about a container, you can use the docker logs command to fetch the logs of a container (whether it’s still running or exited): . docker logs &lt;container_id_or_name&gt; . This basically just gives you stdout and stderr for process(es) running in the container. At some point, you may want to cleanup containers that have exited and you don’t plan on using anymore: . docker rm &lt;container_id_or_name&gt; . will remove the container. You may have noticed when you were running the Ubuntu or Fedora containers the first time that Docker downloaded a good chunk of data before running the image. This is the image of the container. You can view all of the images you’ve downloaded with the docker images command: . baisang@rapture ~/d/labs&gt; docker images REPOSITORY TAG IMAGE ID CREATED SIZE fedora latest 9110ae7f579f 2 weeks ago 235MB ubuntu xenial f975c5035748 3 weeks ago 112MB . Images can take up quite a bit of space on your machine, so you may want to clean up images that you don’t plan on using. This is especially relevant if you get errors about not having enough disk space on your machine: . docker rmi &lt;image_id&gt; . The image files, as well as various filesystems of containers, are stored in /var/lib/docker. We’ll go over more commands later on in the lab. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#basic-management",
    "relUrl": "/labs/a10/#basic-management"
  },"35": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Dockerfiles",
    "content": "A more powerful way to interface with Docker is by using a Dockerfile. A Dockerfile allows you to define an image by specifying all of the commands you would type manually to create an image. Docker can then build images from a specified Dockerfile. These Dockerfiles can be put into version control and the images distributed as a binary to keep track of both how the image is constructed and also to keep pre-built images around. Dockerfiles are very powerful and have many different commands and features. We’ll go over a basic example, but you should check out the reference page if you are trying to do anything more complex. Here is an example Dockerfile that will build an image that has python3.6 installed. It will also run python3.6 directly, so you’ll be at a python prompt instead of a bash prompt when you run it. FROM ubuntu:bionic RUN apt-get update &amp;&amp; apt-get install -y python3.6 --no-install-recommends CMD [\"/usr/bin/python3.6\", \"-i\"] . Note: there are some “best practices” for writing Dockerfiles that the above example doesn’t use, because it’s a basic example. For instance, we probably would want to delete /var/lib/apt/lists/*, where apt stores the package list information from apt update, after we are done installing packages. We may also choose to use Linux variants that are smaller and lighter, e.g. Alpine Linux. The general philosophy is containers should be kept as small and “light” as possible. If you’re interested in this stuff, check out this article. What is this doing? We specify a base image ubuntu:bionic (release 18.04 of ubuntu). We then specify that we should run (RUN) the command apt-get update and then apt-get install python3.6 so we can install python3.6. Then we set the default command (CMD) of the container to run the python3.6 interpreter in interactive mode. Copy the contents of the Dockerfile above into a file named Dockerfile. Then use Docker to build it with the following command: . docker build -t mypython:latest . This tells Docker to look in the current directory for a Dockerfile to build, and build it. The -t flag tells it to tag this build with the name mypython:latest. Docker will look for a Dockerfile in the current directory since you specified . Remember, you can see all of the images you’ve built on your machine with the docker images command. Questions . | Run the image you just built. Since we specified the default CMD, you can just do docker run -it mypython:latest. What do you observe? | Write and build a Dockerfile that installs the packages fortune and fortunes-min and runs the fortune executable (located in /usr/games/fortune after you install it). Note that you won’t need to use the -it flags when you run the container as fortune doesn’t need STDIN. Submit your Dockerfile with this lab. Hint: if you’re having trouble writing your Dockerfile, try booting an interactive container and installing both packages. How can you translate what you did interactively to a Dockerfile? | Paste the output of your docker images command after questions 1 and 2. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#dockerfiles",
    "relUrl": "/labs/a10/#dockerfiles"
  },"36": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Detached Containers and Ports",
    "content": "You might not always want containers to be running interactively. For instance, if you are running a web server, you’ll likely want the container to continue keep running until you explicitly want to end it. Docker supports this use case with the -d flag, which starts containers in detached mode. We’ll explore a bit about detached containers by running a standalone Apache container. The image has already been built for you; you can find it on Docker Hub as httpd. Docker creates a separate virtual network for containers, so you will need to do forward your host port to your container’s port (this is called port forwarding, or port mapping). The container is listening on port 80, so let’s try to forward our host machine’s port 5050 to the container’s port 80 when we run the container: . docker run -d -p=5050:80 httpd . The -p flag takes in a colon separated pair of HOST_PORT:CONTAINER_PORT (it can actually accept a ton of more options, but don’t worry about that for now). You should be able to view visit &lt;url_of_host_machine&gt;:5050, assuming you don’t have anything else running on that port (if you’re not on campus, you can just curl &lt;url_of_host_machine&gt;:5050 from your VM or another machine on campus, e.g. ssh.ocf.berkeley.edu), and see the words “It works!”. You may need to allow the port 5050 on your firewall, simply run the command ufw allow 5050 . You can actually “attach” to running containers and run more commands in them, similar to how docker run works. Use the docker exec command: . docker exec &lt;container_id_or_name&gt; &lt;command&gt; . To stop this container, use docker stop &lt;container_id_or_name&gt;. You can restart the container using docker restart &lt;container_id_or_name&gt;. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#detached-containers-and-ports",
    "relUrl": "/labs/a10/#detached-containers-and-ports"
  },"37": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Dungeons and docker-compose",
    "content": "Congratulations! You’ve just been hired by some trash SF Bay Area tech bubble startup as their systems administrator. Unfortunately, both the CEO and CTO are busy handling the business side, which leaves it up to you to get their web application deployed using Docker and docker-compose. Don’t worry though – while you may not have health insurance or a nice salary, you do have some of the CTO’s notes and equity to help you with your task. You get off BART at 12pm and enter your cramped SOMA coworking space, sitting down at the desk you share with the CTO while cracking open a cold LaCroix. Checking your email, you find the following notes from the CTO: . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#dungeons-and-docker-compose",
    "relUrl": "/labs/a10/#dungeons-and-docker-compose"
  },"38": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "About docker-compose",
    "content": "docker-compose lets you define applications that require more than one container to function. For example, on a web application you may want your actual web application running inside of a single container, and your database running in a different container. Typically you define applications in terms of services. Again, going with the web application example, there are two distinct services: the app itself, and the database backing it. docker-compose lets you define different services within a YAML file and run the services accordingly. One of the nice things about docker-compose is that it automatically sets up a network for your containers in which: . | each container for a service is on the network and reachable from other containers on the network | each container is discoverable on the network via its container name | . This means it should be pretty simple to get our web app to connect to the database. Installing . docker-compose is really just a python package, so ideally we should just install it with virtualenv and pip (as with most things, the version packaged in Ubuntu is too old, so we can’t just apt install it). Feel free to do it this way if you want, but since we’re a hotshot tech startup we’re gonna do this the cowboy way (yeehaw): . sudo curl -L https://github.com/docker/compose/releases/download/1.27.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose . The web application . The web application is written only the most badass rockstar tech, Node.js. For the database, it uses the most webscale, reliable, and persistent database available on the market today, MongoDB. The web application can be found on GitHub. Note that the web app listens on port 8080, so you’ll need to forward or expose that port. Don’t forget to allow it on your firewall, ufw allow 8080. Instructions for setting it up are located in the README.md of the repository: https://github.com/0xcf/decal-sp18-a10 . For MongoDB, you can just use the image on DockerHub (a website where people can upload built Docker images). It’s just called mongo. For example, if you wanted to run MongoDB within a container in detached mode: . docker run -d mongo:latest . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#about-docker-compose",
    "relUrl": "/labs/a10/#about-docker-compose"
  },"39": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Putting it all together",
    "content": "Your task is to use docker-compose to deploy the Node.js app with the MongoDB database. The CTO has roughly mapped out a suggested order of tasks: . | Write a Dockerfile that will allow you to run the Node.js web application | Write a docker-compose.yml file that will glue the Node.js app container with a MongoDB container | . Here is a basic skeleton for docker-compose.yml. You will need to fill out the web and database service entries: . version: '3' services: web: database: . By default, the Node.js web application is designed to look for a MongoDB instance at hostname database, so be sure that your MongoDB service is defined under that name. docker-compose will make sure that the hostname database maps to the container for that service. One huge caveat: your hotshot CTO unfortunately wrote the Node.js app in a crap way where if it’s not able to connect to the MongoDB database once it starts, it’ll fail and exit without retrying. Since Javascript is poison, you’ll need to find a way to make sure that the Node.js app only starts after the MongoDB container is ready to accept incoming connections without modifying server.js. I included a wrapper script wait-for in the repo for the Node.js app that will allow you to wait for the MongoDB service to be ready before launching the Node.js app. But, in order to use the script, you will need to have netcat installed in your container, so be sure to include that in your Dockerfile. See the repo for the script for instructions on how to use the script. Feel free to come up with other ways to solve this issue though! . You will likely find the Compose File Reference useful. Additionally, the Getting Started guide will help as well, although it’s a python example instead of the superior Node.js /s I suggest poking around at other docs on that site also. I expect you to run into errors and difficulties – this is intended as part of the lab. Feel free to ask in #decal-general if you ever feel especially stuck! . Hints (if you want them): . | For the Node.js Dockerfile, I recommend basing it off of ubuntu:xenial and installing everything you need (nodejs, npm, etc.) via apt. These aren’t in Debian’s apt repository so you’d have to find another way to install them if you use Debian. | npm install needs to be run within the directory containing the repository (i.e. needs to be run within the directory that has the package.json file). If you want to change the current working directory within your Dockerfile, use the WORKDIR command | If you change your Dockerfile after running docker-compose up, you will need to run docker-compose build to rebuild your services | . Once you’ve set things up properly, just running docker-compose up in the same directory as the docker-compose.yml file will bring up your web application! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#putting-it-all-together",
    "relUrl": "/labs/a10/#putting-it-all-together"
  },"40": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Questions",
    "content": ". | Paste your Dockerfile for the Node.js web application | Paste your docker-compose.yml file | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#questions-1",
    "relUrl": "/labs/a10/#questions-1"
  },"41": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Submission",
    "content": "Don’t forget to submit to Gradescope! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/#submission",
    "relUrl": "/labs/a10/#submission"
  },"42": {
    "doc": "Lab 10 - Containerization and Docker",
    "title": "Lab 10 - Containerization and Docker",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a10/",
    "relUrl": "/labs/a10/"
  },"43": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "Table of contents",
    "content": ". | About This Lab . | Grading note | Workflow | . | Debian: An introduction to apt and dpkg . | apt | dpkg | . | Getting Started | Exercise 1: Compiling and Packaging . | Writing and Compiling the Program | Packaging the executable | . | Exercise 2: Troubleshooting | Exercise 3: Spelunking | For Hotshots | Resources | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#table-of-contents",
    "relUrl": "/labs/a2/#table-of-contents"
  },"44": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "About This Lab",
    "content": "Grading note . Labs are graded on completion. Treat this lab as seeds of exploration instead of just a grade. Workflow . This lab should be completed on your student VM. You should have received an email with instructions and credentials for connecting your VM. Before starting the lab, ssh into your student VM. Please email us at decal@ocf.berkeley.edu if you are having issues logging in. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#about-this-lab",
    "relUrl": "/labs/a2/#about-this-lab"
  },"45": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "Debian: An introduction to apt and dpkg",
    "content": "In this class, we will be focused on using Debian. As noted within this week’s lecture, Debian uses apt/dpkg as its package manager. Other distributions use different package managers. apt . The frontend package manager for Debian is apt. For the majority of times when you need to deal with a package manager, apt is usually the way to go. Before doing anything with apt, it is typically a good habit to update the package list so that the package manager can find and fetch the most updated versions of various packages. To do that, you can run: . apt update . To find a package to install: . apt search [package|description] . To install a package: . apt install [package] . To remove a package: . apt remove [package] . Once you have been using the packages that you installed for a while, you may notice that they don’t automatically update themselves, a feature that may be present on programs written for other operating systems. To update the packages that you have installed, run: . apt upgrade or sometimes apt dist-upgrade . It is more commonplace to use apt upgrade to update your packages, but there are times when you need to use apt dist-upgrade. You can read up more about the differences between the two here. In some circumstances, you want to be absolutely sure of the version of the package that you want to install. To list the potential versions that you can install, you can run: . apt policy [package] . This lists the candidate version to install, according to its pin priority, along with other versions that are compatible with the system. To install a a version for a specific target release, you can run: . apt -t [targetrelease] install [package] . There are also other commands that can remove unneeded dependencies and purge packages, but that is what the man pages are for. Please note that you are going to have to use sudo for the above commands since you are actually modifying the system itself. dpkg . The backend package manager is dpkg. Traditionally, dpkg is used to install local packages. Using dpkg, you also can inspect packages and fix broken installs. To install local packages, run: . dpkg -i [packagefilename] . To remove a system package: . dpkg --remove [package] . To inspect a package for more information about the package: . dpkg -I [packagefilename] . To fix/configure all unpacked but unfinished installs: . dpkg --configure -a . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#debian-an-introduction-to-apt-and-dpkg",
    "relUrl": "/labs/a2/#debian-an-introduction-to-apt-and-dpkg"
  },"46": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "Getting Started",
    "content": "We are going to use gcc to compile source code and a simple utility called fpm to create packages in this lab. Using the commands above, install gcc, make, ruby-dev, and ruby-ffi. Now check if GCC is installed by typing the followng: . gcc --version . Now install fpm using gem, Ruby’s own package manager: . sudo gem install fpm . Now check if fpm is installed: . fpm . Now clone the decal-web repository: . git clone https://github.com/0xcf/decal-labs.git . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#getting-started",
    "relUrl": "/labs/a2/#getting-started"
  },"47": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "Exercise 1: Compiling and Packaging",
    "content": "Packaging manually for Debian can be very hard and frustrating, especially for first timers. That’s why for this class, we’ll be using a really cool Ruby package called fpm which simplifies the task of packaging a lot. Note: This method is a great way to backport or package your own applications extremely quickly, but is not up to the more formal standards set by the Debian New Maintainers’ Guide. If you’re up for a challenge, feel free to try following the lab instructions, but using the guidelines here for dpkg-buildpackage instead of using fpm. Now we will create a simplistic package using the hellopenguin executable that you will make in the coming steps. First, move into the a2 folder in the repository that you cloned in the Getting Started section: . cd decal-labs/a2 . Now we are going to create a folder to work in for this exercise: . mkdir ex1 . And now move into the folder: . cd ex1 . Writing and Compiling the Program . Now, we will make a very simple application in C that prints “Hello Penguin!” named hellopenguin. Invoke: . touch hellopenguin.c . This will create an empty file named hellopenguin.c. Now, using the a preferred text editor of your choice, such as vim, emacs, or nano, insert the following code into hellopenguin.c . #include &lt;stdio.h&gt; int main() { printf(\"Hello Penguin!\\n\"); return 0; } . We will now compile the source file that you have just written: . gcc hellopenguin.c -o hellopenguin . What this does is to take in a source file hellopenguin.c and compile it to an executable named hellopenguin with the -o output flag. Packaging the executable . Now, we will create the folder structure of where the executable shall reside in. In Debian, user-level packages usually reside in the folder /usr/bin/: . mkdir -p packpenguin/usr/bin . Now move your compiled hellopenguin exectuable into the packpenguin/usr/bin/ folder. mv hellopenguin packpenguin/usr/bin/ . Now we will create a package called hellopenguin. Move into the parent directory of the hellopenguin folder and invoke the following: . fpm -s dir -t deb -n hellopenguin -v 1.0~ocf1 -C packpenguin . This specifies that you want to take in a directory, using the -s flag, and to output a .deb package using the -t flag. It takes in a directory called packpenguin, using the -C flag, and output a .deb file named hellopenguin, using the -n, with a version number of 1.0~ocf1, using the -v flag. Now test it by invoking apt and installing it: . sudo dpkg -i ./hellopenguin_1.0~ocf1_amd64.deb . Now you should be able to run hellopenguin by doing the following: . hellopenguin . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#exercise-1-compiling-and-packaging",
    "relUrl": "/labs/a2/#exercise-1-compiling-and-packaging"
  },"48": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "Exercise 2: Troubleshooting",
    "content": "Now we are going to try and troubleshoot a package. Move to the other folder, ex2. Try installing the ocfspy package using dpkg. It should error. Take note what it is erroring on! Now try and fix it. Hint: Inspect the package for more details. The file to create that application is in the folder. Try compiling and packaging it. Exercise 1 may be a useful reference if you are stuck. After you’re done, complete the following questions and made a submission to Gradescope. Compiling and packaging . | Will we still be able to run “hellopenguin” from any directory if we packaged it into “/usr/share” instead of “/usr/bin”? | What is your rationale for the previous answer? | . Debugging . | What package was missing after trying to install ocfspy? | What is the password that ocfspy outputs after fixing the dependency problem? | . Note that you may want to clean up your VM by removing hellopenguin, ocfdocs, and ocfspy from your system. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#exercise-2-troubleshooting",
    "relUrl": "/labs/a2/#exercise-2-troubleshooting"
  },"49": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "Exercise 3: Spelunking",
    "content": "Let’s shift gears a bit and take a look at a popular package to learn more about how it’s structured! If you recall from lecture, we took at look at the contents of htop. For this next section, choose another package from the Debian repository to download and extract. Here’s a list: try to pick one you have used/installed before! . Note that this exercise is mainly for exploration and learning purposes- you wouldn’t actually install a package using this method. Once you’ve extracted the files, answer the following questions on Gradescope: . | What package did you choose? | What are the package’s dependencies? What file can you find them in? | Extract data.tar.gz and view its contents. If there exists a folder(s) other than usr/bin/ and usr/share/, pick one and briefly describe its purpose (both generally and in the context of this package). If not, explain why additional folders are not needed for this package. | What’s one other interesting thing you learned about this package? (Binaries you never knew existed, easter eggs in documentation, a cool pre-install script…) | . Hints: . | The command to download a package is apt download &lt;packagename&gt;. | To use aunpack, you might need to sudo apt install atool. | Try to choose a package with a smaller filesize, so you won’t have to wait long for it to download and extract. | The lecture demo will be quite helpful! You may want to watch it again for reference. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#exercise-3-spelunking",
    "relUrl": "/labs/a2/#exercise-3-spelunking"
  },"50": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "For Hotshots",
    "content": "In the past examples, we have always precompiled a given program before packaging it. One upside to this, is that the package will always work for systems similar to the one that you run. However, once we start introducing other machines with potentially different architectures, we suddenly need to create duplicate packages compiled specifically for those systems. Create a new package that unpacks the source code for a file, compiles it, moves all of the relevant files to their respective locations, before deleting the irrelevant files. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#for-hotshots",
    "relUrl": "/labs/a2/#for-hotshots"
  },"51": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "Resources",
    "content": "Below are some resources that I found helpful in the creation of this lab. If you are feeling adventurous, you may want to poke around these documents as well. fpm . TLDR pages, a more readable man page . dpkg, alternatively man dpkg . apt, alternatively man apt . Debian New Maintainers’ Guide . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/#resources",
    "relUrl": "/labs/a2/#resources"
  },"52": {
    "doc": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "title": "Advanced Lab 2 - Packages and Packaging and Troubleshooting",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a2/",
    "relUrl": "/labs/a2/"
  },"53": {
    "doc": "Advanced Lab 3 - Pre-install Setup and Installation",
    "title": "Table of contents",
    "content": ". | A preliminary message (read this section carefully!) | Setup . | Acquire installation media | Create VM | . | Partitioning time . | Create partitions | Create filesystems . | ESP | Root partition . | Wiping | Setting up the encrypted device | Creating the actual filesystem | . | Swap | . | Mount the new filesystems | . | Installation . | Mirrors | Continue according to ArchWiki! | initramfs | Root password | Boot loader | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a3/#table-of-contents",
    "relUrl": "/labs/a3/#table-of-contents"
  },"54": {
    "doc": "Advanced Lab 3 - Pre-install Setup and Installation",
    "title": "A preliminary message (read this section carefully!)",
    "content": "In this lab we will be installing Arch Linux into a virtual machine. In this lab you will need to pay close attention to detail: mistakes may not be apparent for quite a while later, and can cause huge headaches. As always, make sure to take advantage of #decal-general and other resources if you need help! Also, in this lab, the ArchWiki will be an invaluable resource that we will be referencing a lot. Throughout the lab, additional notes will be formatted like this. These notes are the only sections of the lab that you can safely skip. They will provide additional interesting information and context, so I recommend reading them anyway! . As always, you will need to submit this lab on Gradescope. Any time you see “GRADESCOPE:” in this lab, stop and make sure that you have submitted the relevant answer or output to Gradescope. In most cases, it will be hard or impossible to go back and get the answer later in the lab. If you realize you forgot to submit something, do not worry! Simply explain what you did / what command you ran rather than restarting. We chose to install Arch Linux in this lab for a few reasons. First, Arch Linux gives you tools to handle monotonous tasks (like genfstab, which does the dirty work of writing out /etc/fstab) while leaving the more complicated and more customizable tasks to you. Second, Arch is widely used and experience with Arch can usually be applied to other distributions as well. Third, ArchWiki. Seriously. It’s that good. Make sure you allocate about 2 hours for this lab (don’t do it last minute!) Trying to rush the process may result in skipping over key details and could require you to restart. That being said though, it ideally shouldn’t take much longer than that. If you’ve had to restart multiple times or have otherwise tried for a long time with no success, contact staff. We don’t want you to get stuck for 6 hours etc. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a3/#a-preliminary-message-read-this-section-carefully",
    "relUrl": "/labs/a3/#a-preliminary-message-read-this-section-carefully"
  },"55": {
    "doc": "Advanced Lab 3 - Pre-install Setup and Installation",
    "title": "Setup",
    "content": "We will be setting up virtual machine inside your student VM. Yes, this is a “nested” virtual machine. First, connect to your student VM using the credentials that were emailed to you. If you haven’t yet, you will need to reset your password when you first log in. Please use a safe password and don’t lose it! . If you’re enrolled in this DeCal, you should have a student VM. If you’re not, we can’t guarantee that these techniques will work on other systems (for a variety of reasons). However, you can obtain a system that’s very similar to a student VM by creating a Droplet on DigitalOcean. Normally this Droplet would cost some amount of money, but you can get free DigitalOcean credits by using the GitHub Student Developer Pack. You can follow the instructions on the DigitalOcean website to create the Droplet. When selecting an image, choose Ubuntu 18.04. PLEASE READ: Before you begin, please upgrade packages/reboot Ubuntu on your Digital Ocean droplet if prompted to do so by the motd (Message of the Day; the text you see when you ssh into your DO droplet), but do not upgrade to Ubuntu 20.04 (do not run the command do-release-upgrade). In other words, before starting the lab, run sudo apt update, then sudo apt upgrade, and finally sudo reboot. You will lose connection when your DO droplet reboots, then ssh back in and begin the lab. Now that you are connected to your student VM, we will need to install some packages that will allow us to create our nested Arch Linux VM. Run . sudo apt install --no-install-recommends qemu-kvm qemu-utils libvirt-bin virtinst ovmf . QEMU is a system for running virtual machines, and it can use KVM, which is a kernel module that supports the virtualization under the hood. We can install this with the package qemu-kvm. libvirt (installed via libvirt-bin) is a system for managing these QEMU/KVM virtual machines. qemu-utils provides necessary tools for creating virtual drives, and is used by virt-install. virtinst will provide the script virt-install, which we will use to create the virtual machine. We add --no-install-recommends because virtinst has a recommended dependency virt-viewer, which depends on the X11 system. However, this is a lot of packages that are only useful if we have a GUI (which we don’t!) so we want to skip recommended dependencies. Finally, ovmf is an additional library that will let us use UEFI (instead of the older BIOS spec) to boot the VM. Acquire installation media . Next, we need to get the installation media. Go to https://mirrors.ocf.berkeley.edu/archlinux/iso/latest/ to find the latest Arch release. Using the wget command within your VM, download the .iso file found within this directory as well as the .iso.sig signature file that we will use to verify the authenticity of the .iso file. For example, the current release at the time of writing is 2021.02.01, so you would run the following commands: . wget 'https://mirrors.ocf.berkeley.edu/archlinux/iso/latest/archlinux-2021.02.01-x86_64.iso' wget 'https://mirrors.ocf.berkeley.edu/archlinux/iso/latest/archlinux-2021.02.01-x86_64.iso.sig' . Note that Arch is a “rolling release” distribution (as opposed to distros like Ubuntu that release distinct versions e.g. Ubuntu 18.04, Ubuntu 20.04), so it is updated frequently. Therefore, the links used above are likely out of date by the time you’re reading this! Make sure to find the correct files for the latest release, do not just copy and paste the commands above. You can run ls to see the two files that were downloaded. Notice that we are downloading this from the OCF software mirrors (mirrors.ocf.berkeley.edu). There’s nothing stopping the OCF from modifying the .iso file and inserting malicious code that will end up running on our machine. To avoid this, we need to verify that the signature we downloaded is valid, and matches the file we downloaded. For more info, see https://wiki.archlinux.org/index.php/Installation_guide#Verify_signature. To verify the signature, run gpg --keyserver-options auto-key-retrieve --verify file.sig, replacing file.sig with the downloaded .sig file. You’ll see information about who created this signature. We want to know that this signature is from an Arch Linux developer. To be pretty confident of that, go to https://www.archlinux.org/people/developers/ and find the developer who is said to have created this signature. Under their info click on the link that says “PGP Key”. You’ll see a bunch of info about their PGP key. Check that the “Fingerprint” listed near the top of this page matches the “Primary key fingerprint” in the gpg output. If not, something is very wrong! . If the gpg commmand above to verify the signature doesn’t work, try using the OCF’s keyserver by appending this to the original command: --keyserver=hkp://pgp.ocf.berkeley.edu. GRADESCOPE: Who is the developer that created this signature, and what is their key’s fingerprint? . Note that this test is only resilient if www.archlinux.org is not compromised. To be more confident, you might want to try to find this fingerprint somewhere else, or independently verify this key somehow. Traditionally this is done via the web of trust, but new systems such as Keybase are trying to find alternate solutions to this fundamental problem of “How do I know you are who you say you are?” . Create VM . Now, we need to actually create our VM. (Don’t run this command until you’ve read the next paragraph!) To do this, you will run . sudo virt-install --name archvm --memory 704 --cpu host --vcpus 1 --disk size=5 --network network=default --boot uefi --graphics none --cdrom archlinux-2021.02.01-x86_64.iso . This will do some initial setup, and then drop us into a virtual serial console connected to the VM. You’ll see some boot options and a timer. Press e to edit the first boot option before the timer runs out! By default, Arch will not enable the serial console we are currently using to connect to the VM, so we need to manually add it to the kernel command line. Once we’re editing this command line, hit END to jump to the end of the line and carefully add a space and then console=ttyS0. When you’re confident you’ve typed it right, hit enter to start booting the kernel. Normally, we use “terminal emulators” (like Terminal or iTerm on Mac, or GNOME Terminal or Terminator on Linux) to access the console. Alternatively, we can use the console via terminals running via a keyboard and display. (To see this, hit ctrl-alt-F1 on an OCF lab computer. Hit ctrl-alt-F7 to get back to the GUI.) The option we are using here is accessing the console via a serial port connection, which in the modern age is pretty rare. However, we’re not using a real serial port of course—since we’re using a virtual machine, the serial port is also virtualized. libvirt provides convenient this convenient tooling to connect to this virtual serial port from the console we already have with the host machine (your student VM). We’re communicating with the VM via this virtual serial connection. If you wanted to detatch from this, you would hit the key combo ctrl-], and reconnect by running the command sudo virsh console archvm. In most cases if you disconnect and have to restart in the middle, you can just run sudo virsh console archvm to reconnect. If you really mess up, you can start things over by stopping the VM (sudo virsh destroy archvm), deleting the VM (sudo virsh undefine archvm --nvram --remove-all-storage), and then recreating it by starting over from the command above. If for some reason, your VM gets turned off before you are done installing Arch, it may be possible to reconnect the archiso and reboot the VM using the archiso. However, doing this is out of scope for this lab. You should start seeing a bunch of lines that start with [ OK ], and eventually you will see a login prompt. Since the installation media is basically just a preinstalled Linux system that makes it easy to install Linux on another system, this is the info about the booting “archiso” system. So, nothing is actually installed on the VM yet, but we are booting into a temporary Linux system that will help us install Linux permanently on the VM. Once you see a login prompt, enter root as the username, and you should get in! You’re now at the archiso command line. GRADESCOPE: Use the hostname command to get the current hostname. What is it? Then, use ip addr to find the current IP address (look at the inet line under ens2, it’s the stuff at the beginning of the line, not including the /24). What is your IP address? In another terminal, try to ping this IP address from your student VM, and then also from tsunami (ssh.ocf.berkeley.edu). Can either of them reach it? . We’ll discuss networking, and why you see these results, in a later lecture. Notice we are booted using UEFI (hence -boot uefi in the virt-install line). Check out the ArchWiki (https://wiki.archlinux.org/index.php/Installation_guide#Verify_the_boot_mode) for more info. Also, notice that we are already connected to the internet! Our virtual network uses DHCP, and the archiso knows to try to autoconfigure using DHCP. We will talk more about DHCP and other networking configuration later in the course. Finally, notice that we’ve conveniently inherited the system clock, so the time inside the VM should be right. You can run date to see. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a3/#setup",
    "relUrl": "/labs/a3/#setup"
  },"56": {
    "doc": "Advanced Lab 3 - Pre-install Setup and Installation",
    "title": "Partitioning time",
    "content": "The first order of business is to set up the partitions that we will be using for this installation. We are going to use a simple partition scheme: . | an EFI system partition (ESP) | one encrypted partition that holds our root filesystem | a small partition for swap space | . This is a very common scheme and is totally a scheme you could use if you were installing Arch on your own computer (except that you’ll hopefully have more than 5GiB to work with)! . GRADESCOPE: Give a brief and basic explanation of the purpose of having (1) the EFI system partition and (2) the swap partition. These explanations can be as short as one sentence, just try to get a general sense of why we have these partitions. Create partitions . We will use fdisk to create our partitions. Before we start the actual partitioning process, run fdisk -l. You should see that your VM has a single storage device called /dev/sda. Linux has special device files that correspond to each “block device” (e.g. hard drives, SSDs, and partitions on the aformentioned storage devices) discovered by the operating system. These device files live in the /dev folder. Read more about the naming convention for storage devices and their partitions here. Test your understanding: What would be the name of the device file corresponding to the fourth partition on the second discovered storage device? . Now to start the actual partitioning process, run fdisk /dev/sda. Note that you’ll be making a bunch of changes to the partition table, but these changes are not made immediately. So, if you make a mistake, you can just start again from step 1 without damaging anything. | Create a GPT table by typing g (then hit enter). | Create your ESP by typing n. Use the default partition number and first sector (just hit enter to automatically take the default). For the last sector, type +512M to allocate 512MiB for the partition. | Type t to change the type of the new partition (partition 1) to “EFI System”. You will have to list the types and find the right ID. (Note: press q to get out of the list of filesystem types). | Create your main root partition by typing n again. Use the default partition number and first sector. To leave 512MiB at the end of the disk for our swap partition, type -512M for the last sector. (This partition should already have the correct type, “Linux filesystem”, so you won’t need to change that.) | Create your swap partition by typing n one last time, and just take all the defaults. | Type t to change the type of the swap partition (partition 3) to “Linux swap”, as in step 3. | Type p to show the current partition table with all the changes you’ve made. You should see an “EFI System” partition that is 512MiB, a “Linux filesystem” partition that is 4GiB, and a “Linux swap” partition that is 512MiB. | If everything looks right, type w to finally actually write the changes to disk. | . At this point, fdisk should exit. GRADESCOPE: To see your final results, run fdisk -l /dev/sda and paste the output into Gradescope. At this point, you’ve created the disk partitions, but nothing is on them yet. Now we need to put the filesystems you will use on these partitions! . Create filesystems . ESP . The ESP (EFI System Partition) has to be in a FAT format. For more information about the ESP, see https://wiki.archlinux.org/index.php/EFI_system_partition. Your ESP should be /dev/sda1 (refer back to output from fdisk -l /dev/sda). Run mkfs.fat -F32 /dev/sda1 to create the FAT32 filesystem. These instructions are straight from https://wiki.archlinux.org/index.php/EFI_system_partition#Format_the_partition. Root partition . Our root partition should be /dev/sda2. We are going to encrypt the root partition. This makes things a bit more complicated, but thankfully the ArchWiki will help us out! . Encryption is basically essentially in modern devices. If you do not encrypt your drive, anyone who has access to that drive can simply take it out of your machine and read everything on it. Your account password doesn’t protect against anything. However, if you do use encryption, you will not be able to get anything off the disk at all without the encryption password. Wiping . A previous version of this lab mentioned that you should wipe your device before encrypting. While this may provide some benefits on older (spinning-disk) hard drives, it will significantly reduce the lifetime of modern solid-state drives. As DigitalOcean VMs, probably your laptop, and almost all modern computers use solid state drives, this section has been removed. If you’d like to see the older version of this lab, see here. Setting up the encrypted device . Again, this is taken from the ArchWiki. Follow along! . First, set up the encrypted partition. For this lab, use the encryption passphrase ilovelinux. cryptsetup -y -v luksFormat /dev/sda2 . A note on passphrases: don’t use a passphrase like this! A good way to come up with passphrases is just to take 6 random words (and I mean actually random, not like xkcd.com/1210 random). One way to generate such a password is the command shuf -n 6 /usr/share/dict/words (you might have to install a package like wamerican on Ubuntu/Debian or words on Arch). We will talk more about security (including password security) later in the course. Now that the encrypted partition has been created, let’s open it! . cryptsetup open /dev/sda2 cryptroot . GRADESCOPE: Run lsblk to see the hierarchy of these partitions. Paste this output into Gradescope! . Creating the actual filesystem . We now have a blank pseudo-partition (“block device”) /dev/mapper/cryptroot, that’s actually backed by encrypted /dev/sda2 disk partition. However, there’s no filesystem here yet. Create it by doing . mkfs.ext4 /dev/mapper/cryptroot . GRADESCOPE: What previous command we ran is similar to this command, and what’s the difference? (Bonus: why?) . Swap . Our swap partition should be /dev/sda3. The swap space isn’t really a filesystem, but we still need to set it up. Thankfully, this is pretty straightforward: . mkswap /dev/sda3 . Then, enable it with . swapon /dev/sda3 . If you don’t know about swap, it is basically a specially designated section of disk that the operating system can use as memory in case it runs out of actual memory. For more info, check out https://wiki.archlinux.org/index.php/Swap. Mount the new filesystems . We’ve now created all our filesystems, but in order to access them, we need to mount them. What does mounting mean? The man page for the mount command provides a nice description: “All files accessible in a Unix system are arranged in one big tree, the file hierarchy, rooted at /. These files can be spread out over several devices. The mount command serves to attach the filesystem found on some device to the big file tree. Conversely, the umount(8) command will detach it again.” We are currently in the “file tree” of the Arch live environment, which does not include the new ESP and root filesystems we created for our future Arch installation. Using mount, we can attach these filesystems to our live environment filesystem and access them as if they were directories at the mount point. Once the ESP and root filesystems are visible to the current filesystem, we can start installing a boot loader to the ESP filesystem and our permanent Arch OS to the root filesystem. We’re going to use /mnt as the temporary root of the new Arch installation. Thus, we mount the root filesystem at /mnt, and the ESP at /mnt/boot (since the ESP will normally be mounted at /boot). Hopefully this will make a little more sense once we begin installing the system. mount /dev/mapper/cryptroot /mnt mkdir /mnt/boot mount /dev/sda1 /mnt/boot . GRADESCOPE: . | You can see every single filesystem that’s currently mounted by running the mount command. Run it, and look for the two filesystems we just mounted. Copy all the output over to Gradescope. | Another common Linux partitioning scheme is to have a separate /home partition in addition to the partitions we created above. This can be useful in case something goes catastrophically wrong with your operating system to the point where you need to reinstall it. You can wipe your root filesystem and reinstall your OS while leaving your /home partition untouched, saving your user folder(s) with personal files like documents and photos without needing to restore from a backup. Hypothetically, if we had made a separate /home partition and filesystem in the previous steps, what command(s) would we need to run to mount it? Assume the /home partition is /dev/sda3. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a3/#partitioning-time",
    "relUrl": "/labs/a3/#partitioning-time"
  },"57": {
    "doc": "Advanced Lab 3 - Pre-install Setup and Installation",
    "title": "Installation",
    "content": "With our partitions all set up and ready to get going, we can start installing out system onto them! . Much of this will be straight from the ArchWiki installation guide, starting at https://wiki.archlinux.org/index.php/Installation_guide#Installation. It’s a good idea to follow along there as well to see what modifications we are making. Mirrors . We need to tell Arch which software mirror to use when downloading packages. Go ahead and just put the OCF mirror at the top! Edit /etc/pacman.d/mirrorlist using vim/emacs/nano and put the following line at the top: . Server = https://mirrors.ocf.berkeley.edu/archlinux/$repo/os/$arch . (We’re usually lower down in the file but putting us at the top will make things a bit faster to install.) . Continue according to ArchWiki! . Follow the arch wiki exactly from https://wiki.archlinux.org/index.php/Installation_guide#Install_essential_packages down until you get to the “Initramfs” section. If you get stuck, check out the following hints: . | vim is not installed in the chroot by default. You can do pacman -S vim to install it, or just use plain old vi. | Our timezone is America/Los_Angeles. | The locale you want to use is en_US.UTF-8. | You shouldn’t need to change the keyboard layout. | You can pick whatever you want for your hostname. OCF machines are all named after “disasters”, so it can be fun to come up with a creative name that fit that theme. | . initramfs . The initramfs is the minimal stuff that’s loaded into RAM that helps Linux get started when you first boot. On Arch, there’s a system to generate this initramfs. You need to tell it to support disk encryption. Based on the ArchWiki’s instructions, we need to edit /etc/mkinitcpio.conf. You should see a line like . HOOKS=(base udev autodetect ...) . We need to add the keymap and encrypt hooks, and move the keyboard hook earlier in the line. When you’re done, it should look like . HOOKS=(base udev autodetect keyboard keymap modconf block encrypt filesystems fsck) . The order of these hooks matters! Be careful. Run mkinitcpio -p linux to generate the new initramfs based on the new config file. Root password . Use passwd to set the root password to itoolovelinux. As mentioned for the disk encryption passphrase, don’t use a password like this in real life! Choose a strong root password using a method like the one from earlier. User programs shouldn’t be able to compromise this password, because it would allow a single program (which should generally be untrusted) to access everything on your computer. Boot loader . Historically, GRUB has been the only reasonable choice of boot loader. However, with the advent of UEFI, there are lots of different good options (or my personal favorite, no bootloader at all). In this lab, we are going to use systemd-boot. We can install systemd-boot to our ESP by running . bootctl --path=/boot install . We now need to tell systemd-boot that our Arch Linux installation exists and how to start it! Create a bootloader entry by creating the file /boot/loader/entries/arch.conf with these contents: . title Arch Linux linux /vmlinuz-linux initrd /initramfs-linux.img options cryptdevice=UUID=290d6a44-2964-48a0-a71e-ea3df0525987:cryptroot root=/dev/mapper/cryptroot rw console=ttyS0 . IMPORTANT NOTE: You will need to replace 290d6a44-2964-48a0-a71e-ea3df0525987 with the correct UUID for your encrypted /dev/sda2 partition. To find the correct UUID, run ls -l /dev/disk/by-uuid and look for the line with -&gt; ../../sda2. This line will have the UUID you need. If you make a mistake here, you can mess things up pretty bad! TRIPLE-CHECK this file! . We could use a name like /dev/sda2 instead of UUID=290d6a44-2964-48a0-a71e-ea3df0525987 here. However, these names like /dev/sdXX are not guaranteed to always be the same. A kernel update or hardware changes can mean that /dev/sda2 is now /dev/sdb2, or vice versa. This will mean we won’t be able to boot, and in particularly bad cases, can lead to data loss. For this reason, we should use UUIDs whenever possible, because they cannot change. See https://wiki.archlinux.org/index.php/Persistent_block_device_naming for more info about this. Also, remember how we had to add console=ttyS0 when we first booted the archiso? We can add that option here to make it permanent for the new system, so the console will always be enabled. Type exit to exit the chroot and then type reboot to REBOOT AND FINISH THE INSTALLATION! Congrats! . If things don’t work after you reboot, don’t panic! Please make a Ask for help on #decal-general, and we will try to help you recover things. When it reboots, you will be asked for the disk encryption password, and then you should see a login prompt. Log in as root using the password you set! . GRADESCOPE: To show off your newly installed Arch system, run the following commands and paste the output into Gradescope: . hostname -f ip addr mount lsblk uname -a . Debugging Note: If the hostname command is not found, you may need to install it by running sudo pacman -S inetutils. Doing so may also reveal that your internet connection is not yet configured. If this is the case, then you will likely need to sudo systemctl enable systemd-resolved and/or sudo systemctl enable systemd-networkd and/or sudo systemctl enable dhcpcd and/or ln -sf /run/systemd/resolve/stub-resolv.conf /etc/resolv.conf . You can see more information about this in the ArchWiki: https://wiki.archlinux.org/index.php/systemd-networkd . When you are done, you can hit ctrl-] to detach your console from the Arch VM and get back to your normal student VM shell. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a3/#installation",
    "relUrl": "/labs/a3/#installation"
  },"58": {
    "doc": "Advanced Lab 3 - Pre-install Setup and Installation",
    "title": "Advanced Lab 3 - Pre-install Setup and Installation",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a3/",
    "relUrl": "/labs/a3/"
  },"59": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "Table of contents",
    "content": ". | Topics Covered | About this Lab . | A note about VMs | . | Generating and using SSH keys | Setting up a firewall . | Gradescope Questions | . | Choose your own adventure . | Music Server | Git server | File Hosting | Password Manager | Gradescope Questions | . | Submission . | Footnotes | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/#table-of-contents",
    "relUrl": "/labs/a4/#table-of-contents"
  },"60": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "Topics Covered",
    "content": "We covered a lot of material in the lecture. Here’s a short list of things you may be interested in looking into further, besides googling and reading the man pages for the commands we discussed in lecture. | SELinux - Security Enhanced Linux, gives role-based/mandatory access control facilities. Utilizing it is well beyind the scope of this class, but reading about how SELinux works should give you an appreciation for the degree to which people have thought about file-level security in the kernel. | Official Wiki | Red Hat documentation | Wikipedia (obviously) | . | Managing users and groups . | TLDP entry | An excellent DigitalOcean guide | These great StackExchange answers | ArchWiki breakdown of permissions | Debian Wiki equivalent | If you needed more reasons to be skeptical of the maturity of the Node ecosystem | Protection Rings - no DND, unfortunately | glibc and kernel source where some of this stuff gets checked | . | Configuring sshd . | Another comprehensive DigitalOcean guide to /etc/ssh/sshd_config | Fail2Ban and Archwiki configuration instructions | . | On-host firewalls (ufw) . | Fairly comprehensive ufw configuration guide | The same guide, but for Ubuntu 18.04: ufw | . | The Filesystem Hierarchy . | Wikipedia entry | Even more comprehensive TLDP entry | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/#topics-covered",
    "relUrl": "/labs/a4/#topics-covered"
  },"61": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "About this Lab",
    "content": "In this lab you will implement some of the things we discussed during lecture. In the first part, you’ll be securing your VM with a firewall and enabling key-based login. Then, we’ll open it up for you to choose a cool service to host on your very own VM! . A note about VMs . In this course, we’ve used several VM’s: . | The OCF’s public login server, tsunami, | Your student VM, hosted on DigitalOcean, &lt;yourname&gt;@&lt;yourname&gt;.decal.xcf.sh, | and the Arch VM you installed in the previous lab. | . To be clear, you should be completing this lab on your student VM and not your newly installed Arch VM unless otherwise stated1. If you happen to have access to a permanent personal VM/server you are also welcome to complete the lab on that (as the student VM’s will be deleted at the end of the semester). ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/#about-this-lab",
    "relUrl": "/labs/a4/#about-this-lab"
  },"62": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "Generating and using SSH keys",
    "content": "Passwords can be guessed, and this is bad. Good security practice now involves taking advantage of public-key crypto to authenticate SSH sessions. In this section, we will be setting up SSH keys, if you haven’t already. If you aren’t currently using a Linux machine, please log into tsunami.ocf.berkeley.edu first (not your student VM- the reason will be clear shortly). These instructions will not work on a Windows machine. | First, make sure you don’t already have an existing SSH key in use that you might overwrite: . you@tsunami $ ls -la ~/.ssh -rw------- 1 &lt;you&gt; ocf &lt;stuff&gt; .ssh/id_rsa # if this already exists, continue to step 3 . | If you don’t have an SSH key, make one with the following command . you@tsunami $ ssh-keygen -t rsa -b 4096 . You can give the key a passphrase if you’d like. This command creates a 4096-bit RSA private key (~/.ssh/id_rsa) and corresponding public key (~/.ssh/id_rsa.pub). There are many types of keys in various sizes, such 2048-bit RSA keys (ssh-keygen -t rsa -b 2048) or 384-bit ECDSA keys (ssh-keygen -t ecdsa -t 384) or more. The full list can be found in man ssh-keygen. Which one to use is up to your preference and/or paranoia2 about quasi-legal government surveillance. | Copy the public key over to your student VM . you@tsunami $ ssh-copy-id you@you.decal.xcf.sh . This command, as its name suggests, copies your public key (by default, ~/.ssh/id_rsa.pub) to the specified remote host, and appends the contents of the public key to the ~/.ssh/authorized_keys file, which is used to control which keys are authorized to be used to authenticate a user. To see specifically what happened, do cat ~/.ssh/id_rsa.pub) on tsunami and then compare that to cat ~/.ssh/authorized_keys on your student VM. | . At the end ssh-copy-id will prompt you to attempt to log into the server using your key. This should succeed. Gradescope Questions . | Paste the contents of ~/.ssh/authorized_keys from your student VM. | What are the permissions on your public key and private key? Why do you think they are the way they are? | . For an extra challenge (optional), configure sshd to only allow key-based login. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/#generating-and-using-ssh-keys",
    "relUrl": "/labs/a4/#generating-and-using-ssh-keys"
  },"63": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "Setting up a firewall",
    "content": "In order to secure your VM, you should install a firewall. To do this, install ufw, the Uncomplicated Firewall. ufw is a easy-to-use wrapper around the powerful iptables firewall. You should be able to figure out how to set up ufw using the guides linked earlier and your own Google-foo. Inorder to get checked off for this portion of the lab, ensure the following: . | All incoming connections are blocked by default. | Allow incoming connections to your VM over port 22 (SSH), otherwise you’ll be locked out of your VM! | Allow incoming connections for the ports necessary for the operation of the software you’ll be installing later on in this lab. For example, if you are configuring a web server, you should enable port 80 and/or 443. (You can always come back to this after figuring out the next part of the lab!) for a web server. | Extra challenge (optional): Allow the above, but only for IPs originating from UC Berkeley’s subnet. UC Berkeley has 3 primary /16s. | Double extra challenge (optional): Configure fail2ban to block IP addresses that are trying to brute-force your SSH password. | . Gradescope Questions . | What command did you use to enable a port? | Paste the output of sudo ufw status verbose. Make sure you can clearly see the changes you made in the steps above! | Why is setting up a firewall important? What are some security concerns that might arise from exposing a port? | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/#setting-up-a-firewall",
    "relUrl": "/labs/a4/#setting-up-a-firewall"
  },"64": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "Choose your own adventure",
    "content": "At this stage, you should have a fully functioning Linux install! Now, your task is to install a useful service on your VM. We’ve described a few examples below, but don’t be restricted by them! You can also take a look at the awesome-selfhosted page for some inspiration! . Music Server . Some music enthusiasts opt to own their own music files instead of using a cloud service (Spotify, Google Play Music, etc). But, if the files are only stored on your computer’s hard drive, how can you listen to your music when on someone else’s computer or on the go? A music server like CherryMusic can solve this problem while still giving you control over your files. Install CherryMusic (or an alternative) on your DeCal VM, and load up a few tunes. Git server . GitHub is a good place to host your source code, but self-hosting your own Git can be a good option if you need to store something private (and don’t trust GitHub), hosting your own can be a good solution. While you can use Git to host a repo on any SSH server using a bare repo, to get a fancy GUI you need to install special software. Some popular options for this include Gitea (which mimicks GitHub’s interface) and cgit (which takes a more minimalist approach). Pick one and install it. File Hosting . Instead of uploading your files to Google Drive or Dropbox to be shared, you can host on your own VM. A good option for this is fluffy (created by an OCF alum!), which also doubles as a pastebin for quickly sharing code snippets. For more options, look at the the “simple click/drag-n-drop upload” section of awesome-selfhosted. Password Manager . BitWarden is a popular self-hosted password manager. You can use it to host your passwords if you don’t want to rely on a proprietary third-party program (like LastPass). Alternatives include pass which is a user-friendly wrapper around gpg. Please note that your student VMs will be deleted at the end of the semester, so you should not use your student VM for long term password storage. Gradescope Questions . | What did you install on your VM? | Attach a screenshot of your service in action. (This could be a web console or a command output in the shell.) | Briefly describe the installation process. Were there any unexpected roadblocks you encountered? | What are some security implications from hosting this service? How have you handled them (or are you not handling them?) | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/#choose-your-own-adventure",
    "relUrl": "/labs/a4/#choose-your-own-adventure"
  },"65": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "Submission",
    "content": "Respond to the checkoff questions on gradescope! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/#submission",
    "relUrl": "/labs/a4/#submission"
  },"66": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "Footnotes",
    "content": ". | Unless you’re up for a challenge configuring port forwarding in a nested VM- then by all means go for it! &#8617; . | https://www.amazon.com/Only-Paranoid-Survive-Exploit-Challenge/dp/0385483821 &#8617; . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/#footnotes",
    "relUrl": "/labs/a4/#footnotes"
  },"67": {
    "doc": "Lab 4 - Linux Post-Install",
    "title": "Lab 4 - Linux Post-Install",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a4/",
    "relUrl": "/labs/a4/"
  },"68": {
    "doc": "Advanced Lab 5 - Processes and Services",
    "title": "Table of contents",
    "content": ". | Overview | Using systemd . | What services are running right now? | Controlling Services | Creating a service | Debugging | Crash the service! | . | Exploration | Submission | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a5/#table-of-contents",
    "relUrl": "/labs/a5/#table-of-contents"
  },"69": {
    "doc": "Advanced Lab 5 - Processes and Services",
    "title": "Overview",
    "content": "For this lab, we are going to deep dive into the components and systemd. We will do this by writing our own systemd service from scratch, while showing the benefits of running a service with systemd. This lab should be completed on your decal VM. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a5/#overview",
    "relUrl": "/labs/a5/#overview"
  },"70": {
    "doc": "Advanced Lab 5 - Processes and Services",
    "title": "Using systemd",
    "content": "What services are running right now? . Run systemctl. You’ll see a long table of every unit known to systemd. Let’s narrow it down to services for now. Run systemctl --type=service. Now you can see a list of all services running on your computer. Each of these services is a daemon running in the background. Do you see any familiar services running? . Question 1: What is the name of a systemd service running on your system? What does it do? . Controlling Services . Now let’s use systemd to control a an nginx web server. If you don’t have it already, install nginx by issuing sudo apt install nginx. Once that is done we can tell systemd to start the service with the following: sudo systemctl start nginx. Run systemctl status nginx to ensure it is running and navigate to http://yourvm.decal.xcf.sh/ – you should be greeted by the nginx default landing page. (You may need to update the firewall you set up in lab A4 to allow connections to port 80.) . Note: If you have a webserver running from lab A4, you may need to shut it down, so that port 80 is available for nginx to use. Now let’s make nginx listen for connections on the nonstandard port 420. In /etc/nginx/sites-available/default change the following lines: . listen 80 default_server; listen [::]:80 default_server; . to: . listen 420 default_server; listen [::]:420 default_server; . TIP: The first line configures the server to listen on IPv4, and the second line configures IPv6. Tell systemd that nginx has changed configuration and needs reloading with: sudo systemctl reload nginx. (Once again, you may need to allow port 420 through your firewall.) Now, accessing http://yourvm.decal.xcf.sh/ should now give you a connection refused error and your webserver will only be accessible via http://yourvm.decal.xcf.sh:420/. Note that not all services can be reloaded; systemd will notify you if this is the case and such services will have to be restarted instead with: sudo systemctl restart yourservice. Finally go ahead and stop the nginx service with sudo systemctl stop nginx. Question 2: What is the difference between systemctl reload yourservice and systemctl restart yourservice? . Creating a service . Let’s set up a web server and create a systemd unit for it. Make sure git is installed; if it’s not, install it using apt. To get the code, run: . $ wget https://decal.ocf.berkeley.edu/static/a5/a5.tar.gz $ tar xvf a5.tar.gz . The materials for this part of the lab will be in the a5 directory. We will also need to install some dependencies. Go ahead and execute the following commands: . # apt update # apt install build-essential make python-virtualenv . Now run ./run. This should start up a simple web server at http://yourvm.decal.xcf.sh:5000. (Again… might need to open the port in your firewall.) . Your mission, should you choose to accept it, is to write a systemd service that manages this web server. To do this, make a new unit file in /etc/systemd/system/toy.service. Refer to the slides for an example; DigitalOcean also has a good guide on how to write systemd units. Here is a skeleton; all you need to do is fill in the values for each field. [Unit] Description= Requires= After= [Install] WantedBy=multi-user.target [Service] ExecStart= User= . Some questions worth considering while writing this unit file are: . | What units needs to be started before a webserver starts? (Hint: you can get a list of special “target” units using systemctl --type=target.) | What script should systemd run to start the webserver? | Units run by root as default. Is that a safe practice for web servers? | . You are encouraged to experiment with other fields as suits your liking. Once you have finished creating toy.service, let’s start the service and have the it start whenever our machine is booted. # systemctl start toy.service # systemctl enable toy.service . Debugging . You can check if the unit file succeeded by running systemctl status toy.service. If you are having issues with the unit file or the web server, check the logs for this unit by running journalctl -u toy.service. If you run into errors don’t get demoralized (it is, after all, only a decal); as a sysadmin you’ll have to become comfortable making sense of arcane error messages. TIP: You can omit the .service in systemctl command for speed. If the unit is another type (e.g. target, socket, or timer), you must include the type. We include the .service for clarity. Crash the service! . One of the great benefits of using systemd to manage your services is that you don’t have to worry unnecessarily about bringing a process back up if it crashes. So let’s crash the service! You can do this by either sending a POST request with the json payload {\"crash\":\"true\"} to http://yourvm.decal.xcf.sh:5000/crash (Hint: use cURL) or by killing the webserver manually by sending a signal – both will cause the unit to crash. You can verify if you succeeded by running systemctl status toy.service, and the unit should either be in an inactive or failed state, depending on how you killed it. Question 3: What command did you run to crash the service? . Now add the following the /etc/systemd/system/toy.service under the Service directive: . Restart=always RestartSec=10 . To tell systemd that the unit file has changed run sudo systemctl daemon-reload. Now start your webserver and crash it again in any way you please, and you should see that it come back online after 10 seconds! Note that you can also run daemon-reload and change a unit file while a service is running. Question 4: Upload your fully featured toy.service file to Gradescope. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a5/#using-systemd",
    "relUrl": "/labs/a5/#using-systemd"
  },"71": {
    "doc": "Advanced Lab 5 - Processes and Services",
    "title": "Exploration",
    "content": "Congratulations, you have completed the lab! This is just the tip of the iceberg when it comes to processes and services. If you want to learn more, here are some related topics you can look into. | Wikipedia’s article on init systems | The construction of a basic init system | Yelp’s dumb-init, a lightweight init system for docker containers | Zombie Processes | Socket activation | Systemd has been the source of a considerable amount of controversy. Opponents allege that it violates the Unix philosophy of “do one thing and do it well”, and that it has had too much scope creep, among other complaints. | Everything you wanted to know about Unix threads, processes, process groups and sessions. Bear in mind that this document is a little dated when it comes to the code about threads, and its description of what happens when a pseudotty is closed is not actually correct. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a5/#exploration",
    "relUrl": "/labs/a5/#exploration"
  },"72": {
    "doc": "Advanced Lab 5 - Processes and Services",
    "title": "Submission",
    "content": "Go to Gradescope to submit your answers! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a5/#submission",
    "relUrl": "/labs/a5/#submission"
  },"73": {
    "doc": "Advanced Lab 5 - Processes and Services",
    "title": "Advanced Lab 5 - Processes and Services",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a5/",
    "relUrl": "/labs/a5/"
  },"74": {
    "doc": "Lab 6 - Networking 102",
    "title": "Table of contents",
    "content": ". | Overview | Network Interfaces . | /etc/network/interfaces | Checkpoint | . | /proc filesystem . | /proc/net/ . | /proc/net/dev | /proc/net/[tcp|udp|raw] | /proc/net/route | /proc/net/arp | /proc/net/snmp | . | /proc/sys/ . | /proc/sys/net/core/ | /proc/sys/net/ipv4/ | . | Checkpoint | . | ARP configuration | DNS configuration . | /etc/hosts | /etc/resolv.conf | /etc/nsswitch.conf | . | DHCP client configuration . | Timing | . | Sysadmin commands . | ifupdown | mtr | iptables | Checkpoint | . | Exercises . | 🔥 This is fine 🔥 . | IMPORTANT NOTE | Setup | Problem Instructions | Debugging Bank | . | Net Ninjas (Optional) | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#table-of-contents",
    "relUrl": "/labs/a6/#table-of-contents"
  },"75": {
    "doc": "Lab 6 - Networking 102",
    "title": "Overview",
    "content": "This lab will go over some concepts of networking and how certain parts of a network stack are implemented and configured in linux systems. It is assumed that you are familiar with basic networking concepts such as those presented in Lab b5. Additional information about certain files discussed here can be found in their corresponding man pages by typing man &lt;filename&gt;. As with the previous labs, there will be questions sprinkled throughout- head over to Gradescope to submit your answers to them! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#overview",
    "relUrl": "/labs/a6/#overview"
  },"76": {
    "doc": "Lab 6 - Networking 102",
    "title": "Network Interfaces",
    "content": "Network interfaces represent a point of connection between a computer and a network. Typically network interfaces are associated with a physical piece of hardware, like a network interface card. However, interfaces can also be entirely implemented in software and have no physical counterpart – take the loopback interface lo for example. lo is a virtual interface; it simulates a network interface with only software. /etc/network/interfaces . Network interface configurations are stored under the /etc/network/interfaces file on your system. Here, there is plenty of room for complexity. For example, you can have certain interfaces automatically brought up by hooking them to system boot scripts or specify some interfaces to only be available under certain circumstances, with some of the provided control flow options. This lab will go over some common configuration keywords, but there is much more to the file. For a detailed page of the features and syntax of the file simply type man interfaces to pull up the man page for the file. Firstly, configurations are logically divided into units known as stanzas. The /etc/network/interfaces file is comprised of zero or more stanzas which begin with iface, mapping, auto, allow-, source, or source-directory. For brevity, we will go over the two most commonly used stanzas auto and iface. The auto stanza is fairly simple, its syntax is auto &lt;iface&gt;. The auto stanza flags an interface to be brought up whenever ifup is run with the -a option (More on ifup below). Since system boot scripts use ifup with the -a option, these interfaces are brought up during boot. Multiple auto stanzas will be executed in the same order as they are written in the file. The iface stanzas lets you express complex configurations for individual interfaces by leveraging its features. Its syntax is iface &lt;iface&gt; &lt;address-family&gt; &lt;method&gt;. Let’s go over some of the arguments the stanza takes. &lt;address-family&gt; identifies the addressing that the interface will be using. The most common address families that you’re probably familiar with are: . | IPv4 denoted by inet in the file | IPv6 denoted by inet6 in the file | . Address families can be configured via different methods expressed by the &lt;method&gt; option. Some common methods you should be familiar with are: . | loopback defines this interface as the loopback. | dhcp is for interface configuration via a DHCP server. | static is for static interface configuration. | manual brings up the interface with no default configuration. | . Methods also have options that let you supply certain configuration parameters. For example, for the static method you can additionally use the address &lt;ip-address&gt; and netmask &lt;mask&gt; options to specify the static IP address and netwask you want the interface to use. Moreover, the iface stanza additionally has its own options compatible with all families and methods. To present just a few, we have: . | pre-[up|down] &lt;command&gt; runs the given &lt;command&gt; before the interface is either taken up or down | post-[up|down] &lt;command&gt; runs the given &lt;command&gt; after the interface is either taken up or down | . As a final note, any changes to the configurations done in this file during runtime are not applied automatically. Changes have to be reloaded via calls to ifupdown, the de facto command suite for interacting with /etc/network/interfaces. Checkpoint . Question 1a: Is the result of running ping enough to determine whether or not you can reach a server? Why or why not? . Question 1b: Here’s a quick check for your understanding – below is a very common default configuration for /etc/network/interfaces: . auto lo iface lo inet loopback . In your own words, explain what this configuration does. What would happen if you deleted these lines and rebooted? . Question 1c: Write a few stanzas that configure an interface called test that is brought up on boot and given the following address: 192.168.13.37/16. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#network-interfaces",
    "relUrl": "/labs/a6/#network-interfaces"
  },"77": {
    "doc": "Lab 6 - Networking 102",
    "title": "/proc filesystem",
    "content": "proc is a virtual filesystem that presents runtime system information in a file-like structure. This file-like interface provides a standardized method for querying and interacting with the kernel, which dumps metrics in the read-only files located in this directory. Using a tool like cat, you can dynamically read those files at runtime. But keep in mind, there are no ‘real’ files within proc. /proc/net/ . We will be focusing on certain portions of proc, the first of which being /proc/net/. This subdirectory in proc contains information about various parts of the network stack in the form of virtual files. Many commands, such as netstat, use these files when you run them. /proc/net/dev . This file contains information and statistics on network devices. ifconfig is an example command that reads from this file. Take a look below and notice how the information presented in the ifconfig output corresponds to data dumped in dev on how many bytes and packets have been received or transmitted by an interface. /proc/net/[tcp|udp|raw] . Thetcp, raw, and udp files each contain metrics on open system sockets for their respective protocols, i.e. reading tcp displays info on TCP sockets. As a side note, raw sockets are network sockets that offer a finer degree of control over the header and payload of packets at each network layer as opposed to leaving that responsibility to the kernel. They are ideal for uses cases that send or receive packets of a type not explicitly supported by a kernel, think ICMP. For additional information check this article out. These files are read by ss, netstat, etc. Check out the example for tcp below. /proc/net/route . This file contains information about the kernel routing table. Some commands that use this file include ip and netstat. Take a look at how the file is parsed and processed by the netstat command. /proc/net/arp . This file contains a dump of the system’s ARP cache. The arp command reads from this file. For example, look at how closely the output of the arp command resembles the raw text dumped by the kernel into the file. /proc/net/snmp . This file contains statistics intended to be used by SNMP agents, which are a part of the Simple Network Management Protocol (SNMP). Regardless of whether or not your system is running SNMP, the data in this file is useful for investigating the network stack. Take the screenshot below for example, examining the fields we see InDiscards which according to RFC 1213 indicates packets that are discarded since problems were encountered that prevented their continued processing. Lack of buffer space is a possible cause of having a high number of discards. Having a statistic like this one, amonst others, can help pinpoint a network issue. For additional information on fields please refer to the header file here. The image is a bit small so feel free to right click -&gt; “Open image in a new tab” to magnify the output. /proc/sys/ . Whereas the files and subdirectories mentioned above are read-only that isn’t true about the /proc/sys subdirectory which contains virtual files that also allow writes. You can not only query for system runtime parameters but also write new parameters into these files. This means you have the power to adjust kernel behavior without the need for a reboot or recompilation. Mind-blowing. While the /proc/sys directory contains a variety of subdirectories corresponding to aspects of the machine, the one we will be focusing on is /proc/sys/net which concerns various networking topics. Depending on configurations at the time of kernel compilation, different subdirectories are made available in /proc/sys/net, such as ethernet/, ipx/, ipv4/, and etc. Given the sheer variety of possible configurations, we will confine the scope of this discussion to the most common directories. /proc/sys/net/core/ . core/ is the first subdirectory that we’ll cover. As its name implies, it deals with core settings that direct how the kernel interacts with various networking layers. Now we can go over some specific files in this directory, their functionality, and motivations behind adjusting them. | message_burst and message_cost Both of these parameters take a single integer argument and together control the logging frequency of the kernel. message_burst defines entry frequency and message_cost defines time frequency in seconds. For example, let’s take a look at their defaults. message_burst defaults to 10 and message_cost defaults to 5. This means the kernel is limited to logging 10 entries every 5 seconds. When adjusting the parameters in these two files, a sysadmin must keep in mind that the tradeoff here is between the granularity of the logs and the performance/storage limitations of the system. Increasing overall logging frequency can translate to a hit to system performance or huge log files eating up disk. But if logging is too infrequent, parts of the network may fail silently and bugs may become much harder to identify. | netdev_max_backlog This file takes one integer parameter that defines the maximum number of packets allowed to queue on a particular interface. | rmem_default and rmem_max These files define the default and maximum buffer sizes for receive sockets, respectively. | smem_default and smem_max These files define the default and maximum buffer sizes for send sockets, respectively. For the above sets of system parameters, adjusting queue lengths have the nice effect of allowing our system to hold more packets and avoid dropping packets due to a fast sender for example. This boils down to optimizing flow control. However, there is no such thing as a free lunch. Increasing queue sizes can only mitigate problems with arrival rates being greater than service rates for so long. For more information on why that is check out queueing theory. Moreover, having many packets stored in long queues also has its own drawback. Storing packet information isn’t free and the more packets stored in the queue, the more resources the system needs. As a result, too many packets may lead to increased paging and ultimately thrashing. Once again, we have another tradeoff, but this time between flow control and paging. | . As a sysadmin many of the configuration decisions you make will be balancing between two extremes and the optimal point isn’t hard and fast. Many times you’ll have to adjust system parameters on a case-by-case basis and, after empirical testing, come to a good point. /proc/sys/net/ipv4/ . ipv4/ is another common subdirectory that contains setting relevant to IPv4. Often the settings used in this subdirectory are used, in conjunction with other tools, as a security measure to mitigate network attacks or to customize behavior when the system acts as a router. | icmp_echo_ignore_all This file configures the system’s behavior towards ICMP ECHO packets. This file has two states 0 for off and 1 for on. If on, the system will ignore ICMP ECHO packets from every host. | icmp_echo_ignore_broadcasts This file is similar to the one above, except turning this parameter on only makes the system ignore ICMP ECHO packets from broadcast and multicast. | . One argument against disabling ICMP is that it makes obtaining diagnostic information about servers much harder. The output of tools that rely on ICMP, i.e. ping, are no longer as useful. On the other hand, allowing ICMP might be a bad idea if your goal is to hide certain machines. Additionally, ICMP has been used in the past in DOS attacks. | ip_forward Turning this parameter on permits interfaces on the system to forward packets. Take for example, if your computer has two interfaces, each connected to two different subnets, A and B. While your machine can individually send and receive traffic to hosts on either network, machines on A cannot send packets to machines on B via your machine. Turning ip_forward on is the first step to configuring your linux machine to act as a router. It is common to see this on machines that act as VPN servers, forwarding traffic on behalf of hosts. | ip_default_ttl This is a simple file that configures the default TTL (time to live) for outbound IP packets. | ip_local_port_range This file takes two integer parameters. The first integer specifies the lower bound of the range and the second specifies the upper bound. Together, the two numbers define the range of ports that can be used by TCP or UDP when a local port is needed. For example, when a socket is instantiated to send a TCP SYN, the port given to the socket is selected by the operating system and lies within the specified range. The ports in this range are as known as ephemeral ports. | tcp_syn_retries This file limits the number of times the system re-transmits a SYN packet when attempting to make a connection. When attempting to connect to either a ‘flaky’ host or over a ‘flaky’ network, setting this number higher might be desirable. But this comes at the cost of adding additional traffic to the network and potential blocking other processes while waiting for a SYN-ACK that might never come. | tcp_retries1 This file limits the number of re-transmissions before signaling the network layer about a potential problem with the connection. | tcp_retries2 This file limits the number of re-transmissions before killing active connections. This implies the following relationship: tcp_retries2 &gt;= tcp_retries1. The two retry values configure how ‘patient’ your system should be when it comes to waiting on RTOs. | . Additional information on configurable system parameters can be found either at this tutorial or in documentation via kernel.org or bootlin. Checkpoint . Question 2a: Describe the tcp_syncookies sysctl option. How can we toggle this value on, and when would we want this on? . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#proc-filesystem",
    "relUrl": "/labs/a6/#proc-filesystem"
  },"78": {
    "doc": "Lab 6 - Networking 102",
    "title": "ARP configuration",
    "content": "The entries in the kernel’s arp cache can be read during system runtime via /proc/net/arp as mentioned above. Additionally, ARP can be configured with persistent static entries. This typically done via a file. Batches of static entries can be included in such a file. The line-by-line format should be &lt;mac-address&gt; &lt;ip-address&gt;. To load the file’s entries into the system’s ARP cache one can run arp -f &lt;file&gt;. Typically the file that holds these entries has the path /etc/ethers. Static ARP entries are cleared from the system ARP cache on reboot, meaning one would have to run the above command on each boot if we wanted the mappings to ‘persist’. To automate the procedure of running the command we can leverage the interface configuration workflow. Recall that /etc/network/interfaces provides the auto stanza to identify interfaces to be automatically configured on boot. Used in conjunction with the iface stanza and its post-up &lt;command&gt; option, we can execute the arp -f /etc/ethers command. This effectively has static entries ‘persist’ by having them added alongside interface configuration during boot. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#arp-configuration",
    "relUrl": "/labs/a6/#arp-configuration"
  },"79": {
    "doc": "Lab 6 - Networking 102",
    "title": "DNS configuration",
    "content": "Some of the DNS configuration files that we will be going over are /etc/hosts, /etc/resolv.conf, /etc/nsswitch.conf. /etc/hosts . This is simple text file that stores static mappings from IP addresses to hostnames. The format for each line is &lt;ip-address&gt; &lt;cannonical-hostname&gt; [aliases]. An example line would be 31.13.70.36 www.facebook.com fb ZuccBook . Thanks to this entry we have mapped www.facebook.com and any aliases we listed to 31.13.70.36. A very common example entry is localhost which also has the aliases ip6-localhost,ip6-loopback which explains why running something like ping localhost or ping ip6-loopback works. This file is one way to manually define translations for certain hostnames. /etc/resolv.conf . Whereas /etc/hosts is for static translations of specific hostnames, many times we want to dynamically resolve names by issuing a query to a name server. There are usually many nameservers, public or private, available to fufill such a query and deciding which ones to query is the job of /etc/resolv.conf amongst other configuration options. /etc/resolv.conf is the configuration file for the system resolver which is the entity that communciates with DNS name servers on your machine’s behalf. If this file does not exist, queries will default to the name server on your local machine. This file consists of one domain or search lines up to three nameserver lines and any number of options. Let’s dive into the details behind these configuration options. | domain Using this option will specific a local domain name. Short queries, which are queries that don’t contain any domain identifiers, then have the local domain appended to them during DNS queries. To understand this better take death as one of the machines within the OCF domain, ocf.berkeley.edu. One can issue a DNS query for death by typing dig death.ocf.berkeley.edu but that’s an awful lot to type. By specifying domain ocf.berkeley.edu in /etc/resolv.conf the query can be shortened to just dig death. In fact, any tool that takes a domain name can now use this shortened version, i.e. ping death. This is because your machine’s resolver is responsible for translating this domain name, and the domain configuration automatically appends the written domain to these short queries. | search The format for this option is search &lt;search-list&gt;. Using this options specifies a list of domain names to iterate through when attempting to look up queries. Let’s examine an example use case, imagine we owned two networks ocf.berkeley.edu and xcf.berkeley.edu and wanted to query a machine which may either be in either network. To enable this we can simply add the line search ocf.berkeley.edu xcf.berkeley.edu. Queries to resolve a domain name will now append those listed domains in order until a successful DNS response. If we assume death is on ocf.berkeley.edu and another machine, life, is on xcf.berkeley.edu, both dig death and dig life are now resolved properly thanks to our configuration. | . One thing to note is that search and domain are mutually exclusive keywords and having both defined causes the last instance to take precedence and override earlier entries. | nameserver The nameserver keyword is fairly self explanatory and follows the format of nameserver &lt;ip-address&gt; where &lt;ip-address&gt; is the IP address of the intended name server. One can have up to MAXNS (default 3) nameserver entries in this file. The resolver will query nameservers in the same order as they are written in the file. | . Following are additional useful configurable options in this file. Options are defined in this format options &lt;option1&gt; [additional-options]. Some example options follow below: . | ndots This option, formatted as ndots:n, configures the threshold,n, at which an initial absolute query is made. Since the default value for this option is 1, any name with at least 1 dot will first be queried as an absolute name before appending domains from search. When less than ndots are present, the queries automatically begin appending elements in &lt;search-list&gt;. Take death.ocf.berkeley.edu as an example, and let’s assume we have the following line search ocf.berkeley.edu in our configuration. Running ping death works because there are 0 dots in death and the query automatically appends search elements so that our query becomes death.ocf.berkeley.edu. If we instead ran ping death. the resolver will first issue a query for death. since it has 1 dot, which fails. | timeout This opton is in the format timeout:n and configures the amount of time n, in seconds, that a resolver will wait for a response from a name server before retrying the query via another name server. | attempts This option is in the format attempts:n and configures the number of attempts n that the resolver will make to the entire list of name servers in this file. | . /etc/nsswitch.conf . With multiple sources of information for resolving hostnames, one can’t help but wonder how the system decides which sources to query and in what order. This is answered with the /etc/nsswitch.conf file. It is this file’s responsibility to list sources of information and configure prioritization between sources. Similar information sources can be grouped into categories that are referred to as ‘databases’ within the context of the file. The format of the file is as follows: database [sources]. While this file provides configuration for a wide array of name-service databases, we will focus on an example relevant to the topic at hand. The hosts database configures the behavior of system name resolution. So far we have introduced two ways to resolve names: . | Using entries in /etc/hosts | Using a resolver to issue DNS queries to DNS name servers | . To let the system know about the above two sources of information there are corresponding keywords, files and dns, respectively. We can then configure name resolution by writing the line hosts: files dns The example syntax above tells the system to first prioritize files before issuing DNS queries. Naturally, this can be customized to best fit your use case. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#dns-configuration",
    "relUrl": "/labs/a6/#dns-configuration"
  },"80": {
    "doc": "Lab 6 - Networking 102",
    "title": "DHCP client configuration",
    "content": "The Internet Systems Consortium DHCP client, known as dhclient, ships with Debian and can be configured via /etc/dhcp/dhclient.conf. Lines in this file are terminated with a semicolon unless contained within brackets, like in the C programming language. Some potentially interesting parameters to configure include: . Timing . | timeout This format for this statement is timeout &lt;time&gt; and defines time to the maximum amount of time, in seconds, that a client will wait for a response from a DHCP server. Once a timeout has occured the client will look for static leases defined in the configuration file, or unexpired leases in /var/lib/dhclient/dhclient.leases. The client will loop through these leases and if it finds one that appears to be valid, it will use that lease’s address. If there are no valid static leases or unexpired leases in the lease database, the client will restart the protocol after the defined retry interval. | retry The format for this statement is retry &lt;time&gt; and configures the amount of time, in seconds, that a client must wait after a timeout before attempting to contact a DHCP server again. | . A client with multiple network interfaces may require different behaviour depending on the interface being configured. Timing parameters and certain declarations can be enclosed in an interface declaration, and those parameters will then be used only for the interface that matches the specified name. The syntax for an example interface snippet is: . interface &lt;iface-name&gt; { send host-name \"death.ocf.berkeley.edu\"; request subnet-mask, broadcast-address, time-offset, routers, domain-search, domain-name, domain-name-servers, host-name; [additional-declarations]; } . As mentioned above this file also supports defining static leases via a lease declaration. Defining such leases may be useful as a fallback in the event that a DHCP server cannot be contacted. The syntax for a example static lease is: . lease { # interface \"eth0\"; # fixed-address 192.33.137.200; # option host-name \"death.ocf.berkeley.edu\"; # option subnet-mask 255.255.255.0; # option broadcast-address 192.33.137.255; # option routers 192.33.137.250; # option domain-name-servers 127.0.0.1; # renew 2 2000/1/12 00:00:01; # rebind 2 2000/1/12 00:00:01; # expire 2 2000/1/12 00:00:01; #} . While the function of most keywords in the above snippet can be inferred from their syntax, more information can be found by simply reading the man page for this file (man dhclient.conf). ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#dhcp-client-configuration",
    "relUrl": "/labs/a6/#dhcp-client-configuration"
  },"81": {
    "doc": "Lab 6 - Networking 102",
    "title": "Sysadmin commands",
    "content": "ifupdown . ifupdowm is a simple suite of commands for interacting with network interfaces. The two commands you’ll be using most are ifup and ifdown which are relatively self-explanatory. ifup brings and interface up and vice versa for ifdown. These two commands should be your de facto commands for bringing interfaces up or down since using these commands loads configurations defined in /etc/network/interfaces. mtr . mtr is a command that combines the functionality of traceroute with that of ping. Take a look at this article for a good primer for using mtr and interpreting its output. iptables . In favor of not reinventing the wheel please check out these excellent and pretty short articles by DigitalOcean, who sponsored this semester’s offering of the decal by supplying us with VMs. | An Introduction to iptables | Adding rules | Deleting rules | Common rules and tips | . Checkpoint . Question 3a: If we preferred name resolution be done dynamically rather than using static entries in /etc/hosts what file do we need to edit and what is the line we should add? . Question 3b: Assume the following information: . | /etc/resolv.conf file has 3 nameserver entries and a options timeout:1 entry. | A successful DNS response takes 20 ms. You need to add the attempts:n option so that you retry a query as many times as possible but the total time to resolve a name, irrelevant of success or failure, takes less than 5 seconds. What should the value of n be? . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#sysadmin-commands",
    "relUrl": "/labs/a6/#sysadmin-commands"
  },"82": {
    "doc": "Lab 6 - Networking 102",
    "title": "Exercises",
    "content": "Now, let’s break things do some experimentation! Remember to submit your answers to Gradescope when you’re done. (Also, don’t forget to submit the checkpoint questions from the sections above!) . The files for these exercises can be found in the decal-labs repository. Clone it now: git clone https://github.com/0xcf/decal-labs . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#exercises",
    "relUrl": "/labs/a6/#exercises"
  },"83": {
    "doc": "Lab 6 - Networking 102",
    "title": "🔥 This is fine 🔥",
    "content": "This section will have you thinking like a sysadmin. IMPORTANT NOTE . Do not run the scripts directly in your student VM! These scripts are dangerous and will brick your VM so please follow the provided setup instructions. However, if you have physical access (or out-of-band management access) to a Linux machine, feel free to run the scripts directly and reboot when necessary, as all changes made are temporary. Each script might make changes to your network stack with the intent of damaging your machine’s connectivity. To confine the scope of the ‘attacks’, scripts will specifically try to alter your connectivity to google.com and ocf.berkeley.edu. Setup . | If you haven’t already, ssh into your student VM (username@username.decal.xcf.sh) and clone decal-labs. | Go into the vm directory: cd decal-labs/a6/vm | Get Virtualbox: sudo apt install virtualbox | Get Vagrant: curl -O https://releases.hashicorp.com/vagrant/2.2.6/vagrant_2.2.6_x86_64.deb then sudo apt install ./vagrant_2.2.6_x86_64.deb | Start a Vagrant instance: vagrant up | Enter your Vagrant instance: ssh vagrant@192.168.42.42. The default password is vagrant. | The decal-labs repo should be available in the Vagrant instance. If it isn’t there, you can sudo apt install git then clone it again. | cd decal-labs/a6/scenario. | . Problem Instructions . There should be 6 scripts, named 1.py to 6.py. Your task is to choose at least 3 of these to run and attempt to fix the problem that they cause (if any). Launch each script with sudo, i.e. sudo python3 &lt;script.py&gt;. For each script, follow this two step process. Only move onto another script once you have finished resolving your current one. | Analyze whether or not your connectivity has been damaged. If your stack has been damaged identify the issue or which part of your network is no longer functioning as intended. | If you concluded there was a problem, resolve the issue. What commands did you use and how did you conclude things were fully functional again? . Additionally, for each step you must explain the tools you used and how you came to your conclusions i.e. I ran example --pls --fix computer and I noticed that line 3: computer-is-broken meant my machine was f*****. This script damaged my ability to connect to google.com by poisoning my arp cache with bogus entries. | . Debugging Bank . I can’t ssh into my Vagrant instance! . | You might need to run vagrant provision and then re-run vagrant up. | Also, make sure you’re running ssh 192.168.42.42 and not vagrant ssh. | . I accidentally bricked something, how do I reset my Vagrant instance? . | Run vagrant destroy and then vagrant up in the vm folder. | . I’ve tried running vagrant provision a bunch of times and it never seems to work :( . | As an alternative to installing Vagrant on your student VM, you can also try installing it on your local machine. | . I accidentally ran the scripts in my student VM and not in the Vagrant instance and now I can’t log in. What do I do? . | You’ll need to ask us to reset your VM. Contact us in #decal-general or over email to arrange this. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#-this-is-fine-",
    "relUrl": "/labs/a6/#-this-is-fine-"
  },"84": {
    "doc": "Lab 6 - Networking 102",
    "title": "Net Ninjas (Optional)",
    "content": "Run this in your Vagrant instance. The file should be found in decal-labs/a6/. | The ninja has spent a few years training in a dojo and has mastered fireball (火球) jutsu. He can use his new skills to tamper with your network stack, incinerating your attempts to catch him. Run sudo python3 advanced_ninja_port.py. Fix the damage he has done and then successfully send him a found you message! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/#net-ninjas-optional",
    "relUrl": "/labs/a6/#net-ninjas-optional"
  },"85": {
    "doc": "Lab 6 - Networking 102",
    "title": "Lab 6 - Networking 102",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a6/",
    "relUrl": "/labs/a6/"
  },"86": {
    "doc": "Lab 7 - Networked Services",
    "title": "Table of contents",
    "content": ". | Overview | Which networked services are already running? | /etc/services | Questions . | NFS | DNS | Load Balancing . | Part 1: Configuration | Part 2: Health Checks | Some hints for Parts 1-2 | Part 3: Crashing | Extra Fun (optional questions) | . | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/#table-of-contents",
    "relUrl": "/labs/a7/#table-of-contents"
  },"87": {
    "doc": "Lab 7 - Networked Services",
    "title": "Overview",
    "content": "Networking is key to many services because it allows processes and computers to communicate with each other. In this lab, we’ll work with a couple different types of services and set up a service of your own from scratch! . Make sure, as always, that you are doing all of these steps on your provided DigitalOcean VM (available at yourusername@yourusername.decal.xcf.sh), as we have provided some resources for you to use for this lab that are only accessible from your student VMs. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/#overview",
    "relUrl": "/labs/a7/#overview"
  },"88": {
    "doc": "Lab 7 - Networked Services",
    "title": "Which networked services are already running?",
    "content": "Connect to your VM using SSH, and then run sudo netstat -plunt (or sudo netstat -peanut if you’d prefer) to show the services running on your VM already. You should see something like this: . Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 789/sshd tcp6 0 0 :::22 :::* LISTEN 789/sshd udp 0 0 10.138.132.55:123 0.0.0.0:* 792/ntpd udp 0 0 10.46.0.38:123 0.0.0.0:* 792/ntpd udp 0 0 159.65.76.196:123 0.0.0.0:* 792/ntpd udp 0 0 127.0.0.1:123 0.0.0.0:* 792/ntpd udp 0 0 0.0.0.0:123 0.0.0.0:* 792/ntpd udp6 0 0 fe80::b0a7:c1ff:fef:123 :::* 792/ntpd udp6 0 0 fe80::38c5:f3ff:fe0:123 :::* 792/ntpd udp6 0 0 ::1:123 :::* 792/ntpd udp6 0 0 :::123 :::* 792/ntpd . Why are there so many services already running? We haven’t even really done anything yet! Well, to start off with, sshd must have been running already, otherwise how would you have connected to the machine in the first place using SSH? However, the other service (ntpd) is a bit more mysterious. Let’s check it out! . $ man ntpd DESCRIPTION The ntpd program is an operating system daemon which sets and maintains the system time of day in synchronism with Internet standard time servers. It is a complete implementation of the Network Time Protocol (NTP) version 4, but also retains compatibility with version 3, as defined by RFC-1305, and version 1 and 2, as defined by RFC-1059 and RFC-1119, respectively. ntpd does most computations in 64-bit floating-point arithmetic and does relatively clumsy 64-bit fixed-point operations only when necessary to preserve the ultimate precision, about 232 picoseconds. While the ultimate precision is not achievable with ordinary workstations and networks of today, it may be required with future gigahertz CPU clocks and gigabit LANs. The last sentence of this description snippet above is pretty funny, because gigahertz CPU clocks and gigabit LANs are both pretty common these days! Anyway, as mentioned in the lecture and in the manpage description above, NTP is used for time synchronization on a computer using network time servers, so it would make sense for this to already be running to allow your VM to always have the correct system time. This is especially important for VMs compared to using unix on a physical system. VMs can often be quite far off in terms of system time if NTP is not running (if they are suspended and then later resumed for example, or if the host for the virtual machine is under heavy load). Here’s a pretty awesome post with a list of falsehoods that programmers believe about time, there’s a surprising number of them. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/#which-networked-services-are-already-running",
    "relUrl": "/labs/a7/#which-networked-services-are-already-running"
  },"89": {
    "doc": "Lab 7 - Networked Services",
    "title": "/etc/services",
    "content": "One tip that might help when trying to find what a service does is to look at which port it is listening on. For instance, from above, ntpd is listening on port 123. If you open the file /etc/services on most unix machines, you will get a list of protocols and the ports they typically use. Here are the lines for the port that ntpd is using: . ntp 123/tcp ntp 123/udp # Network Time Protocol . This helps make it clearer that ntpd is most likely doing something with the Network Time Protocol, which in this case was pretty clear, however, if you have not seen the service before then /etc/services can be more useful. Keep in mind that any port can be used by any service but by convention they follow the mapping in /etc/services. Also keep in mind that for higher numbered ports (above 1024), that they can be used by any user if a service is not running on the port already, so this can be a security risk if you do not properly secure these ports. That being said, most people follow convention if possible to make their services easier to maintain, so checking /etc/services is a good first step if trying to figure out what a specific port/service is for. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/#etcservices",
    "relUrl": "/labs/a7/#etcservices"
  },"90": {
    "doc": "Lab 7 - Networked Services",
    "title": "Questions",
    "content": "To submit the lab, answer the questions on Gradescope. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/#questions",
    "relUrl": "/labs/a7/#questions"
  },"91": {
    "doc": "Lab 7 - Networked Services",
    "title": "NFS",
    "content": "We have provided a NFS server for you to connect to at staff2.decal.xcf.sh with two different directories, one read-only and one read-write. First, install the nfs-common package so that you can mount directories over NFS. Then, use the mount command (remember to look at the man pages or search online if you do not recognize a command) to mount from staff2.decal.xcf.sh:/opt/lab7/public (the remote directory) to your local directory at /mnt/. Once you do this, you should see a file with a secret inside it in /mnt. You can tell if you are connected or not by running df and checking if there is something that looks like staff2.decal.xcf.sh:/opt/lab7/public present in the list. What is the secret in the file? . If NFS takes a excessive time to mount or you cannot read the file because it hangs while doing so, please let us know. Try creating a file in the read-only directory (note that you will want to try with sudo, otherwise you will get a permission denied error because root owns the directory mounted over NFS) . If you’d like to disconnect again, make sure you are not in the directory that has the file (otherwise it is unable to disconnect because it is still loaded and you will get an error message like umount.nfs4: /mnt: device is busy). Then use umount to disconnect from NFS. If you run df, you should see that the entry that was present before has now disappeared. Now, let’s unmount the filesystem (try to figure out how) so that we can mount a different directory, at staff2.decal.xcf.sh:/opt/lab7/private/&lt;your username&gt; using mount in a similar way to before. What do you see in /mnt/ now? . Follow the instructions in the file given there. note that you will have to use sudo here too to create a new file since the directory mounted over NFS is owned by root, not your user. Again, if NFS takes an excessive time to mount during any of this or you cannot read files because it hands while doing so, please let us know on Slack or by email (or at office hours if you’d prefer). We’ve had some problems in the past with NFS being very slow to mount/read and needing a restart. | Question 1a. What command did you use to mount the read-only NFS directory? . | Question 1b. What is the secret word in the read-only (public) NFS share? . | Question 1c. What line does the df command show at the bottom when you have the read-only NFS directory mounted? . | Question 1d. What error is given if you try to create a file in the read-only NFS file system? (any similar error message is fine, there are a large variety of ways to create files) . | Question 1e. What command did you use to unmount the read-only NFS directory? . | Question 1f. What item did you add in the private NFS directory? (/opt/lab7/private/&lt;your username&gt;) We can check this from the NFS host, so make sure the text file exists with your answer! . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/#nfs",
    "relUrl": "/labs/a7/#nfs"
  },"92": {
    "doc": "Lab 7 - Networked Services",
    "title": "DNS",
    "content": "In this section we are going to be setting up our own DNS server! Remember that DNS is the system that maps from a domain like ocf.berkeley.edu to an IP like 169.229.226.23 (and 2607:f140:8801::1:23 for IPv6) so that computers know how to send information over the network to servers without people having to remember a bunch of numbers to connnect to everything. A more thorough description of this is in Lab 6 if you’d like a refresher or want more information. First, install the bind9 package on your VM to set up a DNS server. Let’s check the status of the service using systemctl. What command can you run to do this? . In the output of the systemctl command, you should see that the bind9 service is already running. Let’s bring it down temporarily so we can investigate: systemctl stop bind9 . The service should have a unit file at /lib/systemd/system/named.service or /lib/systemd/system/bind9.service. If you print that file (with cat or systemctl cat bind9), you should see something like this: . [Unit] Description=BIND Domain Name Server Documentation=man:named(8) After=network.target Wants=nss-lookup.target Before=nss-lookup.target [Service] EnvironmentFile=-/etc/default/named ExecStart=/usr/sbin/named -f $OPTIONS ExecReload=/usr/sbin/rndc reload ExecStop=/usr/sbin/rndc stop [Install] WantedBy=multi-user.target Alias=bind9.service . This should look pretty familiar to you after the lecture on services! Don’t worry if it doesn’t all look familiar since there are some options you haven’t seen yet in here, but you should at least recognize some of the options used. If you now run dig ocf.berkeley.edu @localhost from your VM, you should see that the command eventually times out after trying to run for about 15 seconds. This is because it is trying to send DNS requests to your VM, but the DNS server is not actually running yet so it doesn’t get a response. However, if @localhost is left off the end of the command, it succeeds. Why is this the case? What DNS server are requests currently being sent to if @localhost is not specified in the command? . Try starting the DNS server using the relevant systemctl command. If you check the status of the bind9 service after starting it, you should see the status has changed to say that the service is active and running. If you now run dig ocf.berkeley.edu @localhost from your VM, you should now see a response containing the correct IP (169.229.226.23)! . Make sure to add port 53 to be allowed through your firewall with ufw (set up in lab a4) if you would like to access your DNS server from outside your VM. Now to the exciting part, the configuration! Edit /etc/bind/named.conf.local with your favorite text editor. Inside this file, it should be empty apart from a few comments at the top because you haven’t done any local configuration yet. Add a new zone in this file for example.com with these contents: . zone \"example.com\" { type master; file \"/etc/bind/db.example.com\"; }; . Then, create a file /etc/bind/db.example.com to contain the responses to give if anyone sends requests to your DNS server for example.com. The easiest way to do this is generally to copy an existing config and then make changes from there to get what you want for your config instead of having to start from scratch. To make this easier, we’ve provided a valid config in decal-labs that you can copy in place at /etc/bind/db.example.com. You’ll need to edit the config to include your VM’s IP address and domain name! . This config includes a subdomain that does not usually exist, named test.example.com. Please add few more records of your choice. Try to add one A record, and a couple of other types of records (CNAME, SRV, TXT, etc.). Make sure to reload the bind9 service after changing anything in /etc/bind9, since you want the running service to change its configuration. If you now run the dig commands below, you should see that your VM’s domain name (&lt;username&gt;.decal.xcf.sh) is returned for the first result, for the second result (example.com) your VM’s IP address should be returned, and for test.example.com you should see 93.184.216.34 as the result. Make sure to run these commands from your VM, or if you want to run them from your laptop or from an OCF computer, substitute localhost in any commands with your VM’s domain name (it’ll be in the format &lt;username&gt;.decal.xcf.sh). | Question 2a: What is the systemctl command to show whether bind9 is running or not? . | Question 2b: Why does the dig command (dig ocf.berkeley.edu) work if @localhost is not present at the end (if bind9 is not started) but times out when @localhost is added? . | Question 2c: What DNS server are requests currently being sent to on your VM if you don’t include @localhost in dig? . | Question 2d: What additional entries did you add to your DNS server config (the db.example.com file)? . | Question 2e: What commands did you use to make requests to the local DNS server for your additional entries? . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/#dns",
    "relUrl": "/labs/a7/#dns"
  },"93": {
    "doc": "Lab 7 - Networked Services",
    "title": "Load Balancing",
    "content": "For this section we will be using HAProxy, a commonly-used open-source load balancer. NGINX is actually starting to become a load balancer alongside being a web server, which is pretty interesting, but HAProxy is still commonly used. You can install HAProxy using sudo apt install haproxy. First, grab the python file for the service you will be running from the decal-labs repo using wget or something similar to download it. You’ll likely also need to install tornado using sudo apt install python3-tornado. When run (python3 server.py), this script will start up 6 different HTTP server workers listening on ports 8080 to 8085 (inclusive). Each worker returns different content to make it clear which one your are talking to for this lab (“Hello, I am ID 0” for instance), but in real usage they would generally all return the same content. You would still want something to distinguish between them (maybe a HTTP header saying which host or instance they are?), but only for debugging purposes, not like in this lab where they have actually differing content. The idea behind using a load balancer is that requests will be spread out among instances so that if a lot of requests are coming in all at once, they will not overload any one instance. Another very useful feature is that if one of the instances happens to crash or become unavailable for whatever reason, another working server will be used instead. This requires some kind of health checks to be implemented to decide whether a server is healthy or not. Your job is to do the configuration to get it to work with the services you are given! The main config file is at /etc/haproxy/haproxy.cfg and you should only have to append to the end of this file to finish this lab. One snippet is provided here for you to add to the config already, this will give you a nice status page that you can use to see which of the servers is up or down: . listen stats bind 0.0.0.0:7001 mode http stats enable stats hide-version stats uri /stats . Make sure to add ports 7000 and 7001 to be allowed through your firewall with ufw (set up in lab a4) to allow access to your load balancer server and the stats page from other computers. After adding this, if you restart the haproxy service and open http://&lt;username&gt;.decal.xcf.sh:7001/stats in a web browser, you should see a page with a table and some statistics information on HAProxy (pid, sessions, bytes transferred, uptime, etc.). Part 1: Configuration . Your goal is to add a backend and frontend to haproxy’s config that proxies to all of the running workers on the ports from 8080 to 8085 and listens on port 7000 on your VM, so that if you go to http://&lt;username&gt;.decal.xcf.sh:7000 you can see the responses from the workers. Try refreshing, what do you notice happening? Do you notice a pattern? What load balancing algorithm are you using from your observations? What config did you add to the haproxy config file to get this to work? . Part 2: Health Checks . Now, after adding all the servers to the backend in the config, add health checks for each of them. If you refresh the stats page, what do you notice has changed? What color are each of the servers in your backend? . Some hints for Parts 1-2 . | You shouldn’t need to change the current contents of haproxy.cfg; you’ll just need to append additional lines to the bottom of the file. | You’ll need to add two sections, one for frontend and one for backend. Take a look at the Frontend and Backend sections of The Four Essential Sections of an HAProxy Configuration to learn more about the syntax and options available! | You can label your frontend and backend sections however you wish. | You should need to append about 10-15 lines to the config file. | If you’d like more hints, feel free to ask on #decal-general! | . Part 3: Crashing . If you make a request to http://&lt;username&gt;.decal.xcf.sh:7000/crash, it will crash the worker that you connect to. What changes in the HAProxy stats page? (Try refreshing a few times, the health checks can take a couple seconds to update the status from UP -&gt; DOWN) If you make a lot of requests to http://&lt;username&gt;.decal.xcf.sh:7000 again, are all the servers present in the IDs that are returned in your requests or not? Try crashing a particular worker by running curl localhost:&lt;port&gt;/crash, substituting the port with one of the workers that is still up on your instance. What happens on the HAProxy stats page? If you crash all the workers, what status code does HAProxy return to you when you make a request to the service? . | Question 3a: Do you notice any pattern when you refresh the page multiple times? . | Question 3b: What load balancing algorithm are you using? . | Question 3c: What did you add to the haproxy config? (just copy and paste the lines you added to the bottom into here) . | Question 3d: What do you notice has changed on the stats page after adding health checks? What color are each of the servers in the backend now? . | Question 3e: What changes in the stats page when you crash a worker? What happened to the pattern from before? . | Question 3f: What HTTP status code (or error message) does HAProxy return if you crash all of the workers? . | . Extra Fun (optional questions) . Make sure to add port 53 to be allowed through your firewall with ufw (set up in lab a4) if you would like to access your DNS server from outside your VM. Once you have set up your DNS server, try changing your laptop’s settings to use your VM as a DNS server and navigate to http://example.com:7000 and you should see the load-balanced services you set up. Also try navigating to test.example.com. What type of error do you see? Why do you think that this causes a error and does not display the page that http://example.com normally shows even though example.com resolves to the IP that you used (93.184.216.34)? . Also note that your DNS server is set up to only accept queries, especially recursive queries, from within Berkeley networks. If you try to use it off-campus somewhere, you will not be able to make queries to your DNS server. This is because open relays are a security problem that can be abused by attackers, so we’ve restricted your DNS server to only accept queries from specific IP ranges that are more likely to be safe. Again, remember to submit your answers on Gradescope! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/#load-balancing",
    "relUrl": "/labs/a7/#load-balancing"
  },"94": {
    "doc": "Lab 7 - Networked Services",
    "title": "Lab 7 - Networked Services",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a7/",
    "relUrl": "/labs/a7/"
  },"95": {
    "doc": "Lab 8 - Configuration Management",
    "title": "Table of contents",
    "content": ". | The Setting | Aside: Installing Puppet on your student VM | Your task, in plain English | Hints (if you need them) | Extra fun (completely optional) | Submission | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a8/#table-of-contents",
    "relUrl": "/labs/a8/#table-of-contents"
  },"96": {
    "doc": "Lab 8 - Configuration Management",
    "title": "The Setting",
    "content": "You’re suddenly awoken by an alarm. Still drowsy from sleep, you check the time on your phone. 7:00am?? you think to yourself. No way. I don’t even have any 8ams. In fact, I haven’t woken up this early since… Looking back at your phone again, which you realize is now 2 times thicker and suddenly has a 3.5mm audio port, you check the year. You may have thought Berkeley was hell, but now you’ve traveled back in time for some true suffering: high school. After getting dressed and lamenting your disastrous teenage fashion sense, you get a text message on your dumb phone. Sighing, you open it even though it’s going to cost you 10 cents. FROM: 5cr1p7k1dd1337 MSG: w31c0m3 b4ck t0 h1ghsk00l. i h4v3 a t45k f0r j00: j00 mu5t 1n5ta11 th3 f0ll0w1ng 5cr1p7 0n 3v3ry c0mput3r 1n j00r sk00l by the 3nd 0f t0d4y, 0r j00l b3 5tuCk 5ever. j00r sk00l u535 puppet, s0 j00 c4n ju57 wr1t3 a m0dul3 f0r th15. F1l3s R @ https://github.com/0xcf/decal-labs 1n a8/ . Rubbing your eyes, you try to understand 5cr1p7k1dd1337’s arcane runes once again: . Welcome back to high school. I have a task for you: you must install the following script on every computer in your school by the end of today, or you'll be stuck forever. Your school uses puppet, so you can just write a module for this. Files are in the decal-labs repo (https://github.com/0xcf/decal-labs) in the a8/ directory. Great, you think to yourself, good thing I’m currently taking the best DeCal at UC Berkeley, the Linux SysAdmin DeCal! This is gonna be a piece of cake. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a8/#the-setting",
    "relUrl": "/labs/a8/#the-setting"
  },"97": {
    "doc": "Lab 8 - Configuration Management",
    "title": "Aside: Installing Puppet on your student VM",
    "content": "In order to save yourself from your circumstances, you’ll need to set up Puppet on your student VM so you can test your changes. Luckily, we’ve provided a snippet of code to install the Puppet agent. Run the following block of code on your VM: . wget https://apt.puppetlabs.com/puppet6-release-bionic.deb &amp;&amp; \\ sudo dpkg -i puppet6-release-bionic.deb &amp;&amp; \\ sudo apt-get update &amp;&amp; \\ sudo apt-get -y install puppet-agent . Puppet will automatically add itself to PATH, but you may have to relog into your VM for this to take effect. Afterwards, ensure you can run puppet, and you should be good to go! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a8/#aside-installing-puppet-on-your-student-vm",
    "relUrl": "/labs/a8/#aside-installing-puppet-on-your-student-vm"
  },"98": {
    "doc": "Lab 8 - Configuration Management",
    "title": "Your task, in plain English",
    "content": "You need to write a puppet module that places a script hack_everything into /usr/local/bin/ and sets up a cronjob to run the script repeatedly and append its output to a file. Your module will need to install the dependencies for the script and ensure that all of the pieces are installed correctly. There are three main parts you’ll need to work on: . | Installing the packages the script depends on | Placing the script in the right directory, and placing a file the script depends on in the right directory | Setting up cronjob to run the script every 30 minutes and append its output to a file | . We’ve provided skeleton code for you in the decal-labs repository in a8, so make sure to git pull the latest version! The script hack_everything is located in a8/modules/hacked/files/hack_everything. The only file you need to change is in a8/modules/hacked/manifests/hacked.pp. We’ve included some hints and points to relevant documentation that will help you complete this manifest. Although we are only applying your manifest on one machine (your DeCal VM), you could, in theory, apply this module on thousands of machines that are connected to a puppet-master! How neat is that! . While you’re writing the manifest, there’s an easy way to check your syntax: you can use the command puppet parser validate hacking.pp. Once you have completed your manifest, you can apply the changes to your system with this command (assuming you cloned decal-labs into $HOME): . sudo env \"PATH=$PATH\" puppet apply --modulepath=$HOME/decal-labs/a8/modules $HOME/decal-labs/a8/manifests/default.pp . Basically, we’re running puppet locally on the module we just created. default.pp is just a file that includes the hacked module you’re editing, and we need to be sure to include the path to the modules so puppet can find them. The weird little env part is due to a Debian security feature known as secure_path, which resets your PATH when you run sudo. Since puppet is not in this list of default paths, running it with regular sudo won’t work. Once this is done, you should be able to run the command hack_everything (as the script is now in your path). Try it out! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a8/#your-task-in-plain-english",
    "relUrl": "/labs/a8/#your-task-in-plain-english"
  },"99": {
    "doc": "Lab 8 - Configuration Management",
    "title": "Hints (if you need them)",
    "content": ". | The skeleton code has links to relevant docs. You should clone/download the decal-labs repository if you haven’t already. | Here is an example puppet manifest that might be helpful. | More hints are available at live lab or by asking on #decal-general! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a8/#hints-if-you-need-them",
    "relUrl": "/labs/a8/#hints-if-you-need-them"
  },"100": {
    "doc": "Lab 8 - Configuration Management",
    "title": "Extra fun (completely optional)",
    "content": "Using your knowledge of config management, you might like to try any of the following: . | Self-host something from awesome-selfhosted by writing a Puppet config file | Try out another config management tool like Ansible and consider how they differ. | Check out the OCF Puppet repository, and submit a PR! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a8/#extra-fun-completely-optional",
    "relUrl": "/labs/a8/#extra-fun-completely-optional"
  },"101": {
    "doc": "Lab 8 - Configuration Management",
    "title": "Submission",
    "content": "Congratulations on finishing the lab! . To submit, upload hacking.pp into the Gradescope submission. (You do not need to upload the rest of the files in the skeleton, just the one file!) . Providing feedback: Since the submission consists entirely of the single file upload, there is no dedicated feedback question. Please leave your comments in the bottom of hacking.pp - there should be a section in the skeleton with more instructions. Thanks! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a8/#submission",
    "relUrl": "/labs/a8/#submission"
  },"102": {
    "doc": "Lab 8 - Configuration Management",
    "title": "Lab 8 - Configuration Management",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a8/",
    "relUrl": "/labs/a8/"
  },"103": {
    "doc": "Lab 9 - Security",
    "title": "Table of contents",
    "content": ". | Overview . | Getting help | . | Threat Models . | Example: Safekeeping | Task 1: Construct your own threat model | . | Security Building Blocks . | Encryption . | A Brief Introduction | Types of Encryption . | Symmetric Key Cryptography | Public Key Cryptography | . | . | Signatures and Certificates | Hashing | . | Encryption Lab Activity . | Submission | Introduction: Making SSH keys | Warm-up Task | Task 2 - Symmetric Encryption | Task 3 - Asymmetric Encryption | Task 4 - Hashing | File Security . | File Security and Permissions | Task 5 - File Security | . | Network Security . | Task 6 - Network Security Lab Activity | . | Optional Task: Letsencrypt on an nginx instance! | . | Footnotes | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#table-of-contents",
    "relUrl": "/labs/a9/#table-of-contents"
  },"104": {
    "doc": "Lab 9 - Security",
    "title": "Overview",
    "content": "In this lab, we will cover a variety of topics that are of interest to those studying computer security. We will go much more in depth than you need to know, so we hope you pick up the main practical concepts and dig deeper if you are interested. There are many aspects to security, and the field spans a number of disciplines. We will cover the following: . | Threat Models | Security Building Blocks . | Encryption - Symmetric and Public-Key Crypto | Certs, Signatures | Hashing | . | File Security | Network Security | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#overview",
    "relUrl": "/labs/a9/#overview"
  },"105": {
    "doc": "Lab 9 - Security",
    "title": "Getting help",
    "content": "If you want any help with any part of this lab, join the OCF slack/discord (https://ocf.io/slack), and post your questions in #decal-general. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#getting-help",
    "relUrl": "/labs/a9/#getting-help"
  },"106": {
    "doc": "Lab 9 - Security",
    "title": "Threat Models",
    "content": "The most important thing to remember when designing secure systems is understanding your threat model. No system is guaranteed to be secure or able to withstand all attacks, nor is this even possible in the face of extreme adversaries. However, you can (and should) take precautions against the threats you are likely to face. Balancing the need for authorized users to get access to the system while keeping unauthorized users out is very easy to get wrong. Fortunately, smart people have distilled the principles of security down to a few axioms, covered very well in the first lecture note of CS 161 (credit to Prof. David Wagner). It is recommended to read the lecture note. When constructing a threat model, keep questions such as these in mind: . | What are you protecting? | Who are your adversaries? | How likely is it you will need to protect it? | What are the consequences of failing to protect it? | How many resources should you devote to protecting it? | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#threat-models",
    "relUrl": "/labs/a9/#threat-models"
  },"107": {
    "doc": "Lab 9 - Security",
    "title": "Example: Safekeeping",
    "content": "Let’s say that you run a safe storage facility for customers to store a variety of valuables. Here’s a description of what your threat model might look like: . In this scenario, you’re responsible for your clients’ valuables. There are a multitude of adversaries, including burglars ranging from smash-and-grab to more sophisticated attackers, disgruntled employees, clients looking to claim fradulent loss, and natural disasters such as earthquakes, fires, or tornados. Storage facilties containing potentially high amounts of valuables in close proximity to each other may serve as enticing targets for attackers and failing to protect the facility would result in a loss of trust that would be devastating for a business. In order to protect against burglars, an variety of protections can be enabled from increased surveillance to 24/7 guards. The rational amount of security depends on the level of desired profit and likelihood of a break-in. Allowing clients to install their own security protects allows them protection against both disgruntled employees and acts as a protection mechanism against fradulent clients. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#example-safekeeping",
    "relUrl": "/labs/a9/#example-safekeeping"
  },"108": {
    "doc": "Lab 9 - Security",
    "title": "Task 1: Construct your own threat model",
    "content": "You’re a journalist criticizing the local authoritarian government and trying to get your story to ProPublica. Considering the principles of security and the above questions, describe your threat model and how you would safely deliver the information. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#task-1-construct-your-own-threat-model",
    "relUrl": "/labs/a9/#task-1-construct-your-own-threat-model"
  },"109": {
    "doc": "Lab 9 - Security",
    "title": "Security Building Blocks",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#security-building-blocks",
    "relUrl": "/labs/a9/#security-building-blocks"
  },"110": {
    "doc": "Lab 9 - Security",
    "title": "Encryption",
    "content": "A Brief Introduction . Hiding information from unauthorized users is a critical element of computer security. How can you make sure we can keep this information hidden in the case that we have to send it out into the open? . Here’s where the power of encryption comes in. Encryption involves taking the information you want to hide, called the plaintext, and scrambling it into a format that can only be read with a key called the ciphertext. Types of Encryption . There are many different types of encryption algorithms, with different types of encryption keys, encryption speeds, security, and usefulness. The most important quality of encryption algorithms is the fact that they are one-way: it is easy to compute the ciphertext from the plaintext (encrypt) but extremely difficult to compute the plaintext from the ciphertext (decrypt) without the secret key. There are two primary types of encryption: symmetric key cryptography, and asymmetric-key or public-key cryptography. The invention of public key cryptography was critical to many of the security features we take for granted today. For the purpose of this lab, we will be using several tools for performing encryption operations, among them GnuPG, a free implementation of the OpenPGP standard, and OpenSSL, a library for implementing TLS, or Transport Layer Security. Symmetric Key Cryptography . Symmetric-key cryptography is named for the fact that a single key both encrypts and decrypts a particular plaintext to ciphertext and vice-versa. The most widely used method of symmetric crypto is AES, or Advanced Encryption Standard, which is certified and trusted by the US Government to encrypt information critical to national security. An easy way to visualize the basics of symmetric key crypto is by the XOR function: a XOR b is true if and only if a and b are different. Suppose our plaintext is the bitstring 100110100101, and we want to apply a bitwise XOR with the bitstring 010010100010, which is our key. The result of this operation is 110100000111. If we XOR the resulting ciphertext with the key again, we get the original plaintext: 100110100101. The XOR function is trivially reversible, but military-grade symmetric key cryptography algorithms are much more difficult to reverse. The security of symmetric-key crypto, therefore, is dependent on keeping the encryption key secret. Symmetric key crypto is useful for almost everything, especially things that fall in these categories: . | Encrypting data in transit (such as HTTPS) | Encrypting data at rest (like data stored on your phone) | . As an example, let’s explore how iPhones use encryption to keep your data safe: . | The iPhone’s internal storage is encrypted with a set of AES keys stored on a chip inside the phone, generated at the factory. | These keys are in turn encrypted with your PIN. Your PIN allows the phone to unlock the keys that allow it to decrypt the rest of the filesystem. | . This is how the iPhone is able to quickly wipe your data in the event your phone is stolen: the phone simply deletes the keys that are stored on the internal chip. Now, even with your PIN, there are no keys to decrypt and the encrypted data in the phone’s storage is, for all intents and purposes, irretrievable and indistinguishable from random data. Public Key Cryptography . Unlike symmetric key cryptography, there are 2 keys in a public-key cryptosystem, the public key and the private key. As the name suggests, the public key is shared publicly, and this is the means by which other people encrypt data that’s meant for you. You use your private key to decrypt this data. As long as no one has your private key, anyone can use your public key to encrypt data and be assured that only you can decrypt it. This is a powerful expansion on the symmetric-key paradigm, as beyond encryption, it also allows for signatures and non-repudiation: a way for someone to verify that the person they are talking to is in fact the person they intend to be talking to, and for someone to prove (without the ability to deny it) that they are who they say they are. Nowadays, public-key cryptography is synonymous with the RSA algorithm, which was one of the first proven dual-key schemes. (You will encounter the RSA algorithm in CS 70 and CS 161 if you plan to take those courses, or already have.) In short, the security of RSA depends on the theoretical difficulty of factoring large numbers on conventional computers. This is expected to continue to be a difficult problem until quantum computers become practical. Here’s a brief overview of how RSA public key crypto works: . | The RSA algorithm, by means of some advanced mathematics (involving prime numbers and modular arithmetic), returns 3 numbers: a public exponent (aka key), a private exponent, and a modulus. The two keys work such that data encrypted with one key can only be decrypted with the other key. | In order to encrypt data, one performs modular exponentiation over the data using one of the exponents and the modulus. | In order to decrypt data, one performs modular exponentation on the encrypted data with the partner key and modulus. In common use, one uses the larger exponent as the private key, which is used for decrypting data and creating signatures, and the smaller exponent as the public key, which is used for encryping data and verifying signatures. | . In lab a4, one task was to generate an SSH key, using the command: . ssh-keygen -t rsa -b 4096 . This command would generate two files, ~/.ssh/id_rsa and ~/.ssh/id_rsa.pub. As the command suggests, this command generates a 4096-bit RSA key pair. You should be able to guess which file represents the public key and which one must therefore be the private key. In order to affect secure SSH logins using the RSA key, the user must first transfer the public key they wish to use to identify themselves to the server in advance. Then, once a session has been established between the server and the client, the server will encrypt a random number with the user’s public key and transmit it to the user. The user will then decrypt the value using their private key and return a hash of that value to the server, who can then hash the value themselves to determine if the user was able to successfully decrypt the random number, thus indicating posession of the matching secret key and serving as proof for authentication. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#encryption",
    "relUrl": "/labs/a9/#encryption"
  },"111": {
    "doc": "Lab 9 - Security",
    "title": "Signatures and Certificates",
    "content": "Public key cryptography allows for a number of important security objects, including signatures and certificates for digital identity verification. Suppose you are an important public entity (maybe your pseudonym is Natoshi Sakamoto). You are in charge of an important project, hereafter known at Litcoin. You’d like to maintain anonymity, but still need to lead your project. How can your loyal followers know that statements supposedly made by Natoshi Sakamoto are actually from you? . There’s a significant incentive to make false statements supposedly “from” Mr. Sakamoto, because each Litcoin is apparently worth a significant amount of real money, and some people stand to gain substantially if they are able to influence the direction of the project in their favor. You can avoid this by signing your messages: in the beginning, you would publish Natoshi’s public key, and thereafter, for every post you make, you would encrypt the content of the message using your (Natoshi’s) private key and post that along with your original message. Then, anyone who wants to verify that Natoshi (i.e. the owner of the private key corresponding to the public key that belongs to Natoshi) did in fact publish a particular message can simply use Natoshi’s public key to decrypt the encrypted signature and compare the content against the original message. Pretenders to Natoshi’s throne will be unable to sign their false statements such that they can be verified with Natoshi’s published public key because they don’t have Natoshi’s private key, and you can rest assured that no one will unduly influence your project in your name while you go into hiding from the IRS and DEA, unless they happen to have warehouses full of ASICs and lots of cheap electricity. However, in this scheme, how do you prevent an adversary from publishing a fake public key and claiming to be you? (they can make valid signatures against that fake public key) Somehow, you need to “bootstrap” trust: someone would need to verify your identity and publicly affirm that your public key actually corresponds to you. We do this by means of certificates: a signed statement claiming that a particular public key does, in fact, belong to who it claims to belong to. Who signs this certificate? A certificate authority, someone we trust to be responsible about verifying identities and issuing signatures. But how do we know which CAs to trust, and how can we trust that a CA that claims to be trustworthy actually is? They probably need a certificate as well. It sounds like it might be turtles all the way down; however, the chain does end somewhere: the so-called root of trust, the root CAs. These are the CAs whose certificates are pre-installed by browsers and operating systems and therefore intrinsically trusted, without any further certificates necessary. If a root CA signs your certificate, we assume they’ve done the due diligence necessary to be willing to risk their reputation by signing your certificate, and basically take their word for it. This model, known as the Web of Trust, is how network security works today. Unfortunately, it isn’t as reliable as we may have hoped: some CAs are scummy and will sign anything for enough money, resulting in valid certificates being issued for domains like microsoft.com and github.com to entities who are very obviously not Microsoft or GitHub.1 Furthermore, any entity with enough border control can force the installation of their own root certificates (e.g. the government of Kazakhstan2) and intercept any traffic by issuing their own bogus certificates for any domain. You might not realize it, but you use and rely on certificates and signatures every day. Any time you see a green lock near the address bar of a website you visit, you are accesssing the site over a TLS or HTTPS connection, and the data being transferred between you and the website is encrypted. When your browser connects to the website’s server, it asks for the server’s public key in order to set up an encrypted connection, and the server’s certificate in order to verify its identity as the server authorized to serve the domain you have requested. Your browser then validates the public key by verifiying the signatures on the certificate. If someone is attempting to perform a man-in-the-middle attack on you, this certificate verification step will fail, because it should be unlikely that a trusted CA will have issued a signed cert for your domain to an entity other than you (unless you have the misfortune of living in Kazakhstan). You will get a very intrusive notification informing you of this fact, and it is a bad idea to ignore the certificate verification failure notification. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#signatures-and-certificates",
    "relUrl": "/labs/a9/#signatures-and-certificates"
  },"112": {
    "doc": "Lab 9 - Security",
    "title": "Hashing",
    "content": "There are many times where we have large amounts of data but need to operate on smaller representations of that data. For example, suppose you download a 1GB file from the internet. You want to make sure that the file you downloaded has not been modified on its way to you (after having taken the DeCal, you know that integrity is a critical goal of computer security). How could you figure out if the file has been changed? You could try downloading another copy to see if there’s a difference, but both copies could have been modified, and it takes a long time to download 1GB. You could use your knowledge of signatures to see if the source has provided a signature of the file you could verify, but the signature would have to be over the whole file3 and this is even more expensive. What we really need is a deterministic way to generate fixed-length representations of arbitrary-length data. Luckily, mathematics has our back with functions known as hash functions. If you took CS 61B, you probably implemented a hash table at some point, and may be familiar with the concept. Here’s an example of hash functions at work. Enter the following commands on your student VM (i.e. ssh username.decal.xcf.sh) to calculate the SHA14 hash of a 40MB file. | wget https://raw.githubusercontent.com/0xcf/decal-labs/master/a9/lab9.jpg | sha1sum lab9.jpg | . You should see 685e925838358fdc162935588c6ee0aa5a5caed6, a 40-digit string. As you can imagine, transferring this string is much easier than transferring a large, 100MB file, and because of the properties of the SHA-1 algorithm, you can be reasonably sure that this file, and only this file, will always hash to that particular value. This means, if you want to verify that the file you downloaded hasn’t been corrupted, you can simply compare the hashes (or more specifically, a signature over the hash) to ensure that the file you’ve downloaded hasn’t been tampered with. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#hashing",
    "relUrl": "/labs/a9/#hashing"
  },"113": {
    "doc": "Lab 9 - Security",
    "title": "Encryption Lab Activity",
    "content": "In this lab, we will be exploring the topics covered so far: symmetric encryption and public key cryptography, hashing, signatures, and certificates. Please make sure you are logged into the appropriate server over ssh prior to completing any of the following tasks. Submission . Remember to submit your answers to Gradescope as you complete the lab! . Introduction: Making SSH keys . We’ll begin our exploration of security building blocks by creating SSH keypairs for ourselves, in case you haven’t already. If you already have an SSH key on your personal computer that you would like to continue to use, or one on tsunami, feel free to skip these steps and proceed to task 1, but please make sure that you can use that key to log into your student VM. As mentioned earlier in this document, and in lab a4, here is how to create a 4096-bit RSA SSH keypair: . | Log into tsunami.ocf.berkeley.edu with your OCF account credentials (potentially not the same as your decal VM credentials). It is important you do these steps on tsunami and not your laptop, an OCF desktop, or your decal VM. | Check to make sure you do not have an existing SSH key: . | Enter ls -l ~/.ssh | If you see files like id_rsa or id_rsa.pub then you already have an SSH key. | . | If no key is present, create a new key now by typing ssh-keygen -t rsa -b 4096, and hit enter when prompted. | If you are asked to type a password to protect the key, you may choose to enter one, but for the purpose of this lab, it is advisable to skip doing so. | . You should now see two new files in the ~/.ssh/ directory. id_rsa is your SSH private key, and it should like the following: . $ cat ~/.ssh/id_rsa -----BEGIN RSA PRIVATE KEY----- &lt;random characters&gt; -----END RSA PRIVATE KEY------ . Please try to not lose or leak this private key. The public key, id_rsa.pub, should be much shorter and look like the following: . $ cat ~/.ssh/id_rsa.pub ssh-rsa &lt;characters&gt; &lt;username&gt;@&lt;host&gt; . It is safe to transfer your RSA public key out in the open, whereas you should never do so with your private key. It should only be transferred over trusted and encrypted communication channels over machines you trust. You’ve just created for yourself an RSA keypair suitable for SSH authentication. For the remaining tasks in this lab, you will be tasked with figuring out the appropriate commands yourself, by Googling, reading man pages, etc. Hints will be given as footnotes as necessary. Please document the commands you use and be prepared to provide a rationale for why you believe those commands are correct. Warm-up Task . Figure out how to use the SSH key you’ve created to log into your student VM.5 . Perform the remaining tasks on your student VM unless otherwise specified. Task 2 - Symmetric Encryption . In order to explore encryption, we’re going to be using the gpg command. | Download6 the file named q2.txt.gpg from github, decrypt it using gpg and the password weak_password. What is the decrypted content? . | Create a text file with your full name, username, and some random content in it. Then, use gpg to symmetrically encrypt this text file using the TWOFISH algorithm and a password of your choice. Make sure the resulting encrypted file is in ASCII-armored format7. What command did you use to do this? . | . Task 3 - Asymmetric Encryption . Remember to perform all the following steps on your student VM. In this task, we will be using gpg to create a PGP key. Step 0: Figure out how to do make this key8, and create a 4096-bit RSA/RSA PGP key. You might be wondering: didn’t we just create a 4096-bit RSA key for use in SSH? Why can’t we just use the same key for GPG? The short answer is that, while technically possible, it is inadvisable to do so for security reasons. | After creating the key, retrieve the key ID and put it in the checkoff form. | Export the public portion of the key in ASCII armor format and figure out how to distribute it. For every subsequent step, make sure to do everything using ASCII armored output where applicable. | The DeCal staff have a public key available. Figure out how to import the key, and write down the key id. | . | The DeCal staff have uploaded a few files called directions to help you figure out how to get to the OCF. However, we suspect nefarious elements may be trying to modify the file in an effort to divert students to their location. Figure out if the file has been modified. (Hint: Check the signature!) . | Where is your private key located? Write down the location where you expect the private key to be. | . We will return to encryption later in the lab. Task 4 - Hashing . Fortunately all the common hashing algorithms have been implemented for us by various libraries. For this lab, please compute the requested hashes by any method you deem appropriate. It would be advisable to do these on an OCF desktop, or on your student VMs, but not on tsunami, because this leaves around a large file that takes up extra space if not cleaned up. | Download a copy of the CentOS 7 NetInstall ISO from the OCF mirrors and verify that its SHA256 hash is correct. Also compute its SHA1 and MD5 hashes. | You may have noticed that the CentOS project provides a signature over the hashes it provides (the .asc file in the same directory as above). Briefly explain why this is a good, efficient security measure, knowing what you do about how signatures, hashing, and malicious attempts at file corruption work. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#encryption-lab-activity",
    "relUrl": "/labs/a9/#encryption-lab-activity"
  },"114": {
    "doc": "Lab 9 - Security",
    "title": "File Security",
    "content": "Now that you have some experience with the primitives of encryption, let’s cover some practical topics in securing files on UNIX-based systems. File Security and Permissions . The base layer in the UNIX security hierarchy is file permissions. Every file and process is owned by a user (and group), and by default, only the user/group that owns the file can edit it. You can see this by typing ls -la in your terminal: . admin@staff:~$ ls -la total 104 drwxr-xr-x 9 admin admin 4096 Oct 3 13:01 . drwxr-xr-x 5 root root 4096 Oct 2 16:49 .. drwxr-xr-x 2 admin admin 4096 Sep 21 21:11 .augeas -rw------- 1 admin admin 27932 Oct 6 14:05 .bash_history -rw-r--r-- 1 admin admin 220 May 15 12:45 .bash_logout -rw-r--r-- 1 admin admin 3526 May 15 12:45 .bashrc drwx------ 3 admin admin 4096 Sep 17 12:02 .config drwxr-xr-x 4 admin admin 4096 Oct 3 12:47 .gem drwxr-xr-x 2 admin admin 4096 Oct 3 12:46 .nano -rw-r--r-- 1 admin admin 675 May 15 12:45 .profile drwxr-xr-x 4 admin admin 4096 Sep 17 14:23 .puppet drwx------ 2 admin admin 4096 Sep 17 12:09 .ssh drwxr-xr-x 3 admin admin 4096 Oct 3 12:38 test -rw------- 1 admin admin 21980 Oct 2 16:42 .viminfo . The first column, e.g. -rw-------, is the read/write/execute permissions for the file. The third and fourth columns are the user and group that own the file. Let’s break down the permissions seen in the example above. You’ll notice that there are 10 entries: they either start with d for directory or - for regular files9, the the remaining 9 entries are split into 3 groups of 3 permission each: read, write, and execute for uuser, group, and other. That means -rw------- refers to a regular file, where the owner can read and write but not execute the file, and no one else can either read, write, nor execute the file. On the other hand, the permissions on the test entry (drwxr-xr-x) indicate that it is a directory, everyone can enter the directory (d--x--x--x), anyone can list files inside the directory (dr--r--r--), but only the owning user can write files inside the directory (d-w-------). A key point to remember is the difference between execute permissions on files vs. directories: on directories, it refers to the ability to enter the directory. The kernel enforces file permissions, preventing running programs from reading or modifying files they aren’t allowed to, and preventing users from executing programs that they don’t have access or permission for. This is important for a variety of reasons. For example, certain UNIX user accounts have their account information stored in a file called /etc/passwd and password hashes in /etc/shadow. These files are owned by root, preventing regular users from reading or changing this information without permission. ❯ ls -la /etc/shadow -rw------- 1 root root 861 Oct 9 02:22 /etc/shadow . This highlights a common security issue in UNIX: programs running as the root user. When a program is started, it inherits its user and group IDs from its parent process, and keeps them unless it manually drops permissions. If you start a program as the root user, because, for example, it requires deeper system access, a vulnerability in the program means that an attacker can interact with your computer as the root user. This is a common problem in misconfigured webservers, where a server running as root with a directory traversal vulnerability might allow an attacker to read secret credentials stored on the server’s filesystem. The moral of this story is tied to the principle of least privilege: wherever possible, only give the minimum amount of permission or privilege possible. If a program doesn’t need root credentials, don’t run it as a privileged user. If a file has sensitive content, don’t make it world-readable. How do you change permissions? There are two primary commands for doing so: chmod and chown. chmod changes the file mode, i.e. permissions, and an example of its syntax follows: . $ ls -la ~/ drwxr-xr-x 3 admin admin 4096 Oct 3 12:38 test $ chmod 644 test $ ls -la drw-r--r-- 3 admin admin 4096 Oct 3 12:38 test $ chmod u+x test drwxr--r-- 3 admin admin 4096 Oct 3 12:38 test $ chmod 000 test d--------- 3 admin admin 4096 Oct 3 12:38 test $ chmod +r test dr--r--r-- 3 admin admin 4096 Oct 3 12:38 test . chmod accepts file permissions in octal notation, which is the following: . | # | rwx | . | 7 | rwx | . | 6 | rw- | . | 5 | r-x | . | 4 | r– | . | 3 | -wx | . | 2 | -w- | . | 1 | –x | . | 0 | — | . chown on the other hand changes the owner and group of a file. For example, suppose a file instructions.txt is created in your home directory (~you) by user staff with permissions -rw-------. You need to read this file to follow the instructions, but the staff user did not make the file world-readable so you could open it. In order to read it, you may first want to chown the file to yourself, by running chown you:you instructions.txt. This would change the file’s owner and owning group, previously “staff” and “staff”, to you. The basic syntax of chown is fairly simple: . chown [-R] [user]:[group] PATH . where PATH is the file or directory whose ownership you wish to modify, and -R means ‘recursive.’ . Making sure that files are only accessible to those who should be allowed to do so, and that vulnerable programs are not given too many permissions, is a critical part of maintaining system security on Linux. Task 5 - File Security . Lets practice using the commands and concepts covered above. Please answer the following questions with regards to some arbitary files, and make note of what commands you would use for checkoff. It’s recommended to play around with those commands on your own. Let’s say you have a file: . | How would you make that file readable to you? | What if the file is very important, as it contains decal secrets. Use chmod and chown to make the file readable only to you. | Lets say we have an even more important file. Only root should be able to read this file, and no one should be able to edit it. | Lets say file4.txt and file5.txt are files are owned by another user. Choose any method to make the files readable to you and unreadable to the previous owner. | Lets say we have two files, filea.txt and fileb.txt: provide a strategy to make these files readable only to you and the decal user, and no one else. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#file-security",
    "relUrl": "/labs/a9/#file-security"
  },"115": {
    "doc": "Lab 9 - Security",
    "title": "Network Security",
    "content": "On UNIX based operating systems, the network is the most common method of gaining unauthorized access to a machine. Why this is the case should be obvious: the network allows one to interact with a machine without needing any physical presence. Anyone on the same network as your machine can connect, and therefore attack, your machine. On the internet, this means the whole world can attack your machine. This introduces a number of security considerations when running networked applications. The first step in securing machines connected to a network, or the open internet, is to make it as hard as possible for attackers to get to your machine. As you may recall from the networking lecture, processes interact with one another over a network by means of sockets and ports. Many protocols listen on well-known ports, such as SSH on port 22, HTTP on port 80, FTP on port 21, etc. We use firewalls and similar software to prevent unauthorized users from connecting to your machine. The second step in maintaining network security is to audit which programs are running on your server, and to design your network to reduce the attack vectors on any single machine by separating concerns as much as reasonably possible. For example, it may not be a good idea to run a critical database server and a potentially insecure webserver on the same machine, as a vulnerability in one could easily lead to the compromising of the other. At the very least, all these programs should be run as minimally privileged users, and never as root unless necessary, like sshd. Finally, the hardest part of online security is auditing your own code. Ultimately, most security vulnerabilities arise from code you need to run to affect your business functions. For example, the popular CMS software WordPress, which is estimated to power nearly a quarter of all websites, has historically been extremely vulnerable to security bugs, especially because people like to install WordPress plugins, often written by amateur coders, which are even less secure. Unfortunately, the only real defense against one’s own imperfection as a programmer is to be vigilant about monitoring one’s programs for vulnerabilities and servers for intrusion, and following good defensive programming practices on the road towards the impossible goal of secure, bug-free programs. Task 6 - Network Security Lab Activity . | Make a list of all the services running on your student VM that are accessible from the public internet, what user they are running as, and what port they are listening on. You may find tools such as netstat and ps to be helpful. You may also want to point nmap -A at your VM from another machine, such as tsunami. | Use less and grep to open up and search your SSH login log file, located in /var/log/auth.log. Besides yourself, is anyone trying to log in? Who and why if there is? . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#network-security",
    "relUrl": "/labs/a9/#network-security"
  },"116": {
    "doc": "Lab 9 - Security",
    "title": "Optional Task: Letsencrypt on an nginx instance!",
    "content": "This task is somewhat involved and completely optional. With that said, being able to use certbot to provision certificates is an invaluable skill that you will likely need when setting up your own webservers. If you ever need to do this in the future, you know where to find a guide! :) . In this task, we’re going to set up one of the most common uses of certificates and signatures: HTTPS. As you might have realized, you are now in possession of a website and webserver, (&lt;you&gt;.decal.xcf.sh), at least for the time being. Perform the following tasks on your student VM. Suppose you want to start hosting files on your site for other people to visit and see. First, install the nginx package to get a web server, and then customize the file at /var/www/html/index.html to reflect your indiviuality. You can see this new file at &lt;you&gt;.decal.xcf.sh in a web browser. Now that you have a website, you decide that, as a good internet citizen, you want to protect your visitors from the prying eyes of the government, by setting up HTTPS. You know already that you will need a public key and a certificate signed by a trusted root CA in order to do this. How do you go about getting one? Searching the internet, you find a wonderful project called Let’s Encrypt that provides free, signed certificates. Let’s go about acquiring one. For the purpose of this lab, we will be performing all the required steps manually instead of using the automated tools for educational purposes. | The first step in acquiring a signed certificate is to generate the public and private key that the certificate will validate. We can do so by using the openssl command. $ openssl genrsa 4096 &gt; domain.key . As you probably guessed, we just created another 4096-bit RSA keypair, this time, in PEM format. Both the public and private keys are encoded in the file domain.key, which you can see using cat. | For Let’s Encrypt, we’ll also need an another key for our Lets Encrypt account. Repeat the command from above, but this time, output to a file called account.key.10 Let’s also export the public portion of this key as you’ll need it soon when you authenticate to LetsEncrypt. $ openssl rsa -in account.key -pubout &gt; account.pub . | Now that we have a keypair that we want signed, (domain.key), let’s generate a “Certificate Signing Request” for it. This will be what you send to Let’s Encrypt in order to get a certificate for your public key. It contains the metadata necessary for LE to issue a certificate. $ openssl req -new -sha256 -key domain.key -subj \"/C=US/ST=CA/L=UC Berkeley/O=Open Computing Facility/emailAddress=&lt;you&gt;@ocf.berkeley.edu/CN=&lt;you&gt;.decal.xcf.sh\" -out csr.pem -outform pem . You’ll find a file in your directory called csr.pem that starts with BEGIN CERTIFICATE REQUEST. What did you just do? You asked for a -new certificate signing request for the public -key in domain.key, using -sha256 for hashing. You are &lt;you&gt;@something from the OCF at UC Berkeley, CA, US, and you’re making this request for the domain name (aka Common Name) &lt;you&gt;.decal.xcf.sh. You’d also like the CSR to be in pem format. Now, we have all the data we need to actually get a certificate. Let’s submit the request to Let’s Encrypt. | Install the certbot utility and do the following: . Enter the following command at a terminal: . sudo certbot certonly \\ --authenticator manual \\ --text \\ --email &lt;you&gt;@email.address \\ --csr csr.pem . You will be asked to answer some questions, read them and type “Y” when prompted. On the last prompt, you will be asked to make a file available in the root directory of the web server, either by copying the file yourself or by executing the Python code provided by the certbot program. It is recommended to use the Python code in a new terminal window. Here is what the code should look like: (do not copy and paste this, use the code provided by certbot) . # mkdir -p /tmp/certbot/public_html/.well-known/acme-challenge # cd /tmp/certbot/public_html # printf \"%s\" &lt;random&gt; &gt; .well-known/acme-challenge/&lt;random&gt; # run only once per server: # sudo $(command -v python2 || command -v python2.7 || command -v python2.6) -c \\ \"import BaseHTTPServer, SimpleHTTPServer; \\ s = BaseHTTPServer.HTTPServer(('', 80), SimpleHTTPServer.SimpleHTTPRequestHandler); \\ s.serve_forever()\" . After this, the certbot client will verify that the domain is legit and issue a certificate, writing it to your current directory, likely as 0000_chain.pem. This .pem file is your signed certificate! Once you set it up with a web server, people will be able to securely browse your website. Let’s configure the webserver to use your new certificate to secure requests. | Make sure that nginx is installed, otherwise you won’t be able to view your website. nginx stores its configuration information in /etc/nginx. From the decal-labs repository, add the file a9/nginx-a9.conf to the /etc/nginx/sites-enabled/ directory. | Edit nginx-a9.conf using your preferred text editor and fix it according to the instructions contained therein. | Rename nginx-lab9.conf to default and reload nginx.11 . | . Now, if you visit https://&lt;you&gt;.decal.xcf.sh, you should see the green lock in the address bar indicating that your website is secured with HTTPS! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#optional-task-letsencrypt-on-an-nginx-instance",
    "relUrl": "/labs/a9/#optional-task-letsencrypt-on-an-nginx-instance"
  },"117": {
    "doc": "Lab 9 - Security",
    "title": "Footnotes",
    "content": ". | https://thehackernews.com/2016/08/github-ssl-certificate.html &#8617; . | https://news.ycombinator.com/item?id=10663843 &#8617; . | limitations on the size of data that public key crypto can operate over render this option nontrivial and difficult to implement. &#8617; . | https://en.wikipedia.org/wiki/SHA1 &#8617; . | hint: look at the man page ssh-copy-id command. &#8617; . | use of wget is recommended &#8617; . | see the --armor option &#8617; . | GitHub has excellent documentation on creating all kinds of cryptographic keys. &#8617; . | There are others too, like ‘l’ for symbolic link &#8617; . | $ openssl genrsa 4096 &gt; account.key &#8617; . | recall lab 6: systemctl reload nginx &#8617; . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/#footnotes",
    "relUrl": "/labs/a9/#footnotes"
  },"118": {
    "doc": "Lab 9 - Security",
    "title": "Lab 9 - Security",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/a9/",
    "relUrl": "/labs/a9/"
  },"119": {
    "doc": "About",
    "title": "About",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/",
    "relUrl": "/about/"
  },"120": {
    "doc": "About",
    "title": "Table of contents",
    "content": ". | Course Description | Administrivia . | Enrollment | Communication | Lecture | Labs | Live Sessions | . | FAQ . | Will the DeCal be offered next semester? | How do I know which track is best for me? | I don’t want units / wasn’t accepted / am not a student. Can I audit this course? | I’m stuck on a lab/concept! Where can I find help? | I have another question! | . | After this Course | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#table-of-contents",
    "relUrl": "/about/#table-of-contents"
  },"121": {
    "doc": "About",
    "title": "Course Description",
    "content": "This course covers the basics of setting up and administering a production-quality Linux server environment. By the end of this course, we expect that you will… . | be comfortable using GNU/Linux | understand how different parts of the OS work together, e.g. init, processes, daemons, filesystems, etc. | understand basic networking on Linux | have a good sense about maintaining system security | understand system administration essentials | get a practical taste of what sysadmins do in industry. | . The course will be taught in two sections: a “Beginner” section for students with minimal background in GNU/Linux or system administration, and an “Advanced” section for students with more experience. While we expect many students will have a CS background, the only real prerequisite is a desire to learn about new and unfamiliar technologies, which is a critical skill for sysadmins. The Beginner section has been designed to introduce new users to Linux, and the Advanced section has been designed to give more experienced users a taste of what Linux is capable of. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#course-description",
    "relUrl": "/about/#course-description"
  },"122": {
    "doc": "About",
    "title": "Administrivia",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#administrivia",
    "relUrl": "/about/#administrivia"
  },"123": {
    "doc": "About",
    "title": "Enrollment",
    "content": "This is a 2 unit DeCal. Since it is a DeCal, the course is P/NP. You must attend an infosession and complete Lab 0 to apply. If you are selected for the course, we will send you a course enrollment code by February 5. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#enrollment",
    "relUrl": "/about/#enrollment"
  },"124": {
    "doc": "About",
    "title": "Communication",
    "content": "Official course communications will primarily be sent via email, and mirrored on the front page of the course website. There are several ways you can get in contact with course facilitators: . | Send a message on #decal-general either on Slack or Discord. (best for conceptual or debugging help) | Send a Slack/Discord private message to a facilitator. (best for personal/individual matters) | Send an email to decal@ocf.berkeley.edu. (best for prospective students and matters that need to go on official record) | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#communication",
    "relUrl": "/about/#communication"
  },"125": {
    "doc": "About",
    "title": "Lecture",
    "content": "Lectures are scheduled for Tuesdays for the Beginner section and Thursdays for the Advanced section, from 8 to 9pm. Due to the online nature of this semester, we will offer pre-recorded lectures, posted weekly on this website. Lab sections and office hours will be held over Zoom at ocf.io/decalzoom. While we normally mandate attendance, this will no longer be a requirement for Spring 2021 given the remote nature of the course. Nonetheless, students will be expected to view all lectures, as knowledge of their content will be assumed in lab assignments. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#lecture",
    "relUrl": "/about/#lecture"
  },"126": {
    "doc": "About",
    "title": "Labs",
    "content": "The primary assignment in this course will be weekly lab work. Labs are designed to be be significantly hands-on. You will be working on real systems, configuring, and fixing things, setting up services, and so on. Each lecture corresponds with a lab, labeled by a “b” or “a” (for Beginner or Advanced) and the week number. Except for b1 and a1, labs will general be released the week before the corresponding lecture. You are highly encouraged to look over the lab, and try to start it, before coming to section each week. This will allow you to better utilize the help of the facilitators. Each lab will be due by the Saturday, 11:59pm PST after the lab section unless otherwise stated. Labs (and lectures) will be released the prior Sunday, so you will have a week to complete them. You must complete 10 labs to receive credit for taking the course. However, we will allow two unexcused late labs to be turned in before the semester ends. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#labs",
    "relUrl": "/about/#labs"
  },"127": {
    "doc": "About",
    "title": "Live Sessions",
    "content": "In a typical semester, lectures are delivered live during the scheduled Tuesday and Thursday sections. However, due to the online nature of Spring 2021 we plan on converting these sections into lab sections, where facilitators will give additional information and demos related to the lab, and hold office hours to answer any questions that may arise. While attendance is not required, you are highly encouraged to attend since the information covered will make completing labs a shorter and more enjoyable experience. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#live-sessions",
    "relUrl": "/about/#live-sessions"
  },"128": {
    "doc": "About",
    "title": "FAQ",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#faq",
    "relUrl": "/about/#faq"
  },"129": {
    "doc": "About",
    "title": "Will the DeCal be offered next semester?",
    "content": "It’s too early to say at this point. Please check back in several months to see if there are any updates! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#will-the-decal-be-offered-next-semester",
    "relUrl": "/about/#will-the-decal-be-offered-next-semester"
  },"130": {
    "doc": "About",
    "title": "How do I know which track is best for me?",
    "content": "Beginner Track is intended for those who have little to no prior experience of using Linux-based systems. We will be providing an overview to several important concepts in systems administration, such as networking, shell scripting, version control, and security. It’s perfectly OK if you’ve never worked with or heard of these concepts before- but if you’re familiar with them, we recommend you opt for the advanced track. Overall, we welcome everyone to this track! . Advanced Track is intended for those who have used Linux-based systems before and are at least somewhat familiar with some of the concepts mentioned in the beginner track description above. While there are no hard/enforced prerequisites, we do recommend that you have experience with one or more of the following: . | Using Linux as a primary/secondary OS | Using a package manager such as apt or pacman | Writing scripts to automate basic tasks | Basic networking (such as working with IP addresses) | . If you are still unsure about which track to choose, you can email us at decal@ocf.berkeley.edu. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#how-do-i-know-which-track-is-best-for-me",
    "relUrl": "/about/#how-do-i-know-which-track-is-best-for-me"
  },"131": {
    "doc": "About",
    "title": "I don’t want units / wasn’t accepted / am not a student. Can I audit this course?",
    "content": "We are working hard to get all of our materials online this semester for everyone to access! Since we are no longer bound by physical constraints, feel free to attend any of our scheduled lectures or complete any of the labs on your own. (You will need your own Linux VM though- you can install one locally or get one from a provider such as DigitalOcean.) . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#i-dont-want-units--wasnt-accepted--am-not-a-student-can-i-audit-this-course",
    "relUrl": "/about/#i-dont-want-units--wasnt-accepted--am-not-a-student-can-i-audit-this-course"
  },"132": {
    "doc": "About",
    "title": "I’m stuck on a lab/concept! Where can I find help?",
    "content": "The best way to get support with course content is to either ask in our Slack channel at #decal-general, Discord channel, or ask us during scheduled lecture times. Logistics questions are best suited for email (decal@ocf.berkeley.edu). ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#im-stuck-on-a-labconcept-where-can-i-find-help",
    "relUrl": "/about/#im-stuck-on-a-labconcept-where-can-i-find-help"
  },"133": {
    "doc": "About",
    "title": "I have another question!",
    "content": "Email us at decal@ocf.berkeley.edu. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#i-have-another-question",
    "relUrl": "/about/#i-have-another-question"
  },"134": {
    "doc": "About",
    "title": "After this Course",
    "content": "There’s no substitute for real-world experience. If you’d like to get experience in a low-risk but real-world setting, consider joining the OCF as a volunteer staff member. There, you’ll be able to put the things you learn in this course to use, and help other students while you’re at it. Best of all- there’s no application process! Just drop by and say hi :) . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/about/#after-this-course",
    "relUrl": "/about/#after-this-course"
  },"135": {
    "doc": "Announcements",
    "title": "Announcements",
    "content": "Check back to this page periodically to find out about new assignments, special events, and more! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"136": {
    "doc": "Announcements",
    "title": "Week 12 Announcements",
    "content": "May 1 &middot; 1 min read . | Last Thursday’s guest lecture is now available on YouTube. | Regularly scheduled DeCal material has now concluded! Thank you for flying OCF, and we hope you enjoyed the course :D | Bonus lab 11 has been released and will be due on 5/9! Lab 11 is optional and may be used to replace an incomplete and/or late lab. Note that lab 0 does not count towards the required 10 labs. | End-of-semester notices: Unless you have requested a lab drop, please remember that 10 labs must be completed before the end-of-semester deadline of Sunday, 05/09. The optional 11th lab will be released next week and will be due on 5/9, for those who were not able to complete a regularly scheduled lab. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | There will be no live lab this week. If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"137": {
    "doc": "Announcements",
    "title": "Week 11 Announcements",
    "content": "Apr 25 &middot; 1 min read . | There will be a special guest lecture this Thursday at 8:10pm at ocf.io/decalzoom! All students (auditors, beginner, advanced) are welcome! See your email for more details about the event. | Regularly scheduled DeCal material has now concluded! Thank you for flying OCF, and we hope you enjoyed the course :D | Bonus lab 11 has been released and will be due on 5/9! Lab 11 is optional and may be used to replace an incomplete and/or late lab. Note that lab 0 does not count towards the required 10 labs. | End-of-semester notices: Unless you have requested a lab drop, please remember that 10 labs must be completed before the end-of-semester deadline of Sunday, 05/09. The optional 11th lab will be released next week and will be due on 5/9, for those who were not able to complete a regularly scheduled lab. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | There will be no live lab this week. If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"138": {
    "doc": "Announcements",
    "title": "Week 10 Announcements",
    "content": "Apr 17 &middot; 1 min read . | The semester has flew by and we’re already at our final week of labs :O Lab 10 is now released and will be due Saturday, 4/24. | End-of-semester notices: Unless you have requested a lab drop, please remember that 10 labs must be completed before the end-of-semester deadline of Sunday, 05/09. The optional 11th lab will be released next week and will be due on 5/9, for those who were not able to complete a regularly scheduled lab. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"139": {
    "doc": "Announcements",
    "title": "Week 9 Announcements",
    "content": "Apr 11 &middot; 1 min read . | The 9th week’s labs and lectures have been released! You can view them in the schedule below. Lab 9 will be due Saturday, 4/17. | End-of-semester notices: Unless you have requested a lab drop, please remember that 10 labs must be completed before the end-of-semester deadline of Sunday, 05/09. We will be offering an optional 11th lab for those who may be unable to complete one of the regularly offered labs; details will be announced next week. | STF Renewal Update: The Student Tech Fund renewal has passed! Thank you to all who took some time out of their day to vote. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"140": {
    "doc": "Announcements",
    "title": "Week 8 Announcements",
    "content": "Apr 4 &middot; 1 min read . | The 8th week’s labs and lectures have been released! You can view them in the schedule below. Lab 7 will be due Saturday, 4/10. | STF Renewal: The Student Tech Fund (STF) is up for renewal during the ASUC elections April 5-7 (starting tomorrow). The OCF (the organization behind this DeCal!) is funded by the STF, and we would greatly appreciate your vote for renewal to ensure we can keep offering the resources you’re currently enjoying! You can read more about the STF and the upcoming vote here. You can make your vote at https://callink.berkeley.edu/ starting Monday. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"141": {
    "doc": "Announcements",
    "title": "Week 7 Announcements",
    "content": "Mar 27 &middot; 1 min read . | The 7th week’s labs and lectures have been released! You can view them in the schedule below. Lab 7 will be due Saturday, 4/3. | Lab 6 is due this Monday, 3/29. | If you haven’t already, please complete our mid-semester feedback form to get an extra late lab! | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"142": {
    "doc": "Announcements",
    "title": "Week 6 Announcements",
    "content": "Mar 14 &middot; 1 min read . | The 6th week’s labs and lectures have been released! You can view them in the schedule below. Lab 6 will be due after break, on Monday, 3/29. | Complete our mid-semester feedback form to get an extra late lab! | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"143": {
    "doc": "Announcements",
    "title": "Week 5 Announcements",
    "content": "Mar 7 &middot; 1 min read . | The fourth week’s labs and lectures have been released! You can view them in the schedule below. Lab 4 will be due on Saturday, 3/13. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | Lab 3 solutions have been released! You can access them in the schedule below. At this time they are only available to registered students and auditors, though we may release them to a wider audience at a future date. | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"144": {
    "doc": "Announcements",
    "title": "Week 4 Announcement",
    "content": "Feb 27 &middot; 1 min read . | The fourth week’s labs and lectures have been released! You can view them in the schedule below. Lab 4 will be due on Saturday, 3/6. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | Lab 2 solutions have been released! You can access them in the schedule below. At this time they are only available to registered students and auditors, though we may release them to a wider audience at a future date. | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"145": {
    "doc": "Announcements",
    "title": "Week 3 Announcement",
    "content": "Feb 21 &middot; 1 min read . | The third week’s labs and lectures have been released! You can view them in the schedule below. Lab 2 will be due on Saturday, 2/27. | Lab 1 solutions have been released! You can access them in the schedule below. At this time they are only available to registered students and auditors, though we may release them to a wider audience at a future date. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"146": {
    "doc": "Announcements",
    "title": "Week 2 Announcement",
    "content": "Feb 14 &middot; 0 min read . | The second week’s labs and lectures have been released! You can view them in the schedule below. Lab 2 will be due on Saturday, 2/20. | Student VM’s will be distributed over the next several days! Please email decal@ocf.berkeley.edu if you are enrolled but don’t receive one by mid-week. If you are auditing and would like assistance setting one up on your own, message us on #decal-general! | As usual, live lab will take place at ocf.io/decalzoom– Tuesday 8pm for beginner, Thursday 8pm for advanced. | Any questions? Contact us on #decal-general! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"147": {
    "doc": "Announcements",
    "title": "Week 1 Announcement",
    "content": "Feb 7 &middot; 0 min read . | The Linux SysAdmin Decal is back for Spring 2021! | The first week’s labs and lectures have been released! You can view them in the schedule below. | Live lab sections begin this week! (Tuesday 8pm for beginner, Thursday 8pm for advanced) | All live meetings will take place at ocf.io/decalzoom. | Any questions? Contact us on #decal-general! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"148": {
    "doc": "Announcements",
    "title": "Week 0 Announcement",
    "content": "Jan 26 &middot; 0 min read . | The Linux SysAdmin Decal is back for Spring 2021! | Registration is currently closed. If you completed Lab 0, we will send you an email to notify you of enrollment status by Saturday, Feb. 6. | Course content will begin on the week of Feb. 9. | Any questions? Contact us at decal@ocf.berkeley.edu! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/announcements/",
    "relUrl": "/announcements/"
  },"149": {
    "doc": "Archive",
    "title": "Unix System Administration Decal",
    "content": "Below are previous semesters' archived course websites: . | Fall 2020 | Fall 2019 | Fall 2018 | Spring 2018 | Fall 2017 | Fall 2012 | Spring 2012 | Spring 2011 | Spring 2010 | Spring 2009 | Fall 2008 | Spring 2008 | Spring 2007 | Spring 2006 | Fall 2005 | Spring 2005 | Fall 2004 | Fall 2002 | Spring 2002 | Fall 2001 | Spring 2001 | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/archive/",
    "relUrl": "/archive/"
  },"150": {
    "doc": "Archive",
    "title": "Archive",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/archive/",
    "relUrl": "/archive/"
  },"151": {
    "doc": "Beginner Lab 1 - Unix, the Shell, OSS",
    "title": "Table of contents",
    "content": ". | Introduction | Shell spelunking | General Questions | Culture Questions | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b1/#table-of-contents",
    "relUrl": "/labs/b1/#table-of-contents"
  },"152": {
    "doc": "Beginner Lab 1 - Unix, the Shell, OSS",
    "title": "Introduction",
    "content": "Welcome to the first lab! . All labs are graded on completeness and effort, so don’t worry too much about getting an exact right answer. (We’ll release staff solutions after the lab is due!) . Labs are also usually due a week from when they are assigned. Remember to ask for help if you need it on Slack! . It may be convenient to submit your answers to Gradescope as you go. Pro Tips: . | Here are some commands you might find helpful: cat, cd, emacs, file, grep, less, ls, man, nano, tar, wget, vim | Google and man are your friends! | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b1/#introduction",
    "relUrl": "/labs/b1/#introduction"
  },"153": {
    "doc": "Beginner Lab 1 - Unix, the Shell, OSS",
    "title": "Shell spelunking",
    "content": "Everything should be done via the shell! . The purpose of this lab is to get you comfortable with using the shell for things you might typically use a GUI for. While these tasks may seem simplistic or limited, you’ll quickly find that the commands have many different options (flags) to perform tasks that are either impossible or incredibly tedious / difficult to complete using traditional methods. Don’t worry about fully understanding how the commands work just yet- as long as you can gain a sense of familiarity with the tools at hand, we’ll be in good shape to explore them further next week! . | ssh into tsunami.ocf.berkeley.edu using your OCF account, or login at ssh.ocf.berkeley.edu . | Run the following command to download the file we have provided: wget https://github.com/0xcf/decal-labs/raw/master/b1/b01.tgz . A .tgz file is actually a composition of two file formats. Sometimes you’ll see these files as .tar.gz instead. A common (and old) way of archiving is with magnetic tapes. However, in order to archive the data, it needs to be a single file, and often you want to archive multiple files at once. This is where the tar command comes in (tar stands for tape archive). Tar will group (or ungroup) multiple files into a single one. tar, unless you ask it to, doesn’t compress files itself though. This is where either gzip (or bzip2) comes in. gzip will compress your file, and so, tar + gzip is often used in conjunction. It looks something like this: file --(tar)--&gt; file.tar --(gzip)--&gt; file.tar.gz. If you read the tar documentation carefully enough, you’ll see that you can give the command an option to compress your files using gzip as well, saving you a total of one line of shell command! . To unarchive the file we provide you, run the following command: tar xvzf b01.tgz. This will provide a b01 directory for you with some files for the rest of this lab. tar has a reputation for being a bit tricky with its options: . | Go into the b01 directory. Make sure you’re in there by running pwd (Present working directory). What does pwd give you (conceptually)? . | There’s a hidden file in the b01 directory. What is the secret? . | A malicious user made its way into my computer and created a message split across all the files in nonsense/. What does it say? How did you find the message? (Hint: ls and/or xargs will be helpful here. If you want a challenge, try to do this in a single short command- but it’s ok to find it by any means available.) . | Go ahead and delete everything in nonsense/ with one command. How did you do it? . | There’s a file in b01 called big_data.txt. It’s 80 megabytes worth of random text. For reference, Leo Tolstoy’s “War and Peace”, the novel with a whopping 57,287 words depicting the French invasion of Russia and the impact of the Napoleonic era on Tsarist society through the stories of five Russian aristocratic families with several chapters solely dedicated to philosophical prose, is only 3.2 megabytes large. For that reason, I don’t recommend using cat to print the file. You can try it, but you’ll be sitting there for a while. There’s some text you need to find in there! Go find it without actually opening up the file itself! . Two lines above the only URL in the file is a secret solution. What is that solution? . Hints: What makes up a URL (https…)? What is Context Line Control? . | Try executing ./a_script. You should get something back that says permission denied: ./a_script. This is because files have three different permissions: read, write, and execute. Which one does a_script need? Change the file permissions so that you can run the script. How did you do it? . | Finally, there’s an empty file called hello_world in the directory. Write your name in it! How did you do it? . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b1/#shell-spelunking",
    "relUrl": "/labs/b1/#shell-spelunking"
  },"154": {
    "doc": "Beginner Lab 1 - Unix, the Shell, OSS",
    "title": "General Questions",
    "content": "Feel free to use Google and work in a terminal (where applicable) to verify your conjectures. | What differentiates Linux/OSX from operating systems like Windows? . | What are some differences between the command line and normal (graphical) usage of an OS? . | What is the root directory in Linux filesystems? Answer conceptually, as in depth as you would like, . | ls has a lot of cool arguments. Try using them to get extra information such as file permissions, owner name, owner group, file size, and late date edited. In addition, I want to be able to see the size and have the files ordered by last date edited, with the oldest files on top. How would I do this? . | Instead of showing the first 10 lines of the file big_data.txt, I want to use the head command to show the first 4. How would I do that? . | What’s the difference between cat foo &gt; out.txt and cat foo &gt;&gt; out.txt? . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b1/#general-questions",
    "relUrl": "/labs/b1/#general-questions"
  },"155": {
    "doc": "Beginner Lab 1 - Unix, the Shell, OSS",
    "title": "Culture Questions",
    "content": "Next are some cultural questions about Linux and Open Source Software. | Briefly, what is the difference between permissive and copyleft licenses? . | Give an example of a permissive license. | Give an example of (a) open-source software and (b) free, but closed-source software that you use. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b1/#culture-questions",
    "relUrl": "/labs/b1/#culture-questions"
  },"156": {
    "doc": "Beginner Lab 1 - Unix, the Shell, OSS",
    "title": "Beginner Lab 1 - Unix, the Shell, OSS",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b1/",
    "relUrl": "/labs/b1/"
  },"157": {
    "doc": "Lab 10 - Containers and Configuration Management",
    "title": "Table of contents",
    "content": ". | Overview | Getting started with Docker . | Creating your first Docker container | Running an interactive container . | Questions | . | Dockerfiles . | Questions | . | Dockerizing a Web Server . | Questions | . | . | Getting started with Puppet (optional) . | Questions | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b10/#table-of-contents",
    "relUrl": "/labs/b10/#table-of-contents"
  },"158": {
    "doc": "Lab 10 - Containers and Configuration Management",
    "title": "Overview",
    "content": "This lab is designed to give you some hands-on experience with Docker and Puppet! By the end of this assignment, you should be able to: . | Create and use a Docker container interactively and create a Dockerfile, which allows you to declaratively define your containers. | Write a basic Puppet manifest and apply the configuration to your VM. | . Keep track of your answers to the questions, as you’ll need to submit them to Gradescope. Also make sure your decal-labs repository is up to date (see lab b9) . Notice (new since Spring 2021): Past students have noted that b10 has been one of the longest labs out of all beginner labs. Start early and don’t be afraid to ask for help! We’ve also made the Puppet section of this lab optional, but we strongly recommend completing it if you have time. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b10/#overview",
    "relUrl": "/labs/b10/#overview"
  },"159": {
    "doc": "Lab 10 - Containers and Configuration Management",
    "title": "Getting started with Docker",
    "content": "You have a couple of options for installing Docker, but for your convenience, here’s are links to the packages you will need to install the latest version of Docker Community Edition: . | containerd.io | docker-ce-cli | docker-ce | . At this point, you should be able to install these packages in a breeze! . Hint: use either apt or dpkg with the appropriate commands. You might notice that these packages have dependencies, which means either you’ll need to install them in order (containerd.io -&gt; docker-ce-cli -&gt; docker-ce) or all at once, which you can do by just adding them in the command you run. After installing, I recommend running sudo usermod -aG docker $USER, then logout and login again. This adds your user to the docker group so you can run docker as a non-root user. This means you won’t have to type sudo docker all the time. This is optional but for the rest of the lab I’m going to assume that you did this. Creating your first Docker container . To verify that you installed things correctly, try running: . docker run hello-world . You should see some friendly output like so: . Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:c3b4ada4687bbaa170745b3e4dd8ac3f194ca95b2d0518b417fb47e5879d9b5f Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly... This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: . | The Docker client contacted the Docker daemon. | The Docker daemon pulled the “hello-world” image from the Docker Hub. | The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. | The Docker daemon streamed that output to the Docker client, which sent it to your terminal. | . Some quick definitions from Docker’s website: . An image is a lightweight, stand-alone, executable package that includes everything needed to run a piece of software, including the code, a runtime, libraries, environment variables, and config files. Images are useful primarily for their speed, but images can also be used as a base to be built on top of in future images, as you’ll see later with Dockerfiles. In the last example hello-world was the image used to test our docker installation. A container is a runtime instance of an image—what the image becomes in memory when actually executed. It runs completely isolated from the host environment by default, only accessing host files and ports if configured to do so. A container gets created upon executing docker run on an image. Be sure to read through the output from running the hello-world image to get an understanding of what the Docker daemon was doing. Running an interactive container . Now, let’s try to run a container interactively. This is useful if you ever need to play around and install stuff on a bare system without messing up your current system. Try running the following command: . docker run -it ubuntu:latest . The -i flag tells docker to keep STDIN open to your container, and the -t flag allocates a pseudo TTY for you. Basically you need both for you to have a shell into your newly started container. Try installing some packages from apt or just play around. It should look like a bare Linux system. You can exit the container with CTRL+D. Questions . | What user are you logged in as by default in the container? | If you start and then exit an interactive container, and then use the docker run -it ubuntu:latest command again; is it the same container? How can you tell? | . Dockerfiles . The natural question is, how are Docker images built? A Dockerfile is like the source code of an image. Rather, a Dockerfile allows you to define an image by specifying all of the commands you would type manually to create an image. Docker can then build images from a specified Dockerfile. These Dockerfiles can be put into version control and the images uploaded to online repositories. Can you see how this can be useful for deploying your application? . Dockerfiles are very powerful and have many different commands and features. We’ll go over a basic example, but you should check out the reference page if you are trying to do anything more complex. Let’s jump in. We’re going to create an image that deploys your new startup’s app, Missile! Unfortunately, so far you only have the opening animation complete, and the source code is in decal-labs/b10/missile.py. Your program has a couple of dependencies. Namely, it requires Python and the python packages termcolor and pyfiglet to be installed. Here is a Dockerfile that puts those requirements into code, by installing Python 3 and the packages onto a base Fedora Linux image. # Specify Fedora Linux as base image FROM fedora:latest # Install Python with yum (Fedora's Package Manager) # Install required Python packages RUN yum update -y &amp;&amp; yum install -y python3 python3-pip &amp;&amp; \\ python3 -m pip install pyfiglet termcolor # Add the missile.py file to the final image ADD missile.py / # Specify the command to be run on container creation CMD [\"/usr/bin/python3\", \"missile.py\"] . Note: there are some “best practices” for writing Dockerfiles that the above example doesn’t use, because it’s a basic example. If you’re interested in this stuff, check out this article. Take a moment to appreciate how cool this is. We have a completely different Linux distribution with an application running on our system that can all be spun up with a single command. Now, when (if?) your startup finally takes off, scaling up will be a breeze! . Make sure you have both files named missile.py and Dockerfile respectively then build the image with the following command: . docker build -t missile:latest . This tells Docker to look in the current directory for a Dockerfile to build, and builds it. The -t flag tells Docker to tag this build with the name missile:latest. Note that building the missile image will take a couple of minutes to complete. You can see all of the images you’ve built on your machine with the docker images command. Questions . | Run the image you just built with no flags. What do you observe? | Write and build a Dockerfile based on ubuntu:bionic that installs the packages fortune and fortunes-min and runs the fortune executable (located in /usr/games/fortune after you install it). Note that you won’t need to use the -it flags when you run the container as fortune doesn’t need STDIN. Submit your Dockerfile with this lab. Hint: if you’re having trouble writing your Dockerfile, try booting an interactive container and installing both packages. How can you translate what you did interactively to a Dockerfile? | Paste the output of running docker images command after completing questions 1 and 2. | . Dockerizing a Web Server . For our last trick, we’re going to use Docker to run multiple Apache web servers inside containers. For simplicity, you will not have to write this Dockerfile. Go ahead and pull the httpd image from Docker Hub. Now, it’s your job to figure out how to run three instances of the Apache containers on your machine. Docker creates a separate network for containers, so you will need to forward your host port to your container’s port (this is called port forwarding, or port mapping). The container is listening on port 80 by default. It is your job to run each instance on ports 4000, 4001, and 4002. I recommend running the containers in detached mode with the -d flag. Detached mode will run a container in the background and print its new container ID. You can view running containers with docker ps. Hints: . | The -p flag takes in a colon separated pair of HOST_PORT:CONTAINER_PORT (it can actually accept a ton of more options, but don’t worry about that for now). | You can see if you were successful by executing curl localhost:4000 on your student VM. Check that you;’ve also done it correctly for ports 4001 and 4002. | Refer to the Docker commands slide if you’re stuck! | . Questions . | While your three containerized Apache web servers are running in detached mode, paste the output of docker ps. | Observe that in the output of docker ps, each container has an associated container ID. Explain why containers have IDs/Names rather than being named after the image, for example httpd. | Now go ahead and stop your containers. Paste the command you used to stop one of the containers. | . Congratulations! You’ve successfully Dockerized and ran a web server without affecting your setup on your machine :) There’s a lot more about Docker and containers to learn about, but I hope this was enough to wrap your head around the basic concepts and get some experience working with it. For further reading, I recommend just reading the official documentation so you can see what is possible with the Docker container format. The following section will show you how to use Puppet in production. If you’re feeling burnt out by this point from Docker, feel free to skip the next section, as the Puppet section is optional. Otherwise, continue reading on! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b10/#getting-started-with-docker",
    "relUrl": "/labs/b10/#getting-started-with-docker"
  },"160": {
    "doc": "Lab 10 - Containers and Configuration Management",
    "title": "Getting started with Puppet (optional)",
    "content": "First, we’re going to install Puppet. Feel free to simply copy the commands below to set up Puppet. Make sure to copy the whole thing! . wget https://apt.puppetlabs.com/puppet6-release-bionic.deb &amp;&amp; \\ sudo dpkg -i puppet6-release-bionic.deb &amp;&amp; \\ sudo apt-get update &amp;&amp; \\ sudo apt-get -y install puppet . To get some hands on experience with Puppet, we are going to write a basic manifest that pulls Kanye West quotes from a service called https://kanye.rest and appends them to a file every two minutes. Although you were taught that in production environments we have the puppet master running on its own server, for simplicity you will apply the manifest locally, making you both the puppet master and the puppet agent. If you are confused about the Puppet vocabulary, review the slides! . The skeleton file quotes.pp is located inside decal-labs\\b10 folder, which you will be filling in. The next few paragraphs describe what your manifest should contain. We plan to pull quotes from the web, so we need to ensure the curl package is installed on our system. Next we need to create a user, quotes, that runs this command for us. We create a separate user for this task because Puppet runs everything as root by default, and pulling anything from the web poses a security risk. For example, a malicious actor could perform a domain hijacking attack to get remote code execution as the root user; the severity of this threat is significantly reduced if the attack is performed on a user with less privileges. Also take note of the dependency between the quotes user and the quotegather group. The require line says the quotegather group must exist for the user quotes to be created. Because we have full control over our user, let’s make its home directory /tmp. Since this user has one purpose, to pull quotes from the web, they don’t need a login shell. Go ahead and set it to /bin/false. Now we need a cron resource that grabs the quotes for us. I went ahead and filled in the command, so all you need to do is specify which user is to run the cron job and the interval at which it runs (every 2 minutes). Once you have completed your manifest, you can apply the changes to your system with the command sudo puppet apply quotes.pp. Some tips for writing this manifest: . | Read the Offical Puppet Documentation about different resources if you are confused about commands | Here is an OCF mail server manifest with similar resources. You can safely ignore the include lines. | You can check your puppet syntax with puppet parser validate quotes.pp | List ‘quotes’ cron jobs with sudo crontab -u quotes -l | https://crontab.guru/ | . Wait 10 minutes or so and running cat /tmp/quotes should yield a list of enlightening quotes. Questions . | Submit your completed quotes.pp file. | . Congratulations! You have successfully written your own puppet manifest. This could easily be added to a puppet master and deployed on thousands of systems with ease. Take a minute to consider how powerful this technology is. The OCF uses Puppet extensively, and you can take a look at how we group our manifests and modules here: https://github.com/ocf/puppet/tree/master/modules . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b10/#getting-started-with-puppet-optional",
    "relUrl": "/labs/b10/#getting-started-with-puppet-optional"
  },"161": {
    "doc": "Lab 10 - Containers and Configuration Management",
    "title": "Lab 10 - Containers and Configuration Management",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b10/",
    "relUrl": "/labs/b10/"
  },"162": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "Table of contents",
    "content": ". | Setting up | SSH (Secure Shell) . | Question | . | Pipes and Redirection . | Questions | Other useful tricks | . | A quick intro to vim . | Why vim? | Hello World | The vim Modes . | Normal mode: | Insert mode: | Visual mode: | . | Questions | If you’re interested in emacs instead | . | A quick intro to tmux . | Why tmux? | Getting Started: | Questions | Advanced usage (optional) | . | Submitting the lab | Resources | . Welcome to Lab 2! In this lab you will be learning how to work productively in a shell. Remember to submit your answers in the Gradescope assignment! . Don’t forget to use Google and man when stuck. The resources linked at the bottom may be helpful as well. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/#table-of-contents",
    "relUrl": "/labs/b2/#table-of-contents"
  },"163": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "Setting up",
    "content": "This lab requires a bash shell, vim, and tmux. If you do not have tmux: apt-get tmux . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/#setting-up",
    "relUrl": "/labs/b2/#setting-up"
  },"164": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "SSH (Secure Shell)",
    "content": "SSH allows you to log in to a remote computer through the internet. It is the equivalent of opening a shell on a remote computer. The usage is ssh [remote username]@[remote host]. Question . | Log on to tsunami.ocf.berkeley.edu with your OCF username and password. There is a file in ~staff/public_html/decal. Open it. What is the secret in the file? | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/#ssh-secure-shell",
    "relUrl": "/labs/b2/#ssh-secure-shell"
  },"165": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "Pipes and Redirection",
    "content": "Chaining together commands is essential to automating your way through the shell. Here’s a quick cheat sheet: . &gt; : Redirect stdout to a file (Will overwrite the file). &gt;&gt; : Append stdout to a file (same as &gt; except does not overwrite). &lt; : Read input from a file. | : Send output from one program to the input of the next. Here’s an example: let’s say you’re taking a class that needs you to submit a text file with your SID in it. Your first instinct might be to open up a text editor (like vim) and simply type it in, but there’s a faster way to create files! Here it is: . echo '123456789' &gt; sid.txt . Questions . Scrabble is a fun word game that rewards players for knowing a bunch of weird words. I’d like to add some more words to my aresnal! . For the next couple questions, download this text file containing all valid Scrabble words using wget, curl, or a similar command. We’ll be having some fun with it! . | I get pretty stuck when I get a rack of all consonants! Help me find some words that don’t contain any vowels by writing a command to print out the first 10 words that do not contain any of the letters A, E, I, O, U, or Y. Text manipulation commands like grep, awk or sed might be useful! | . Example output: . BRR BRRR CRWTH ... (7 more lines not shown) . | In Scrabble, you can get a Bingo (and +50 points!) if you use all 7 of your letters in the same turn! I’ve got the letters ‘CAL’ in my rack and want to score those big style points with them. Write a command to fetch all of the words containing ‘CAL’ that are 7 or more letters long, and save them to a file called cal.txt. | . cal.txt contents: . ABAPICAL ACALEPH ACALEPHE ... (380 more lines not shown) . Other useful tricks . !! can be used to repeat the previous command in the shell. E.g. python program.py sudo !! == sudo python program.py . !:[num] is treated as the previous command’s [num] argument. E.g. touch doc.txt vim !:1 == vim doc.txt . Note: This behavior is from bash and some other shells that implement it. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/#pipes-and-redirection",
    "relUrl": "/labs/b2/#pipes-and-redirection"
  },"166": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "A quick intro to vim",
    "content": "vim is a very widely used text editor. It’s well known for its customizability and plethora of keybinds. While it may be somewhat unintuitive to use at first (since a lot of common keybinds for things like copy-paste, saving, or exiting don’t do what you think they will), it’s well worth learning about, and you’ll certainly come across it all the time when working in the shell! . Why vim? . | It’s a descendant of vi, which was written in Berkeley by Bill Joy, who went on to found Sun Microsystems. | Sometimes you will be suddenly thrown into vim via merging git conflicts or other programs. | It’s included in practically every UNIX environment. | You can be very productive when familiar with it. | . Hello World . Vim is a modal text editor, meaning that you can change editing modes in order to do different things. There are 3 primarily used modes: Normal, Insert, and Visual mode. Note: Instead of reading the (admittedly intimidating) list of common commands below, you can instead spend some time with vimtutor, which will walk you through all of this in an interactive manner! It is accessible as a command. You can then use this section as reference if you forget anything. The vim Modes . Normal mode: . | Used for moving around and performing actions . | hjkl to move left, up, down, and right (arrow keys work too but hjkl is usually faster to use!) | G to move to end of file, gg to move to beginning | i to enter insert mode (a, o also change mode in different ways) | dd to cut a line | yy to copy a line | p to paste | / to search | u to undo | . | Type in commands with : . | Save with :w | Exit with :q | . | Explore more commands online! Here’s a cool cheat sheet to get you started. | . Insert mode: . | Used for editing text like a usual editor | Arrow keys to move | Esc to exit to normal mode (lots of people bind it to Caps Lock) | . Visual mode: . | Enter with v from normal mode | Used to select text visually | Modify selection with normal mode movement commands | Use o to move the cursor to the other side of the selection | Yanking, deleting, and pasting use y, d, p (sound familiar?) | . A key feature of vim is chaining together commands. Normal mode is essentially a massive amount of shortcuts that you can combine to quickly navigate and edit a file. Want to move down 3 lines? You know that j means move down 1 line, so you can use 3j to move down 3. d is for deletion and w is to jump to the next word, so what does dw do? . Questions . Try playing around with lab2.md while looking up some new commands. Use wget to download it! . | How would you delete the previous 10 lines? | How would you jump back to the shell without exiting vim? | How would you edit a new file alongside another file? | How would you indent a block of text? | Tell us about one other cool vim feature you found out about that isn’t mentioned in this lab! | . If you’re interested in emacs instead . | Use this cheatsheet | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/#a-quick-intro-to-vim",
    "relUrl": "/labs/b2/#a-quick-intro-to-vim"
  },"167": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "A quick intro to tmux",
    "content": ". Why tmux? . | You can open multiple windows when sshed into a machine. | You can go compile and run programs while editing them. | You can logout and ssh back in without having to reopen all your files. | . Getting Started: . | Start a session with tmux. | Detach from a session with Ctrl-b d (press d after releasing Ctrl-b) | Split into 2 panes with Ctrl-b % (vertical) or Ctrl-b \" (horizontal) | Swap current pane with Ctrl-b o | Find more information about tmux online. You might find this cheat sheet helpful! | . Questions . | Make a new tmux session. Using tmux shortcuts, try to make your session have a similar layout to the one below, and upload a screenshot of it to Gradescope! | . Some things to note: . | The top left panel is resized. By how much, it doesn’t matter. | The top right panel is named “Hello World”. (You can see this name displayed on the bottom left.) | You don’t need to run any of the commands I did, but they do look pretty cool :) Try to figure out what command the bottom panel is running, and what it does! | Don’t worry about copying the layout exactly. The purpose of this exercise is simply to help you get comfortable making custom layouts in tmux. | . | If you haven’t already, detach from your current tmux session using Ctrl+b d. Now, what command would you type to attach back to it? | What command will delete your session? | What command will create a new session? | . Advanced usage (optional) . | Tmux can be used to share your session with others. | Try remapping shortcuts like the prefix Ctrl-b to something more convenient. | Ctrl-b [ can be used to scroll around buffers and copy things. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/#a-quick-intro-to-tmux",
    "relUrl": "/labs/b2/#a-quick-intro-to-tmux"
  },"168": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "Submitting the lab",
    "content": "Once you’re done remember to submit your answers and screenshot to Gradescope. There are multiple valid answers for some of the questions. Don’t be stressed about getting something correct; just have fun exploring. We’ll release the answers after the lab is due! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/#submitting-the-lab",
    "relUrl": "/labs/b2/#submitting-the-lab"
  },"169": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "Resources",
    "content": "Keybindings . Learning vim progressively . Tmux cheat sheet . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/#resources",
    "relUrl": "/labs/b2/#resources"
  },"170": {
    "doc": "Beginner Lab 2 - Core Shell",
    "title": "Beginner Lab 2 - Core Shell",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b2/",
    "relUrl": "/labs/b2/"
  },"171": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Table of contents",
    "content": ". | Overview . | About this Lab | . | Scripting with the Bourne-Again Shell (Bash) . | Shebang! | Shell Variables and Types | Arithmetic | test | Flow Control . | if-then-elif-else | while | . | Functions | . | Examples | Python for Sysadmins | Scripting Lab Assignment . | Some tips to make things easier | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#table-of-contents",
    "relUrl": "/labs/b3/#table-of-contents"
  },"172": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Overview",
    "content": "Many of the tasks that someone would like to perform on a computer are regular, require repetition, or are menial or tedious to do by hand. Shell scripting allows one to interact programmatically with a shell to do certain tasks. For example, the command for scanning log files in the previous topic guide could be automated to be performed on a schedule by means of a shell script. bash scripts are an incredibly powerful tool for sysadmins to automate tasks that are otherwise difficult to remember or long-running. In cases where shell syntax is inappropriate for the task at hand, one can instead call into programs written in other languages, such as Python, which can read from stdin, process data, and write to stdout. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#overview",
    "relUrl": "/labs/b3/#overview"
  },"173": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "About this Lab",
    "content": "We’ve included a somewhat extensive runthrough of many of bash’s basic features below. There is only one required task (Scripting Lab Assignment) and one optional task. Feel free to use the rest of the lab as a reference guide. For the Gradescope submission, you will need to upload a file containing your script. If you edit and test your script in your VM using vim or another shell editor, you can copy the file to your local machine using scp or simply copy-paste the text into a local file. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#about-this-lab",
    "relUrl": "/labs/b3/#about-this-lab"
  },"174": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Scripting with the Bourne-Again Shell (Bash)",
    "content": "While most programmers are likely familiar with bash in its popular capacity as a command line interpreter, it is in fact a powerful and full-featured programming language. Moreover, bash has a uniquely qualified claim to the title of scripting language in that programs written in bash are simply series of shell commands which bash reads off and executes line-by-line. Or, conversely, one might say that bash command line entries are simply short one-line scripts. So really, you’ve been bash scripting all along! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#scripting-with-the-bourne-again-shell-bash",
    "relUrl": "/labs/b3/#scripting-with-the-bourne-again-shell-bash"
  },"175": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Shebang!",
    "content": "Shell scripts typically begin with the shebang line: #!path/to/interpreter. #! is a human-readable representation of a magic number 0x23 0x21 which can tell the shell to pass execution of the rest of the file to a specified interpreter. If your script is run as an executable (e.g./awesome_shell_script) with a shebang line, then the shell will invoke the executable (usually an interpreter) at path/to/interpreter to run your script. If your script is passed as an argument to an interpreter e.g. bash awesome_shell_script, then the shebang has no effect and bash will handle the script’s execution. Why is this important? The shebang line can be considered a useful piece of metadata which passes the concern of how a script is executed from the user to the program’s author. awesome_shell_script could be a bash script, a python script, a ruby script, etc. The idea is that only the script’s behavior, not its implementation details, should matter to the user who calls the script. You may have seen some variant of #!/bin/sh. Although initially referencing the Bourne shell, on modern systems sh has come to reference to the Shell Command Language, which is a POSIX specification with many implementations. sh is usually symlinked to one of these POSIX-compliant shells which implement the Shell Command Language. On Debian, for instance, sh is symlinked to the shell dash. It is important to note that bash does not comply with this standard, although running bash as bash --posix makes it more compliant. Why is this important? If awesome_shell_script uses bashisms (i.e. non-POSIX bash-specific features) but includes a shebang line pointing to sh, then trying to run the script as an executable e.g./awesome_shell_script will likely fail. So if you plan to use bashisms in your script, the shebang line should point to bash, not sh. Note that this will sacrifice portability, as only systems with bash installed will be able to execute your script. A list of common bashisms and specification differences between common shells can be found here. The commonly installed checkbashisms program can help to identify bashisms. In contexts other than the shebang line, # indicates the beginning of a comment. Everything to the right of a # on a line will not be executed. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#shebang",
    "relUrl": "/labs/b3/#shebang"
  },"176": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Shell Variables and Types",
    "content": "Like most other programming languages, bash facilitates stateful assignment of names to values as variables. Variables can be assigned in bash with the syntax: NAME=value. Note the lack of spaces between the assignment operator = and its operands. Assignment is whitespace-sensitive. You can retrieve the value of a variable by prepending a $ to it’s name. Getting the value of NAME must be done with $NAME. This is called variable interpolation. $ NAME = \"Tux\" # Incorrect -bash: NAME: command not found $ NAME=\"Tux\" # Correct $ echo NAME # Incorrect. We want the value we assigned to NAME, not the text # NAME itself. NAME $ echo $NAME # Correct Tux . $? holds the exit code of the most recently executed command. In this context, exit code 0 generally means that a program has executed successfully. Other exit codes refer to the nature of the error which caused the program to fail. Special positional parameters allow arguments to be passed into your script. $0 is the name of the script, $1 is the first argument passed to the script, $2 is the second argument passed to the script, $3 is the third argument, etc. $# gives the number of arguments passed to the script. So ./awesome_shell_script foo bar could access foo from $1 and bar from $2. Bash variables are untyped. They are usually treated as text (strings), but a variable can be treated as a number if it contains digits and arithmetic operations are applied to it. Note that this is different from most programming languages. Variables don’t have types themselves, but operators will treat their values differently in different contexts. In other words, bash variables are text and don’t have any inherent behaviors or properties beyond that of text which can be manipulated, but operators will interpret this text according to its content (digits or no digits?) and the context of the expression. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#shell-variables-and-types",
    "relUrl": "/labs/b3/#shell-variables-and-types"
  },"177": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Arithmetic",
    "content": "Bash supports integer arithmetic with the let builtin. $ x=1+1 $ echo $x # Incorrect. We wanted 2, not the text 1+1. 1+1 $ let x=1+1 $ echo $x # Correct 2 . Note that let is whitespace sensitive. Operands and operators must not be separated by spaces. bash does not natively support floating point arithmetic, so we must rely on external utilities if we want to deal with decimal numbers. A common choice for this is bc. Fun fact: bc is actually it’s own complete language! . We commonly access bc via a pipe (represented as |), which allows the output of one command to be used as the input for another. We include the -l option for bc in order to enable floating point arithmetic. $ echo 1/2 | bc -l .50000000000000000000 . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#arithmetic",
    "relUrl": "/labs/b3/#arithmetic"
  },"178": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "test",
    "content": "Bash scripts frequently use the [ (a synonym for test) shell builtin for the conditional evaluation of expressions. test evaluates an expression and exits with either status code 0 (true) or status code 1 (false). test supports the usual string and numeric operators, as well as a number of additional binary and unary operators which don’t have direct analogs in most other programming languages. You can see a list of these operators, along with other useful information, by entering help test in your shell. The output of this is shown below. Note that help is similar to man, except it is used for bash functions instead of other programs. $ help test test: test [expr] Exits with a status of 0 (true) or 1 (false) depending on the evaluation of EXPR. Expressions may be unary or binary. Unary expressions are often used to examine the status of a file. There are string operators as well, and numeric comparison operators. File operators: -a FILE True if file exists. -b FILE True if file is block special. -c FILE True if file is character special. -d FILE True if file is a directory. -e FILE True if file exists. -f FILE True if file exists and is a regular file. -g FILE True if file is set-group-id. -h FILE True if file is a symbolic link. -L FILE True if file is a symbolic link. -k FILE True if file has its `sticky' bit set. -p FILE True if file is a named pipe. -r FILE True if file is readable by you. -s FILE True if file exists and is not empty. -S FILE True if file is a socket. -t FD True if FD is opened on a terminal. -u FILE True if the file is set-user-id. -w FILE True if the file is writable by you. -x FILE True if the file is executable by you. -O FILE True if the file is effectively owned by you. -G FILE True if the file is effectively owned by your group. -N FILE True if the file has been modified since it was last read. FILE1 -nt FILE2 True if file1 is newer than file2 (according to modification date). FILE1 -ot FILE2 True if file1 is older than file2. FILE1 -ef FILE2 True if file1 is a hard link to file2. String operators: -z STRING True if string is empty. -n STRING STRING True if string is not empty. STRING1 = STRING2 True if the strings are equal. STRING1 != STRING2 True if the strings are not equal. STRING1 &lt; STRING2 True if STRING1 sorts before STRING2 lexicographically. STRING1 &gt; STRING2 True if STRING1 sorts after STRING2 lexicographically. Other operators: -o OPTION True if the shell option OPTION is enabled. ! EXPR True if expr is false. EXPR1 -a EXPR2 True if both expr1 AND expr2 are true. EXPR1 -o EXPR2 True if either expr1 OR expr2 is true. arg1 OP arg2 Arithmetic tests. OP is one of -eq, -ne, -lt, -le, -gt, or -ge. Arithmetic binary operators return true if ARG1 is equal, not-equal, less-than, less-than-or-equal, greater-than, or greater-than-or-equal than ARG2. We can test integer equality . $ [ 0 -eq 0 ]; echo $? # exit code 0 means true 0 $ [ 0 -eq 1 ]; echo $? # exit code 1 means false 1 . string equality . $ [ zero = zero ]; echo $? # exit code 0 means true 0 $ [ zero = one ]; echo $? # exit code 1 means false 1 . and a number of other string and numeric operations which you are free to explore. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#test",
    "relUrl": "/labs/b3/#test"
  },"179": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Flow Control",
    "content": "bash includes control structures typical of most programming languages – if-then-elif-else, while for-in, etc. You can read more about conditional statements and iteration in the Bash Guide for Beginners from the Linux Documentation Project (LDP). You are encouraged to read those sections, as this guide provides only a brief summary of some important features. if-then-elif-else . The general form of an if-statement in bash is . if TEST-COMMANDS; then CONSEQUENT-COMMANDS elif MORE-TEST-COMMANDS; then MORE-CONSEQUENT-COMMANDS else ALTERNATE-CONSEQUENT-COMMANDS; fi . Indentation is good practice, but not required. For example, if we write . #!/bin/bash # contents of awesome_shell_script if [ $1 -eq $2 ]; then echo args are equal else echo args are not equal fi . we see . $ ./awesome_shell_script 0 0 args are equal $ ./awesome_shell_script 0 1 args are not equal . while . The general form of a while loop in bash is . while TEST-COMMANDS; do CONSEQUENT-COMMANDS done . If TEST-COMMANDS exits with status code 0, CONSEQUENT-COMMANDS will execute. These steps will repeat until TEST-COMMANDS exits with some nonzero status. For example, if we write . #!/bin/bash # contents of awesome_shell_script n=$1 while [ $n -gt 0 ]; do echo $n let n=$n-1 done . we see . $ ./awesome_shell_script 5 5 4 3 2 1 . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#flow-control",
    "relUrl": "/labs/b3/#flow-control"
  },"180": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Functions",
    "content": "bash supports functions, albeit in a crippled form relative to many other languages. Some notable differences include: . | Functions dont return anything, they just produce output streams (e.g. echo to stdout) | bash is strictly call-by-value. That is, only atomic values (strings) can be passed into functions. | Variables are not lexically scoped. bash uses a very simple system of local scope which is close to dynamic scope. | bash does not have first-class functions (i.e. no passing functions to other functions), anonymous functions, or closures. | . Functions in bash are defined by . name_of_function() { FUNCTION_BODY } . and called by . name_of_function $arg1 $arg2 ... $argN . Note the lack of parameters in the function signature. Parameters in bash functions are treated similarly to global positional parameters, with $1 containing the $arg1, $2 containing $arg2, etc. For example, if we write . #!/bin/bash # contents of awesome_shell_script foo() { echo hello $1 } foo $1 . we see . $ ./awesome_shell_script world hello world . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#functions",
    "relUrl": "/labs/b3/#functions"
  },"181": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Examples",
    "content": "Despite bash’s clumsiness, recursion and more complex programming logic are possible (read: painful). #!/bin/bash # contents of fibonacci if [ $# -eq 0 ]; then echo \"fibonacci needs an argument\" exit 1 fi fib() { N=\"$1\" if [ -z \"${N##*[!0-9]*}\" ]; then echo \"fibonacci only makes sense for nonnegative integers\" exit 1 fi if [ \"$N\" -eq 0 ]; then echo 0 elif [ \"$N\" -eq 1 ]; then echo 1 else echo $(($(fib $((N-2))) + $(fib $((N-1))))) fi } fib \"$1\" . bash can give us a recursive solution to finding the nth Fibonacci number. $ ./fibonacci 10 55 . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#examples",
    "relUrl": "/labs/b3/#examples"
  },"182": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Python for Sysadmins",
    "content": "Although bash scripts can be a simple and straightforward way to automate tasks involving the sequential execution of some shell commands, you may have already gathered that venturing beyond trivial conditional logic and simple functions introduces unnecessary syntactic complexity as compared to many other modern interpreted languages. For this reason, more complex scripts are popularly written in another, more general, programming language like python. Scripting with python is increasingly popular among sysadmins. Countless great tutorials for learning python are available online. Alternatively, Berkeley offers several courses that teach or use python, notably CS 61A and Data 8. Adapting python to command-line scripting is only a matter of using relevant modules. Here are some tips: . | The argparse module in the python standard library is a popular way to implement command-line interfaces for python scripts | fabric simplifies some sysadmin tasks, mostly in regard to application deployment | salt is useful for general infrastructure management | psutil provides an interface to system information monitoring | . In practice, the decision to write a script in either python or bash is largely dependent on the context of the task at hand. Generally, tasks solvable with simple shell commands and those requiring simple file reading, writing, and appending are often a good fit for a bash script. Those with complex control logic, recursion, and other more general programming patterns are a better fit for a python script. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#python-for-sysadmins",
    "relUrl": "/labs/b3/#python-for-sysadmins"
  },"183": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Scripting Lab Assignment",
    "content": "You’ll be completing a classic first shell scripting assignment: make a phonebook. Write a shell script phonebook which has the following behavior: . | ./phonebook new &lt;name&gt; &lt;number&gt; adds an entry to the phonebook. Don’t worry about duplicates (always add a new entry, even if the name is the same). | ./phonebook list displays every entry in the phonebook (in no particular order). If the phonebook has no entries, display phonebook is empty . | ./phonebook remove &lt;name&gt; deletes all entries associated with that name. Do nothing if that name is not in the phonebook. | ./phonebook clear deletes the entire phonebook. | ./phonebook lookup &lt;name&gt; displays all phone number(s) associated with that name. You can assume all phone numbers are in the form ddd-ddd-dddd where d is a digit from 0-9. | NOTE: You can print the name as well as the number for each line. For an additional challenge, try printing all phone numbers without their names. (See the example below for more details) | . | . For example, . $ ./phonebook new Linus Torvalds 101-110-0111 $ ./phonebook list Linus Torvalds 101-110-1010 $ ./phonebook new Tux Penguin 555-666-7777 $ ./phonebook new Linus Torvalds 222-222-2222 $ ./phonebook list Linus Torvalds 101-110-1010 Tux Penguin 555-666-7777 Linus Torvalds 222-222-2222 # OPTIONAL BEHAVIOR $ ./phonebook lookup Linus Torvalds 101-110-1010 222-222-2222 # ALTERNATIVE BEHAVIOR $ ./phonebook lookup Linus Torvalds Linus Torvalds 101-110-1010 Linus Torvalds 222-222-2222 $ ./phonebook remove Linus Torvalds $ ./phonebook list Tux Penguin 555-666-7777 $ ./phonebook clear $ ./phonebook list phonebook is empty . If you run into an edge case that isn’t described here, you can handle it however you wish (or don’t handle it at all). You can assume all inputs are in the correct format. To help you in this task, skeleton code for this lab can be found here. Once you are done with this task, you can submit your work on Gradescope. As an optional (but recommended) assignment: Try implementing the same Phonebook behavior, but in python! This will highlight some of the strengths and weaknesses between the two languages. If you’re already familiar with python, you may find it helpful to do this before implementing it in bash. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#scripting-lab-assignment",
    "relUrl": "/labs/b3/#scripting-lab-assignment"
  },"184": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Some tips to make things easier",
    "content": ". | bash has an append operator &gt;&gt; which, as you might guess, appends the data from its first argument to the end of the second argument. | . $ cat foobar.txt foobar $ echo \"hello, reader\" &gt;&gt; foobar.txt $ cat foobar.txt foobar hello, reader . | bash also has a redirect operator &gt;, which takes the output of one command and outputs it to a file. | . $ cat foobar.txt foobar $ echo \"hello\" &gt; foobar.txt $ cat foobar.txt hello $ &gt; foobar.txt $ cat foobar.txt $ . | Remember that you can simply write to and read from a file to persist data. | In bash, changing lines can be done through the sed command. If you wish to do so, the format sed -i \"s/&lt;old&gt;/&lt;new&gt;/g\" ./filename may be helpful in this lab (e.g. for deleting a line or part of a line). For example: $ echo \"hello 123\" &gt; foobar.txt # writes hello to foobar.txt $ cat foobar.txt hello 123 $ sed -i \"s/h/j/g\" foobar.txt $ cat foobar.txt jello 123 # You can also use regex: learn more at regex101.com $ sed -i \"s/[0-9]\\{3\\}/world/g\" foobar.txt $ cat foobar.txt jello world . | Recall that bash exposes its command line arguments through the $&lt;integer&gt; positional parameters: | . #!/bin/bash # contents of argscript.sh echo \"$1\" echo \"$2\" . $ ./argscript.sh foo bar foo bar . | In bash, single quotes '' preserve the literal value of the characters they enclose. Double quotes \"\" preserve the literal value of all characters except for $, backticks `, and the backslash \\\\. The most important implication of this is that double quotes allow for variable interpolation, while single quotes do not. You can think of single quotes and the stronger “escape everything” syntax while double quotes are the more lax “escape most things” syntax. | . $ echo '$LANG' $LANG $ echo \"$LANG\" en_US.UTF-8 . | In python, you can interact with command-line arguments through the sys.argv list | . # !/usr/bin/python # contents of argscript.py import sys print(sys.argv[1]) print(sys.argv[2]) # end of file . $ ./argscript.py foo bar foo bar . | python lets you manipulate files with the open function, commonly used with the with control structure | . # !/usr/bin/python # contents of fileman.py with open('./newfile.txt', 'w') as f: f.write(\"hello from python\\n\") # end of file . $ python fileman.py $ cat newfile.txt hello from python . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/#some-tips-to-make-things-easier",
    "relUrl": "/labs/b3/#some-tips-to-make-things-easier"
  },"185": {
    "doc": "Lab 3 - Shell Scripting",
    "title": "Lab 3 - Shell Scripting",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b3/",
    "relUrl": "/labs/b3/"
  },"186": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "Table of contents",
    "content": ". | What is a distribution? | What should I use? . | What is Ubuntu? | . | But what about these “package managers”? | Ubuntu: An Example . | Example | . | But what about software that isn’t in the repositories? . | Warning: | . | So how do I compile? (Exercise 1) | How do I package stuff? | Spelunking (Exercise 2) | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#table-of-contents",
    "relUrl": "/labs/b4/#table-of-contents"
  },"187": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "What is a distribution?",
    "content": "A Linux distribution (often abbreviated as distro) is an operating system made from a software collection that is based upon the Linux kernel and, often, a package management system. -Wikipedia . Note that Linux is not the only kernel! There are alternative kernels such as the Berkeley Software Distribution (BSD) and Solaris. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#what-is-a-distribution",
    "relUrl": "/labs/b4/#what-is-a-distribution"
  },"188": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "What should I use?",
    "content": "There are around 300 actively developed Linux distributions listed on DistroWatch, so it’s often difficult for people to pick. People often switch between distros for months (known as “distro hopping”) to find their favorite. Some popular distributions include Debian, Ubuntu, Arch Linux, Fedora CentOS, and Red Hat Enterprise Linux, but in this course, we’ll only be using Ubuntu. What is Ubuntu? . Ubuntu is a popular Linux distribution built around ease of use. Ubuntu is based on the Debian project and and has spawned its own family of distributions. The defining characteristic of the Debian family of distributions is the use of the DEB package format and the dpkg/apt package managers. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#what-should-i-use",
    "relUrl": "/labs/b4/#what-should-i-use"
  },"189": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "But what about these “package managers”?",
    "content": "If you come from Windows or MacOS, you might be wondering what a package manager is. On those operating systems, the most common method of installing new programs is to run an installer that unpacks and copies files into the correct location, and updates the OS registry to reflect this. Enter the package manager, a centralized way to install, update, and remove software from your computer using verified sources called repositories. Most package managers work in the same way: the package manager gets a list of packages from the repository, and then, when asked to install a package, fetches the package from the repository, verifies that it is legit, and installs it. A package manager is like a librarian. When a patron wants to read a book, the librarian consults a catalog (which is the package database) and then fetches the book from the shelf and gives it to the patron (installing the package). Sometimes, the librarian has to update the catalog because new editions of the books were added (updating the package database). When the patron is done, the librarian knows where to return the book (cleaning up after removing a package). Contrast this to the approach on Windows, where dedicated uninstaller programs are occasionally necessary as the OS does not know where programs install their own files. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#but-what-about-these-package-managers",
    "relUrl": "/labs/b4/#but-what-about-these-package-managers"
  },"190": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "Ubuntu: An Example",
    "content": "In this class, we will be focused on using Ubuntu. As noted before, Ubuntu uses apt or dpkg as its package manager. dpkg was the original tool used for managing packages on Debian. apt was created to make managing packages easier, and introduced the concept of repositories (remote package sources). We invoke the package manager by using apt. Before installing anything, you shoud update your local package metadata list (name, version, etc.) to ensure the package manager installs the latest and most up-to-date packages. To do that, run: . $ sudo apt update . To find the package to install (note this doesn’t actually install any software, so sudo is not required): . $ apt search [package|description] . To install a package, run: . $ sudo apt install package . To remove a package, run: . $ sudo apt remove package . Easy? When you want to upgrade the packages that you have installed when new versions are released, you can do so by calling: . $ sudo apt upgrade . There are also other commands, such as removing unneeded dependencies (dependencies are other packages a package needs), sudo apt autoremove, and purging packages (sudo apt purge). You are encouraged to look at the man pages regarding these commands. Example . We are going to install the C compiler GCC for the next step of the lab. Simply run: . $ sudo apt install gcc . Now check if GCC is installed by running the following to check GCC’s version: . $ gcc --version . This, and all other parts of the lab, should be done on your DigitalOcean student VM, as you cannot install packages on OCF machines. You should be able to connect to your student VM at &lt;OCF username&gt;.decal.xcf.sh by running ssh &lt;username&gt;@&lt;username&gt;.decal.xcf.sh and the password you set when your first logged in, or using the email you received. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#ubuntu-an-example",
    "relUrl": "/labs/b4/#ubuntu-an-example"
  },"191": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "But what about software that isn’t in the repositories?",
    "content": "Sometimes it happens that a program you want to install hasn’t been packaged for your distribution, or hasn’t been packaged at all. You have several options in this scenario to install the software you want: . Warning: . Installing software not from a repository carries the same risks as installing software from a random .exe or .msi on Windows. Linux is popularly considered more secure than Windows or MacOS because of its use of repositories – but a malicious package installed manually can pwn your system as easily as malware on any other OSes. Use common sense! Only manually install from sources you trust. (For users of Ubuntu: PPAs, or third-party repositories, carry the same risks of running malicious third-party code.) . If the developers provide a package compatible with your distribution (.deb for Debian-based distros), you can download that package and install it using: . $ sudo apt install ./path/to/the/package.deb . Another way is to find a generic binary package from the developer. This can come in the form of shady shell scripts, or a binary tarball that you can just extract it and run, or an appimage, which is a special type of executable that includes its own dependencies. The last way is to compile your software from scratch. What does that mean? Open source software must have its source code publicly available somehow, (GitHub, GitLab, their website). If you fetch their source code, it won’t magically run out of the box. The source code is like the recipe, while the software itself is like food. A package is like a dish that is put into a box but we won’t covering the details of making a package yourself (there are tools that do that for you and it varies from platform to platform). ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#but-what-about-software-that-isnt-in-the-repositories",
    "relUrl": "/labs/b4/#but-what-about-software-that-isnt-in-the-repositories"
  },"192": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "So how do I compile? (Exercise 1)",
    "content": "Compiling software on Linux can be a mixed bag. Sometimes, all the dependencies (like libraries) are installed on your computer and there is no fiddling around. Sometimes, the dependencies don’t even exist pre-compiled for your distribution so you have to compile those yourself in order to compile what’s at hand. Most of the time, these steps are simplified through the use of a Makefile, which controls the Make build system. In most source tarballs, there is usually a Makefile that contains a set of directives to compile a project. This is because there are usually multiple files across many directories that need to be compiled together into the final executable. On top of that, there are multiple settings that control, for example, optimizations, size of the executable, static vs. dynamic linking, and whether to link against system libraries or alternatives. Many projects that have to be compiled are usually in C, C++, or similar lower-level languages. On most Linux distributions, there are usually three compiler “options”. There is the GNU Toolchain which provides gcc or the GNU C Compiler, LLVM which provides clang, and Intel’s proprietary toolkit, icc. Both gcc and clang are open-source and free software. To compile software that provides a Makefile, assuming you have the dependencies, simply type: . $ make . This is will usually choose the correct compiler and compile the whole project. Once the compilation is done, the resulting executables are usually stored in the ./bin or ./build directories. GCC and clang also have compiler flags that allow certain features to be enabled. Usually the flags that actually matter are optimization flags. Depending on what you want to optimize for, either space or memory or speed, there is a flag for it. Now, we will make a very simple application in C that prints “Hello Penguin!” named hellopenguin. Run: . $ nano hellopenguin.c . to create a file named hellopenguin.c, and type in the following: . #include &lt;stdio.h&gt; int main() { printf(\"Hello Penguin!\"); return 0; } . Now save and exit. We will now compile the source file that you have just written: . $ gcc hellopenguin.c -o hellopenguin . What this does is take the source file hellopenguin.c and compile it, writing the executable output to a file named hellopenguin. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#so-how-do-i-compile-exercise-1",
    "relUrl": "/labs/b4/#so-how-do-i-compile-exercise-1"
  },"193": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "How do I package stuff?",
    "content": "Packaging manually for Debian can be very hard and frustrating, especially for first timers. That’s why for this class, we’ll be using a really cool Ruby package called fpm which simplifies the task of packaging a lot. Note: This method is a great way to package your own applications more quickly, but isn’t up to the standards required for publishing a package to the official repositories. We won’t be covering them here, but if you are interested in learning more you can do so here. First, make sure ruby and its own package manager called gem is installed. If they aren’t, run sudo apt install ruby ruby-dev rubygems build-essential. Now run the following to install fpm locally: . $ gem install fpm --user . Try invoking fpm and if it doesn’t work, add ~/.gem/ruby/2.5.0/bin to your PATH (list of directories to find executables). To do that, add this to your .bashrc, or just type the following into Bash to temporarily add it to your PATH: . $ export PATH=~/.gem/ruby/2.5.0/bin:$PATH . Now we will create a very simple package using the hellopenguin executable that you made above. First, we will make a new folder named packpenguin and move into it: . $ mkdir packpenguin $ cd packpenguin . Now we will create the folder structure of where the executable will reside. In Ubuntu, user-level packages usually reside in the folder /usr/bin/. $ mkdir -p usr/bin . Now move your hellopenguin into the packpenguin/usr/bin/ folder. $ cd ../ # cd into the directory where the hellpenguin executable is $ mv hellopenguin packpenguin/usr/bin/ . Now we will create a package called hellopenguin. Move into the parent directory of the hellopenguin folder and invoke the following: . $ fpm -s dir -t deb -n hellopenguin -v 1.0~ocf1 -C packpenguin . This specifies that you want to take in a directory, using the -s flag, and to output a .deb package using the -t flag. It takes in a directory called packpenguin, using the -C flag, and output a .deb file named hellopenguin, using -n, with a version number of 1.0~ocf1, using the -v flag. Now test it by invoking apt and installing it, replacing &lt;version+arch&gt; with the appropriate version and architecture that the package is built for, which will be provided by fpm when the package is built: . $ sudo apt install ./hellopenguin_&lt;version+arch&gt;.deb . Now you should be able to run hellopenguin by doing the following: . $ hellopenguin . If all of this works, you’re ready to head over to Gradescope and answer the questions there! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#how-do-i-package-stuff",
    "relUrl": "/labs/b4/#how-do-i-package-stuff"
  },"194": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "Spelunking (Exercise 2)",
    "content": "Let’s shift gears a bit and take a look at a popular package to learn more about how it’s structured! For this next section, we will choose a package from the Debian repository to download and extract. Note that this exercise is mainly for exploration and learning purposes- you wouldn’t actually install a package using this method. Step 1: Choose a package Here’s a list of packages published on the Debian repository. If you see one that seems interesting or you’ve used before, note its name and you can use it for this exercise! . If you are unsure or would like suggestions, here are some examples: htop, less, git . Step 2: Download and extract the package Once you’ve decided on a package, you can download it from the terminal using the command apt download &lt;packagename&gt;. You should now have a .deb file in your current directory. In order to extract the .deb, you can use the command: ar x &lt;your .deb file&gt;. Now, you should have two more files, control.tar.gz and data.tar.gz. You can extract these in whichever way you like. One relatively easy way to do so is via the aunpack command, which is available if you sudo apt install atool. Now, you should have two folders named control and data. | control contains installation scripts and general package information. | data contains the actual stuff in the package that will be installed to your filesystem. Common folders that exist within data are usr/bin (binaries) and usr/share (documentation). | . Step 3: Explore! Using commands like cd, cat, vim, and less, spend some time looking through the files to see what’s inside a typical package. While many of the scripts may be hard to understand or somewhat irrelevant, see if you can learn anything about which folders they are located in and what their general purpose is! . Now, answer the following questions on Gradescope: . | What package did you choose? | What are the package’s dependencies? What file can you find them in? | What’s one interesting thing you learned about this package? (Binaries you never knew existed, easter eggs in documentation, a cool pre-install script…) | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/#spelunking-exercise-2",
    "relUrl": "/labs/b4/#spelunking-exercise-2"
  },"195": {
    "doc": "Beginner Lab 4 - Debian, packages, compiling software",
    "title": "Beginner Lab 4 - Debian, packages, compiling software",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b4/",
    "relUrl": "/labs/b4/"
  },"196": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Table of contents",
    "content": ". | Overview | MAC . | IP | ARP | DNS | DNS Records | TCP and UDP | Ports (Optional) | . | Sysadmin Commands | Exercises . | Short Answer Questions | Programming Exercise | Submission | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#table-of-contents",
    "relUrl": "/labs/b5/#table-of-contents"
  },"197": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Overview",
    "content": "It is undeniable that the internet is an important system that has redefined our world. The ability to develop networks and allow devices to communicate is critical to modern day computer systems. This lab will take a look into the basics of computer networking and then examine networks through the perspective of a sysadmin. We will be using web browsing as an analogy to understand the basics of networking. What exactly happens when I go web browsing for cat pictures? . But first let’s take a short dive into the details of networking. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#overview",
    "relUrl": "/labs/b5/#overview"
  },"198": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "MAC",
    "content": "Media access control (MAC) addresses are identifiers uniquely assigned to network interfaces. Since the MAC address is unique this is often referred to as the physical address. The octets are often written in hexadecimal and delimited by colons. An example MAC address is 00:14:22:01:23:45. Note that the first 3 octets refer to the Organizationally Unique Identifier (OUI) which can help identify manufacturers. Fun fact – the 00:14:22 above is an OUI for Dell. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#mac",
    "relUrl": "/labs/b5/#mac"
  },"199": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "IP",
    "content": "IP addresses are means of identifying devices connected to a network under Internet Protocol. There are two versions of the internet protocol, IPv4 and IPv6, that which differ on the size of their addresses. An example IPv6 address is 2001:0db8:85a3:0000:0000:8a2e:0370:7334 which is considerably longer than an IPv4 address like 127.0.0.1. For the sake of time we will only go over IPv4, but IPv6 is certainly gaining ground and worth checking out! . IPv4 addresses are 32 bits, i.e. 4 bytes, long and are delimited by a dot (.) every byte. An example IPv4 address is 127.0.0.1. Coincidentally this address is known as the loopback address which maps to the loopback interface on your own machine. This allows network applications to communicate with one another if they are running on the same machine, in this case your machine. But why 127.0.0.1 and not 127.0.0.0 or 127.0.0.2? . The answer is that 127.0.0.1 is simply convention, but technically any address in the network block 127.0.0.0/8 is a valid loopback address. But what exactly is a network block? . In IPv4 we can partition a block of addresses into a subnet. This is written in a format known as CIDR. Let’s take the subnet above as an example 127.0.0.0/8. The number that comes after the slash (/), in this case 8, is the subnet mask. This represents how many bits are in the network address, the remaining bits identify a host within the network. In this case the network address is 127.0.0.0 and the Mask is 255.0.0.0. So 127.0.0.1 would be the first host in the 127.0.0.0/8 network and so on and so forth. This diagram provides a visual breakdown of CIDR addressing . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#ip",
    "relUrl": "/labs/b5/#ip"
  },"200": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "ARP",
    "content": "Address Resolution Protocol (ARP) is a protocol used to resolve IP addresses to MAC addresses. In order to understand ARP, we first discuss two ways to send a frame, unicast and broadcast. In the context of Layer 2, unicasting a frame means to send that frame to exactly one MAC address. On the other hand, broadcasting a frame by sending it to the broadcast address means the frame should be sent to every device on the network, effectively “flooding” the local network. For example let’s imagine a sender, A, who has MAC 00:DE:AD:BE:EF:00, broadcasting a message that essentially asks “Who has IP address 42.42.42.42 please tell A at 00:DE:AD:BE:EF:00”. If a machine, B, with MAC 12:34:56:78:9a:bc has the IP address 42.42.42.42 they send a unicast reply back to the sender with the info “12:34:56:78:9a:bc has 42.42.42.42”. The sender stores this information in an arp table so whenever it receives packets meant for machine B i.e. a packet with an destination IP address of 42.42.42.42 it sends the packet to MAC it received from B. In order to route IP packets, devices have what is known as a routing table. Routing entries are stored in the routing table and they are essentially rules that tell the device how packets should be forwarded based on IP. A routing entry specifies a subnet and the interface that corresponds to that entry. The device chooses an entry with a subnet that is most specific to a given packet and forwards it out the interface on that entry. Routing tables are usually to also have a default gateway. This serves as the default catch all for packets in the absence of a more specific matching entry. Take this routing table for example. default via 10.0.2.2 dev eth0 10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 10.0.2.128/25 dev eth0 proto kernel scope link src 10.0.2.15 192.168.162.0/24 dev eth1 proto kernel scope link src 192.168.162.162 . A packet destined for 8.8.8.8 would be forwarded out eth0, the default gateway. A packet destined for 10.0.2.1 would be forwarded according to the second entry, out of eth0. A packet destined for 10.0.2.254 would be forwarded according to the third entry, out of eth0. A packet destined for 192.168.162.254 would be forwarded according to the fourth entry, out of eth1. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#arp",
    "relUrl": "/labs/b5/#arp"
  },"201": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "DNS",
    "content": "We’ve gone over IP addresses and how they are means of communicating with a host over IP, but while IP addresses are machine friendly (computers love numbers) they aren’t exactly human friendly. It’s hard enough trying to remember phone numbers, memorizing 32 bit IP addresses isn’t going to be any easier. But it’s much easier for us to remember names like www.google.com, www.facebook.com, or coolmath-games.com. So out of this conflict the Domain Name System (DNS) was born as a compromise between machine friendly IP addresses and human friendly domain names. DNS is a system that maps a domain name like google.com to 172.217.6.78. When you query for google.com your computer sends out a DNS query for google.com to a DNS server. Assuming things are properly configured and google.com has a valid corresponding address you will receive a response from an authoritative server that essentially says “google.com has IP address x.x.x.x”. Now let’s flush out this black magic a bit… . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#dns",
    "relUrl": "/labs/b5/#dns"
  },"202": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "DNS Records",
    "content": "DNS servers store data in the form of Resource Records (RR). Resource records are essentially a tuple of (name, value, type, TTL). While there are a wide variety of types of DNS Records the ones we are most concerned with are . | A records name = hostname value = IP address . This record is very simply the record that has the IP address for a given hostname, essentially the information we want to end up with. | NS records name = domain value = name of dns server for domain . This record points to another dns server that can provide an authoritative answer for the domain. Think of this as redirecting you to another nameserver. | CNAME records name = alias value = canonical name . These records point to the canonical name for a given alias for example docs.google.com would be an alias which simply points to documents.google.com try www.facebook.com . | MX records The record used by mail service. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#dns-records",
    "relUrl": "/labs/b5/#dns-records"
  },"203": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "TCP and UDP",
    "content": "Now we will transition into a discussion on the protocols at the transport layer. The two most well known protocols at this layer are Transmission Control Protocol (TCP) and User Datagram Protocol (UDP). TCP is a stateful stream oriented protocol that ensures reliable transport. Reliable transport essentially guarantees that information arrives wholly intact and in order at the destination. TCP is a connection oriented protocol which means it must first establish a connection before sending any data. This connection exchanges information that is the mechanisms TCP uses to provide reliable transport amongst other features. A TCP connection begins with something known as the TCP handshake. The TCP handshake consists of setting certain flags in the TCP header of packets exchanged between sender and receiver. The sender initiating a TCP connection by first sending a SYN, a packet with the SYN flag set. The server acknowledges this connection request by sending back a SYN-ACK, a packet with both the SYN and ACK flags set. The client acknowledges this by sending one final ACK back to the server, and the connection is then established. TCP then begins transmitting data and if it successfully arrives on the other end of the connection then an ACK is issued. Therefore if data is lost, reordered, or corrupted, TCP is capable of recognizing this and sends a request for retransmission of any lost data. TCP also has a procedure to close connections. We only consider a graceful termination here, abrupt terminations have a different procedure we will not go over. If you’re interested, CS168 has some great material here. Let’s assume machine A wants to close its connection to machine B. A begins by sending a FIN. B must respond by sending a FIN and an ACK. If B only sends a ACK the connection persist and additional data can be sent until an FIN is sent. On the other hand B can also send just one packet with both FIN and ACK flags set, i.e. FIN+ACK if B is ready to close the connection and doesn’t need to send additional data Once A has received a FIN and an ACK it sends one last ACK to signal the connection termination. UDP is stateless connectionless protocol. UDP focuses on sending messages in datagrams. Being connectionless UDP also doesn’t incur the overhead of the TCP handshake and termination. UDP also makes no guarantees about reliable transport so messages may be corrupted, arrive out of order, or not arrive at all. For this reason UDP is sometimes called Unreliable Datagram Protocol. While UDP makes no guarantees about reliable transport it doesn’t suffer from the overhead of establishing and closing connections like in TCP. UDP is therefore ideal for usage cases where we just want to send packets quickly and losing a few of those isn’t disastrous. Moreover, compared to TCP each UDP datagram sent needs to be individually received. While for TCP you pass a stream of data that is transparently split into some number of sends and the data stream is transparently reconstructed as a whole on the other end. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#tcp-and-udp",
    "relUrl": "/labs/b5/#tcp-and-udp"
  },"204": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Ports (Optional)",
    "content": "Ports define a service endpoint, broadly speaking – ports mark a point of traffic ingress and egress. Whereas IP addresses connect hosts, ports connect process that run on such hosts. Only one process can be bound to a port at a time. Ports are represented by a 16 bit number meaning thus ranging from 0 to 65535. Ports from 0 to 1023 are well known ports, i.e. system ports. Using these ports usually has a stricter requirement. 1024 to 49151 are registered ports. IANA maintains the official list of well-known and registered ranges. The remaining ports from 49152 to 65535 are ephemeral ports which can be dynamically allocated for communication sessions on a per request basis. Some port numbers for well known services are as follows: . | Service | Port | . | SSH | 22 | . | DNS | 53 | . | HTTP | 80 | . | HTTPS | 443 | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#ports-optional",
    "relUrl": "/labs/b5/#ports-optional"
  },"205": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Sysadmin Commands",
    "content": "As a sysadmin, trying to diagnose network issues can often be pretty challenging. Given the scale and complexity of networks, it’s tough trying to narrow down the scope of a problem to a point of failure. What follows is a list of commands/tools that can help with triaging problems. There are a lot of tools and we don’t expect you to memorize every single detail. However, it is important to know what tools exist and when to use them when problems inevitably arise. If you ever need more details the man pages for these commands are a great place to turn to for reference. Tools also tend to overlap in functionality – for example there are multiple tools that can display interface information or test connectivity. When possible, it is a good idea to use multiple tools to cross-check one another. Note that when it comes to real world networks there are even more factors to consider that we haven’t touched on like network security. For example, two machines can have a fully functioning connection but if one machine has been configured to drop all packets then it might seem as if they aren’t connected. So take the output of these tools with a grain of salt, they a means of narrowing down issues. It is important not to misinterpret outputs or jump to conclusions too quickly. | hostname A simple and straightforward command that can display information about a host, IP addresses, FQDN, and etc. Make sure to also check out host, which is a similar command that provides more detailed information by doing a lookup on a given name. | ping Another simple command, most of the time you’ll be using ping as a first step towards testing connectivity. If ping can’t reach a host then there is likely an issue with connectivity. The ping tool does this by sending out ICMP messages to the host expecting a response. (More on the protocol here) . Moreover ping also provides metrics for Round Trip Time (RTT) and packet loss. Round trip time is defined as the time it takes for a response to arrive after sending the ping packet. These can prove to be very useful statistics. | traceroute Traceroute sends packets Time to Live (TTL) equal to the number of hops. Routers decrease the value of TTL for incoming packets. If a packet’s TTL = 0 then the router drops it and may send back diagnostic information to the source about the router’s identity. Otherwise the router continues forwarding the packet. Traceroute provides a detailed view of the routers that a packet traverses while on its way to a destination. If router does not respond within a timeout then traceroute prints an asterisk. | arp Provides info on and the ability to manipulate the ARP cache of the system. With arp you can display the system arp table. Add, remove, or modify arp entries and much more. | dig Utility for doing dns query and triaging DNS issues. Dig by default performs queries to nameservers in /etc/resolv.conf but some options allow you to: specify name server, choose query type (iterative vs recursive), and much more – making dig a very flexible DNS tool. | ip ip is a command with many subcommands offering a lot of functionality – so much it can be overwhelming at first. You will most commonly be using ip to display/modify routing, IP addresses, or network interfaces. It will take time to get use to how much functionality is included in this command but for reference here is a pretty compact cheatsheet. A few common use cases include: ip addr which displays information on your IP addresses, ip route which displays information on your routing table, and ip link which displays information about your network interfaces. | curl cURL does as its name suggests, and allows you to see the contents at certain URLs. Beyond this it’s also an extremely powerful program that lets you interact with and inspect servers over several different protocols certain protocols such as HTTP, FTP, etc … . Be sure to check out its documentation for specific use cases. | wget wget is quite similar to curl in the sense that they are both command line tools designed to transfer data from or to servers with certain protocols and both come with a bunch of features. There are differences between the commands, two notable examples being that wget is command line only meaning there no library or API. However, wget has a big advantage of being able to download recursively. You can read a bit more on the two tools here. | netstat (Optional) This tool is good for printing network connections, routing tables, and probing sockets, amongst other functions. netstat also has functionality to probe sockets for activity and displays information such protocol (UDP/TCP) . If you are investigating sockets ss and lsof are also options you may want to consider . | tcpdump (Optional) Perfect for monitoring incoming or outgoing traffic on a machine. tcpdump offers countless options when it comes to analyzing traffic: it can capture packets, log traffic, compute metrics, filter traffic, monitor specific interfaces, etc. As a primer you can check out these examples. | nc (Optional) Netcat is a very powerful tool that can be used for just about anything involving TCP or UDP. It can open TCP connections, send UDP packets, listen on arbitrary TCP and UDP ports, do port scanning, and deal with both IPv4 and IPv6. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#sysadmin-commands",
    "relUrl": "/labs/b5/#sysadmin-commands"
  },"206": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Exercises",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#exercises",
    "relUrl": "/labs/b5/#exercises"
  },"207": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Short Answer Questions",
    "content": ". | Does HTTP use TCP or UDP and why? How about Discord and Skype, why? | Who manufactured the NIC with mac address 52:54:00:d7:ce:cc? | How many distinct hosts can 127.0.0.0/8 contain? | What types of records do you get when you perform a DNS lookup of facebook.com? | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#short-answer-questions",
    "relUrl": "/labs/b5/#short-answer-questions"
  },"208": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Programming Exercise",
    "content": ". | Write a shell script is_on.sh so that is_on.sh host shows whether host is online. If it is, show “OK”. If it’s not, show “Host is not reachable”. Don’t show anything else. Some clarifications: . | A host is online here means the ping to the host is successful | Just ping the server once (we assume the internet connection is reliable and the packet will not be dropped) | You can use man ping to see how to make the ping only ping the server once, and what the return value of ping command means. Use if to decide what to print. | . | Write a shell script mac.sh which processes the output of ip command and displays the MAC address of the network interface eth0 of your VM. | First figure out how to use ip command to get an output which contains the information we want | Then use head and tail command and pipes to tailor ip’s output to one line | Use cut command (Examples) to get the MAC address. Since we know that the MAC address has fixed length, feel free to count the indices. | The final shell script only has to have one line, although a answer with multiple lines are also acceptable. | . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#programming-exercise",
    "relUrl": "/labs/b5/#programming-exercise"
  },"209": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Submission",
    "content": "Go to Gradescope for submission. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/#submission",
    "relUrl": "/labs/b5/#submission"
  },"210": {
    "doc": "Lab 5 - Introduction to Networking",
    "title": "Lab 5 - Introduction to Networking",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b5/",
    "relUrl": "/labs/b5/"
  },"211": {
    "doc": "Lab 6 - Processes and Services",
    "title": "Table of contents",
    "content": ". | Overview | Which processes are running on my system? | htop . | The process hierarchy | Orphan processes | . | Cron | Job Control | Exploration | Submission | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/#table-of-contents",
    "relUrl": "/labs/b6/#table-of-contents"
  },"212": {
    "doc": "Lab 6 - Processes and Services",
    "title": "Overview",
    "content": "At any given moment, there are anywhere from dozens to thousands of process running on a Unix system. The large majority of these processes, called daemons, run in the background. Daemons are crucial to having a usable system and provide much of a system’s core functionality, including the graphics server, sound server, and networking services to name a few. Today we’ll explore these background processes and create some of our own! Make sure the following exercises are executed on your VM unless explicitly specified otherwise. Make sure to answer the questions on Gradescope as you work through the lab! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/#overview",
    "relUrl": "/labs/b6/#overview"
  },"213": {
    "doc": "Lab 6 - Processes and Services",
    "title": "Which processes are running on my system?",
    "content": "Open up a terminal and run the ps command. You should see something like this: . PID TTY TIME CMD 3371 pts/2 00:00:00 zsh 3416 pts/2 00:00:00 ps . Now open up another terminal and run sleep 1000 &amp;, which start a sleeping process in the background. Then run ps. It should look like: . ~ ❯ sleep 100 &amp; [1] 3726 ~ ❯ ps PID TTY TIME CMD 3371 pts/2 00:00:00 zsh 3726 pts/2 00:00:00 sleep 3752 pts/2 00:00:00 ps . In the first terminal run ps again. You should notice that the sleep process is not showing up, even though the thousand seconds haven’t expired. (Exercise 1) Why do you think this behavior occurs (hint: TTY column)? . We can get the process to display on the first terminal by running ps -u, which displays all the processes running as your user. Notice the PID column; each process has a unique ID assigned to it by the kernel. One thing we can do with this PID is send signals to the process. sleep 1000 is pretty useless, so go ahead and kill it – kill 3726 (substitute 3726 with whatever PID ps outputted for you). The most common use of ps is to run ps -ef to see all the processes running on the system. Run ps -e and ps -f independently to see how the flags work together. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/#which-processes-are-running-on-my-system",
    "relUrl": "/labs/b6/#which-processes-are-running-on-my-system"
  },"214": {
    "doc": "Lab 6 - Processes and Services",
    "title": "htop",
    "content": "Make sure htop is installed by running sudo apt install htop. Now, open up a terminal and run the htop command. htop can be thought of as a more extensive version of ps -ef, whereby process stats are updated in real-time. First press &lt;F2&gt;, scroll down to Display options, and check “Hide userland process threads.” We won’t be dealing with those in this lab. Now open up another terminal and SSH into your VM. Run the command yes. It uses a lot of resources as it prints a continuous stream of y’s. (Exercise 2) What resource specifically does the yes command exhaust? If you are having trouble finding this, press &lt; to choose which resource to order processes by. Make sure to quit out of yes (^C) once you are finished. The process hierarchy . Run htop once more. This time click &lt;F5&gt; to enter Tree View. You should see a visual representation of the process hierarchy on your system, with everything stemming from /sbin/init (systemd). For curious students that are interested in seeing a more extensive process hierarchy on a large system, you are encouraged to run htop on the OCF server tsunami. Let us know of any cool processes that you find! . Orphan processes . Open a second terminal and ssh to your VM. Now run sleep 1000 &amp;. You should see this new process pop into your htop session on your first terminal. If not, press &lt;F3&gt; and search for “sleep.” (Exercise 3) What is its parent? . Select this parent and press &lt;F9&gt; to kill it. Send the SIGTERM signal. The sleep process now has init as its new parent, which is PID 1. What you just did is manually orphan a process; when that happens said process is subsequently re-parented by the init process. Now go through the same steps again. This time, send the parent a SIGHUP (hangup) signal. Can you still find the sleep process? When SIGHUP is sent to a parent shell, the parent subsequently sends hangup signals to any child processes before terminating; all processes that receive SIGHUP from a parent shell will terminate – this is one way to avoid creating orphan processes. If you are interested in learning about the different signals, run man 7 signal. Note that you can run man man for an explanation about the different manual section numbers. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/#htop",
    "relUrl": "/labs/b6/#htop"
  },"215": {
    "doc": "Lab 6 - Processes and Services",
    "title": "Cron",
    "content": "So much infrastructure in the computing world relies on scheduled processes. This is the job of the cron daemon, an automatic process scheduler. For example, at the OCF, we use a cron job that runs every thirty minutes to keep our servers and desktops updated via puppet. Process scheduling is defined in a crontab file. Each line in the file represents a different job. A line consists of a time descriptor, typically a sequence of 5 terms separated by spaces, and a command to be run at that time. For example, the line: . 5 12 2 8 * echo \"It is 12:05 on August 2nd\" &gt;&gt; $HOME/crontest.txt . would append “It is 12:05 on August 2nd” to a file in your home directory at 12:05 on August 2nd. You can find an interactive editor to help you with the time descriptors at crontab.guru! . To get a feel for the cron scheduler, we’re going to write a basic cron job. (Exercise 4) Open the cron editor by running crontab -e (if the editor of your choice isn’t being launched, set the EDITOR environment variable), which will create a crontab for your user. Below is a sample task. Put this in your crontab: . * * * * * date +\"\\%T\" &gt;&gt; $HOME/timestamps.txt . Right now this runs every minute. Modify it to run every five minutes and make a note of the line you wrote. Then, quit out of the editor. If you get stuck, visit crontab.guru! (Seriously, it’s a lifesaver!) . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/#cron",
    "relUrl": "/labs/b6/#cron"
  },"216": {
    "doc": "Lab 6 - Processes and Services",
    "title": "Job Control",
    "content": "For this section of the lab you will need to get the necessary code from GitHub: . git clone https://github.com/0xcf/decal-labs.git . If you already have the code run git pull in your decal-labs directory. Now enter the b6 directory in the decal-labs repository and split your terminal with the multiplexer of your choice (I recommend tmux). In one pane run ./job.sh &gt; ~/count and in the other run less +F ~/count. You should see the less command increments every half a second or so. Now run Ctrl+Z in the pane with the job.sh command. This will suspend the process. (Exercise 5) What happens when you suspend the job command? . Now, let’s resume our suspended process. Since we only have one job, we can just run bg. (Exercise 6) What happens after running the bg command? . Now let’s bring our job to the foreground. First run jobs -l. You should see both the job number (in brackets) and the pid of the job. We’ll bring the job to the foreground by running fg %i (where i is the number that showed up in the brackets when you ran jobs -l) and kill it using Ctrl+C. (Exercise 7) What is another way we can kill the job (Hint: kill also recognizes the % syntax)? . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/#job-control",
    "relUrl": "/labs/b6/#job-control"
  },"217": {
    "doc": "Lab 6 - Processes and Services",
    "title": "Exploration",
    "content": "Congratulations, you have completed the lab! This is just the tip of the iceberg when it comes to processes. If you want to learn more, here are some related topics you can look into. | Everything you wanted to know about Unix threads, processes, process groups and sessions. Bear in mind that this document is a little dated when it comes to the code about threads, and its description of what happens when a pseudotty is closed is not actually correct. | Zombie Processes . | Wikipedia’s article on init systems . | The construction of a basic init system - Yelp’s dumb-init, a lightweight init system for docker containers . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/#exploration",
    "relUrl": "/labs/b6/#exploration"
  },"218": {
    "doc": "Lab 6 - Processes and Services",
    "title": "Submission",
    "content": "Go to Gradescope for submission. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/#submission",
    "relUrl": "/labs/b6/#submission"
  },"219": {
    "doc": "Lab 6 - Processes and Services",
    "title": "Lab 6 - Processes and Services",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b6/",
    "relUrl": "/labs/b6/"
  },"220": {
    "doc": "Lab 7 - Services",
    "title": "Table of contents",
    "content": ". | Using systemd . | What services are running right now? | Controlling Services | Creating a service | Debugging | Crash the service! | . | Exploration | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b7/#table-of-contents",
    "relUrl": "/labs/b7/#table-of-contents"
  },"221": {
    "doc": "Lab 7 - Services",
    "title": "Using systemd",
    "content": "What services are running right now? . On your provided virtual machine, run systemctl. You’ll see a long table of every unit known to systemd. Let’s narrow it down to services for now. Run systemctl --type=service. Now you can see a list of all services running on your virtual machine. Each of these services is a daemon running in the background. Do you see any familiar services running? . Controlling Services . Now let’s use systemd to control a an nginx web server. Again on your virtual machine, install nginx by issuing sudo apt install nginx. Once that is done, we can tell systemd to start the service with the following: sudo systemctl start nginx. Run systemctl status nginx to ensure it is running and navigate to http://yourvm.decal.xcf.sh/ – you should be greeted by the nginx default landing page. Now let’s make nginx listen for connections on the nonstandard port 420. Using a terminal text editor, change the following lines in /etc/nginx/sites-available/default: . listen 80 default_server; listen [::]:80 default_server; . to: . listen 420 default_server; listen [::]:420 default_server; . Tell systemd that nginx has changed configuration and needs reloading with: sudo systemctl reload nginx. Now, accessing http://yourvm.decal.xcf.sh/ should now give you a connection refused error and your webserver will only be accessible via http://yourvm.decal.xcf.sh:420/. Note that not all services can be reloaded; systemd will notify you if this is the case and such services will have to be restarted instead with: sudo systemctl restart yourservice. Finally go ahead and stop the nginx service with sudo systemctl stop nginx. Exercise 1: What is the difference between systemctl reload yourservice and systemctl restart yourservice? . Exercise 2: Which file determines what exactly happens when systemctl reload yourservice is called on different services? . Creating a service . Let’s set up a web server and create a systemd unit for it. Make sure git is installed; if it’s not, install it using apt. To get the code run: git clone https://github.com/0xcf/decal-labs.git . If you have already cloned the repository, go to your decal-labs directory and run git pull. The materials for this part of the lab will be in the b7 directory. We will also need to install some dependencies. Go ahead and execute the following commands: . sudo apt update sudo apt install build-essential make python-virtualenv . Now run ./run. This should start up a simple web server at http://yourvm.decal.xcf.sh:5000 . If you’re having issues reaching the site on your browser, try accessing it from a shell using a command like curl . Your mission, should you choose to accept it, is to write a systemd service that manages this web server. To do this, make a new unit file in /etc/systemd/system/toy.service (using sudo to give yourself privileges if necessary). Refer to the slides for an example; DigitalOcean also has a good guide on how to write systemd units. Here is a skeleton; all you need to do is fill in the values for each field. [Unit] Description= Requires= After= [Install] WantedBy=multi-user.target [Service] ExecStart= User= . Some questions worth considering while writing this unit file are: . | What units needs to be started before a webserver starts (Hint: network)? | What script should systemd run to start the webserver? | Units run by root as default. Is that a safe practice for web servers? | . You are encouraged to experiment with other fields as suits your liking. | Hint: If you’re stuck, try taking a look at the unit file for nginx. | Hint: If you can’t find the service file, know that a certain command used to display service information for a given service will also display the unit file path | . Once you have finished creating toy.service, let’s start the service and have the it start whenever our machine is booted. sudo systemctl start toy.service sudo systemctl enable toy.service . Debugging . You can check if the unit file succeeded by running systemctl status toy.service. If you are having issues with the unit file or the web server, check the logs for this unit by running journalctl -u toy.service. If you run into errors don’t get demoralized (it is, after all, only a decal); as a sysadmin you’ll have to become comfortable making sense of arcane error messages. Crash the service! . One of the great benefits of using systemd to manage your services is that you don’t have to worry unnecessarily about bringing a process back up if it crashes. So let’s crash the service! You can do this by either sending a POST request with the json payload '{\"crash\":\"true\"}' to http://yourvm.decal.xcf.sh:5000/crash (Hint: use curl with the --data option) or by killing the webserver manually by sending a signal (using kill) – both will cause the unit to crash. You can verify if you succeeded by running systemctl status toy.service, and the unit should either be in an inactive or failed state, depending on how you killed it. Now add the following the /etc/systemd/system/toy.service under the Service directive: . Restart=always RestartSec=10 . To tell systemd that the unit file has changed run sudo systemctl daemon-reload. Now start your webserver and kill it again in any way you please, and you should see that it come back online after 10 seconds! Note that you can also run daemon-reload and change a unit file while a service is running. Exercise 3: Submit your toy.service file! . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b7/#using-systemd",
    "relUrl": "/labs/b7/#using-systemd"
  },"222": {
    "doc": "Lab 7 - Services",
    "title": "Exploration",
    "content": "Congratulations, you have completed the lab! This is just the tip of the iceberg when it comes to processes and services. If you want to learn more, here are some related topics you can look into. | Wikipedia’s article on init systems | The construction of a basic init system | Yelp’s dumb-init, a lightweight init system for docker containers | Zombie Processes | Socket activation | Systemd has been the source of a considerable amount of controversy. Opponents allege that it violates the Unix philosophy of “do one thing and do it well”, and that it has had too much scope creep, among other complaints. | Everything you wanted to know about Unix threads, processes, process groups and sessions. Bear in mind that this document is a little dated when it comes to the code about threads, and its description of what happens when a pseudotty is closed is not actually correct. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b7/#exploration",
    "relUrl": "/labs/b7/#exploration"
  },"223": {
    "doc": "Lab 7 - Services",
    "title": "Lab 7 - Services",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b7/",
    "relUrl": "/labs/b7/"
  },"224": {
    "doc": "Lab 8 - Security Fundamentals",
    "title": "Table of contents",
    "content": ". | Encryption and Decryption . | Symmetric Cryptography | Asymmetric Cryptography . | GPG Keyring Abstraction | . | Signatures | . | Hashing (Checksums) | File Security | Lab Checkoff . | Submission | Setup | Encryption and Decryption | Hashing (Checksums) | File Security | . | . For this lab, we will use GnuPG (also referred to as GPG), a free implementation of the OpenPGP standard. As stated by GPG’s website: . GnuPG allows you to encrypt and sign your data and communications; it features a versatile key management system, along with access modules for all kinds of public key directories. The GPG manual page might be useful. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b8/#table-of-contents",
    "relUrl": "/labs/b8/#table-of-contents"
  },"225": {
    "doc": "Lab 8 - Security Fundamentals",
    "title": "Encryption and Decryption",
    "content": "Encryption takes in a plaintext and a key, returning ciphertext. Decryption takes in a ciphertext and a key, recovering and returning the original plaintext only if the decryption key is valid. The keys for encryption and decryption are long strings of random bits that make it computationally infeasible for an attacker to guess the key and decrypt a ciphertext. Symmetric Cryptography . In symmetric cryptography, the keys used for encryption and decryption are the same. To try it out: . | gpg --symmetric [FILE] on any file to output a [FILE].gpg file which is the encrypted version of the inputted file. You’ll need to enter a password when encrypting the file. | gpg --decrypt [FILE].gpg on the encrypted version of original file, upon which you’ll need to enter the original password. | . In this GPG implementation, encryption and decryption of your file both require knowledge of a single password, which in this case serves as the symmetric key. Asymmetric Cryptography . In asymmetric cryptography, two separate keys are respectively used for encryption and decryption. These two keys come in a public-private pair. The public key is made known publicly and used to encrypt data. Whereas, the private key is kept secret by the owner and used to decrypt data. Encryption of a file with a public key implies that only someone with the corresponding private key can the decrypt the resulting encrypted file. GPG Keyring Abstraction . GPG uses a “keyring” as a centralized location to hold all of a user’s keys. You’ll need to add/import a key to your keyring if you wish to use it and keep it around. Similarly, if you wish to share a key with someone else, you can export your key (which makes a copy of your key) and have them import it to their keyring. To try it out: . | gpg --full-generate-key to generate a GPG public-private key pair. It’ll ask for a password. If your machine is taking a while to generate a key, it may be due to a lack of entropy (randomness) that is needed for a long, random key. sudo apt-get install haveged will install a daemon that generates entropy. | gpg --recipient [RECIPIENT] --encrypt [FILE] which’ll encrypt [FILE] with [RECIPIENT]’s public key (for now, try encrypting a file with your own public key). | gpg --decrypt [FILE].gpg will search through your keyring and decrypt the file with the appropriate private key (if you possess the correct private key, of course). You don’t need to specify which key to decrypt a file with because GPG-encrypted files and keys contain metadata that allow GPG to pick the correct key from the keyring to decrypt the file with. | . Signatures . The asymmetric scheme involving encryption with public key and decryption with private key can also be reversed to implement digital signatures whose role is equivalent to that of physical signatures. In this reversed scheme, the private key is used to sign a file, producing a signature on that file. And the corresponding public key is used to verify the signature. Therefore, only a person with the private key can produce a signature, but anyone with the corresponding public key can verify that signature. To try it out: gpg --sign [FILE] to sign [FILE] with your private key. gpg --verify [FILE].gpg to verify that the file was signed by one of public keys on your keyring. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b8/#encryption-and-decryption",
    "relUrl": "/labs/b8/#encryption-and-decryption"
  },"226": {
    "doc": "Lab 8 - Security Fundamentals",
    "title": "Hashing (Checksums)",
    "content": "Hash functions deterministically map arbitrary-length data to a fixed-length string of bits (AKA a hash). As a result, the latter can serve as a summary of the former if the former exceeds the latter in terms of byte length. For instance, if we download a 1GB file and want to verify its integrity, instead of re-downloading the entire file again, we can simply compute a 256-bit hash of the file on our end and compare it to the 256-bit hash of source, which is known as a checksum. To try it out: . | sha1sum [FILE] to get the SHA1 hash of [FILE]. | md5sum [FILE] to get the MD5 hash of [FILE]. | . There are many hash functions, only some of which satisfy the requirements of cryptographic hash functions. Crytographic hash functions primarily differ from their non-cryptographic counterparts in that they provide a property that make it computationally infeasible to forge a pre-hash file that maps to the same hash. If you are interested in all of the properties of a cryptographic hash function, read here. In particular, SHA1 and MD5 have been proven to no longer be cryptographically secure and are only used for checksums to ensure data integrity. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b8/#hashing-checksums",
    "relUrl": "/labs/b8/#hashing-checksums"
  },"227": {
    "doc": "Lab 8 - Security Fundamentals",
    "title": "File Security",
    "content": "The UNIX permission model has 3 components: permissions given to the file’s (1) owning user, (2) owning group and (3) others/everyone else. Permissions themselves have 3 subcomponents: (1) read, (2) write and (3) execute, enforcing the ability to read, write or execute a file. To try it out: . | ls -l shows all the permissions of the current directory’s files in the leftmost column. | chown [-R] [NEWUSER]:[NEWGROUP] [FILE] to change [FILE]’s user and group ownerships respectively to [NEWUSER] and [NEWGROUP]. | chmod [-R] [PERMISSIONS] [FILE] to set [FILE] with specified [PERMISSIONS]. | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b8/#file-security",
    "relUrl": "/labs/b8/#file-security"
  },"228": {
    "doc": "Lab 8 - Security Fundamentals",
    "title": "Lab Checkoff",
    "content": "Submission . Submit answers to each question on Gradescope. Setup . You should complete this lab on your student VM (username@username.decal.xcf.sh). Once you’re connected to your VM, you’ll need to clone the decal-labs repository: . git clone https://github.com/0xcf/decal-labs.git . If you’ve already cloned decal-labs before, run git pull in your decal-labs directory to make sure all of your files are up to date. Encryption and Decryption . | Decrypt b8/file1.txt.gpg with the password ocfdecal (for real-life purposes, never store passwords in plaintext). What are the decrypted contents of b8/file1.txt.gpg? | What command allows you to import a key? | What command allows you to export a key to a file? (Add the --armor flag to ASCII-encode the key so it can be sent easily in text form) | What command allows you to see all of the keys on your keyring? | Use the private key b8/lab8privkey to decrypt the file b8/file2.txt.gpg (for real-life purposes, it is necessary to keep private keys secret). What are the decrypted contents of b8/file2.txt.gpg? | . Hashing (Checksums) . | What is the MD5 hash of b8/file3.txt? | What is the SHA1 hash of the MD5 hash of b8/file3.txt? In other words, what is SHA1(MD5(file3.txt))? | . File Security . Run sudo setup.sh from decal-labs/b8/ before beginning this section. | b8/file4.txt: What are the permissions of this file? Explain what they allow and disallow. | b8/file5: Make this file executable and execute it. What is its printout? | b8/file6.txt: Change this file to be under your ownership. What command did you use? | b8/file7.txt: Make this file readable only to you. What command did you use? | b8/file8.txt: Change this file’s permissions such that only root should be able to read this file and no one should be able to edit it. What command did you use? | b8/file9.txt: Choose any method to make this file readable to you and unreadable to the previous owner. What command did you use? | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b8/#lab-checkoff",
    "relUrl": "/labs/b8/#lab-checkoff"
  },"229": {
    "doc": "Lab 8 - Security Fundamentals",
    "title": "Lab 8 - Security Fundamentals",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b8/",
    "relUrl": "/labs/b8/"
  },"230": {
    "doc": "Lab 9 - Version Control and Backups",
    "title": "Git IRL",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b9/#git-irl",
    "relUrl": "/labs/b9/#git-irl"
  },"231": {
    "doc": "Lab 9 - Version Control and Backups",
    "title": "Table of contents",
    "content": ". | Git IRL . | Pulling the code | Part 1: Git Basics . | rand.py demo | Creating a new branch | Making commits | Viewing your progress | Merge conflicts and rebase | (OPTIONAL) Combining commits | . | Part 2: Pull Requests | Part 3: Questions | . | . In this lab, we’ll be learning how to use Git and typical best practices for version control! . Pulling the code . If you haven’t already cloned the decal-lab git repository, run: git clone https://github.com/0xcf/decal-labs.git . Go to your decal-labs directory and cd into the folder b9. Run git pull to pull the latest changes. Part 1: Git Basics . In the b9 directory, we’ve provided a basic Python program called rand.py to help demonstrate some core Git concepts. rand.py takes command line arguments and performs a number of coin flips and outputs the result in your terminal. We want to add a feature to rand.py that also lets us perform dice rolls. We will simulate the real-world development process by making a branch for our new dice rolling feature, making a few commits to that branch, and then merging our feature branch into the master branch. You won’t need to personally write any Python for this lab! You will only need to copy-and-paste the code we provide, since this lab is about learning version control and not Python. rand.py demo . Run python3 rand.py -h in your terminal to see the help dialogue for the program. At the moment, it takes one positional argument of either coin or dice as well as an optional flag -i (or --iterations) if you want to flip/roll more than once. The dice argument doesn’t work as we haven’t implemented it yet, but you can try flipping a coin: . exiang@supernova:~/decal-labs/b9$ python3 rand.py coin 1 coin flip(s) resulted in 0 Heads and 1 Tails: T exiang@supernova:~/decal-labs/b9$ python3 rand.py coin -i 10 10 coin flip(s) resulted in 3 Heads and 7 Tails: T, T, H, T, H, H, T, T, T, T exiang@supernova:~/decal-labs/b9$ python3 rand.py coin -i 999 Number of flips must be in the range [0 - 100] . Creating a new branch . Let’s start working on the dice rolling feature! When working on a project with version control, it’s best practice to keep the master branch clean (read: mostly bug-free and stable). | Any branches you make will be based on/descended from code in the master branch. You don’t want to write new code on top of a foundation that’s broken or buggy! . | Some organizations may directly deploy the master branch to a production environment (live for your users and clients), so new and work-in-progress features should be developed in their respective branches and finished before merging them into master. | . Let’s make a branch for our dice rolling feature: . git checkout -b dice . This makes a new local branch called dice based on the branch that we are currently on (master) and switches you to the dice branch. This command is basically shorthand for: . git branch dice // Create new branch called 'dice' git checkout dice // Switch to branch called 'dice' . You can view the branches you’ve created by typing git branch. You should see two branches at this point, one called master and one called dice. An asterisk is placed next to the branch that you’ve currently checked out. You can make git branch (and many other command-line tools) display more information by passing the verbose flag -v, or make it display even more information by adding additional v characters to the flag (e.g. -vv). git branch -v will display the commit message of the most recent commit on the branch (aka the HEAD). git branch -vv also displays in square brackets the remote branch that the local branch is tracking, if one exists. In this repository, master is associated with a remote branch origin/master that lives on Github’s servers. This means when you git push or pull to/from origin master, you are syncing up your local copy of the master branch with the remote master branch on Github’s servers. At the moment, your newly created dice branch is local only, meaning that attempting to git push or pull will not work (or Git may ask you if you want to have a remote branch created). Making commits . Now that you’re on your dice branch, you can safely start adding code without modifying the master branch. The code for dice rolling will be split up into three commits so that we can demonstrate how to combine multiple commits into a single commit later. Open rand.py in your preferred text editor. Find the comment in the __main__ function that says COMMIT 1 and add the following code below it like so: . # COMMIT 1: Add -s flag for number of sides on a die parser.add_argument( \"-s\", \"--sides\", dest=\"sides\", type=int, default=6, help=\"Number of sides on a die (max=20; ignored when flipping a coin)\" ) . If you’re unsure about copying the code correctly, take a look at rand_reference.py for what the finished code should look like! . Save and exit the text editor and return to the terminal. Type git status to see that rand.py has been changed but not staged. Type git add rand.py to stage the file. To “stage” a file means to add it to the group of files that you want to include in your commit. You may already know git add . to add every changed file in your current directory to the staging area, but in some cases you want to only add relevant files if you hopped around implementing different things. A commit should be a group of changes focused on a single small goal, sub-feature, or bug fix. In the event that you need to roll back a commit, you don’t want to cause collateral damage by undoing changes in an unrelated file that you lumped into the commit. Now, lets commit our changes and write a concise and useful commit message. Type git commit -m \"Add -s flag for number of sides on a die\". Organizations and companies will have different best practices for writing commit messages, but here are some common guidelines: . | Keep it short. Typical commits should be one line (some exceptions). If a lot of changes have been made, you might want to make multiple commits instead. | Make it descriptive. If someone needs to read the commit history, they’re not going to know or remember what was changed by a commit that just says “Fixed bug” or “WIP”. | A lot of places like to capitalize the first letter and use the “&lt;present tense verb&gt; &lt;descriptive thing&gt;” sentence structure. For example, “Add”, “Fix”, or “Remove” some thing. You can think of your commit message as completing the sentence “This commit will…”. For example, “This commit will add -s flag for number of sides on a die”. | . Next, we will follow the same procedure to make commits 2 and 3. Find the comment in the function roll_dice that says COMMIT 2 and add the following code. Make sure that it’s indented properly inside the function! Then stage your changes and make a commit with the message \"Add dice rolling logic and output dice sum and sequence\". # COMMIT 2: Add dice rolling logic and output dice sum and sequence diceRecord, diceSum = [], 0 for i in range(iterations): roll = random.randint(1, sides) diceRecord.append(roll) diceSum += roll print(\"{} roll(s) of a {}-sided die resulted in a sum of {}:\" .format(iterations, sides, diceSum)) print(*diceRecord, sep=', ') . Find the comment in the function roll_dice that says COMMIT 3 and add the following code. Then stage your changes and make a commit with the message \"Restrict input range for dice iterations and sides\". # COMMIT 3: Restrict input range for dice iterations and sides if iterations &gt; MAX_ITERATIONS or iterations &lt; 0: print(\"Number of rolls must be in the range [0 - {}]\" .format(MAX_ITERATIONS)) return if sides &gt; MAX_SIDES or sides &lt; 1: print(\"Number of sides must be in the range [1 - {}]\" .format(MAX_SIDES)) return . When you’re done, you should now be able to roll dice: . exiang@supernova:~/decal-labs/b9$ python3 rand.py dice -i 10 -s 20 10 roll(s) of a 20-sided die resulted in a sum of 119: 15, 3, 12, 10, 16, 8, 18, 20, 13, 4 . Viewing your progress . Let’s take a look at the commits you’ve made. Type git log to see a history of commits. Each commit has some information such as who authored the commit, a timestamp for when the commit was created, and the commit message. | The first line of each commit entry has a long hexadecimal string. This is the commit hash: think of it as a unique ID that you can use to reference that specific commit. | Some commits have branch information in parentheses next to the commit hash, indicating that they are the most recent commit or HEAD of that branch. Your most recent commit should have something like (HEAD -&gt; dice). The fourth commit should have (origin/master, origin/HEAD) because we based our branch off of master and have added three new commits on top of it. Note that if someone adds new commits to the local or remote master, the branch information may change or be out of date. | . Type q to exit git log. Besides looking at the commit history, you may want to view the actual changes in the code. You can use git diff &lt;old commit&gt; &lt;new commit&gt; to view the difference between two commits. There are a few different ways you can reference a commit. One that was mentioned before was copying a commit’s hash (note that your commit hashes will be different from the example below): . git diff 3368313c0afb6e306133d604ca72b0287124e8f2 762053064506810dee895219e5b2c2747a202829 . You can also copy a small chunk of the beginning of the commit hash instead of the entire hash. Because of the way hashes work, it’s very unlikely that you’ll have two commits that have the exact same starting sequence. git diff 3368313 7620530 . If you’re trying to diff two commits that are pretty close together in the log, an easier way is to reference commits by their distance from the HEAD (most recent) commmit using the format HEAD~&lt;number&gt;. Since we added three commits new commits in dice, we can view the difference between dice and master using the following command: . git diff HEAD~3 HEAD . Merge conflicts and rebase . Now that you’ve implemented dice rolling on on your feature branch, you’ll want to merge your feature into the master branch. This means that Git will take your changes on the dice branch and and replay them on the master branch, bringing master up to date with dice. However, things can go wrong when master has new commits added to it while you’re working on dice. Now, our commits on dice may be based on an old version of master. Even worse, someone else may have modified the same lines of code on master that we changed on dice, resulting in Git not knowing whose lines to use. This is called a merge conflict. Let’s simulate a merge conflict by making a change on master. Switch to the master branch using git checkout master. Make sure that you’re on the master branch by checking the output of git branch. Now that you’re on the master branch, rand.py shouldn’t contain the code for the new dice feature we added. Go to the comment that says COMMIT 2 and add the following code below: . # COMMIT 2: Add dice rolling logic and output dice sum and sequence diceSum = random.randint(1, iterations * 6) print(\"{} roll(s) of a {}-sided die resulted in a sum of {}:\" .format(iterations, sides, diceSum)) . Now stage the changes and commit with the message \"dice rolling WIP\". In this totally realistic scenario, our imaginary maverick teammate has added some buggy code to master, making your life harder. Switch back to your dice branch with git checkout dice and prepare to handle this merge conflict. There are a multiple ways to handle a merge conflict, but the one we will be showing you in this lab is using git rebase. Our dice branch is “based” on the master branch at a certain point in time, but the master branch has moved forward leaving dice based on an outdated master. Thus, we want to “re-base” dice on the current state of master. While on your dice branch, run git rebase master. Git will rewind the commits you’ve made on dice, copy any new commits made on master, and attempt to replay your commits on top. Sometimes rebase will run to completion without your intervention, but if there’s a merge conflict you will need to resolve it. Git will give you instructions on what to do if it encounters a merge conflict during a rebase. In this case, open rand.py and find the conflicted zone which should have the following format: . &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Lines of code from the base branch (in this case master) ======= Lines of code from the branch you're rebasing (in this case dice) &gt;&gt;&gt;&gt;&gt;&gt;&gt; Commit message of the commit that conflicts with the base branch . To fix the conflict, simply keep the lines you want (your lines from dice) and delete the other lines in the conflicted zone (&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt; dice, and the unwanted code from master), and then save and exit the file. Git will take what you’ve saved as the exact form of what the file will look like at the end of the rebase, so what you’re doing is essentially fixing the file so that the code runs properly. This means that if you have multiple merge conflicts and you decide to mix keeping some lines from the base branch and some from your feature branch, you need to make sure the code actually works correctly. Now that you’ve fixed the merge conflict, follow the rebase instructions and stage your fixed file (git add rand.py), then run git rebase --continue. If Git finds any more merge conflicts for other files, you would follow the same procedure as above. However, we only had one conflicted file so our rebase is finished! Run git log to see the result of our rebase. You should now see that your imaginary teammate’s \"dice rolling WIP\" commit in your branch’s history, with your commits on top of theirs. Wait! We haven’t actually merged our commits into the master branch. If you want to do the optional step of combining your commits into a single commit before merging, go to the next section. You can also merge now and do the optional step later; you won’t see the combined commit on master but you will still learn the concepts. Otherwise, switch to the master branch using git checkout master and run git merge dice to integrate your changes from dice into master. Now you’re done! Don’t forget to complete the quick Gradescope check below. Because we ran rebased our branch before merging, we didn’t get any merge conflicts when running git merge dice. You can simply git merge dice without rebasing first, but Git will prompt you to resolve the exact same merge conflicts before it allows a merge so you aren’t saving yourself any work. We decided to show git rebase because it’s a good habit to regularly sync your branch with its base branch. Run git rebase every so often if you suspect there are new changes on master so that any merge conflicts are small and incremental. If you work with a large team and toil away on your feature branch for several days without rebasing, you may find that when its time to merge, your teammates have already updated master many times giving you a large backlog of merge conflicts and an even larger headache. Gradescope: . | On your master branch, type git log and paste a portion of your commit history showing the commit(s) you merged in from your dice branch plus a few commits into the past for context. If you haven’t completed the optional “Combining commists” section, 5-6 of the most recent commits should be sufficient. If you have completed the optional section and squashed your commits, 3-4 of the most recent commits should be sufficient. | On the master branch, use git diff to show the difference between what rand.py looks like now versus what it looked like at the start of the lab. There are multiple ways to use git diff to do this, so pick any one you like. In Gradescope, paste both the git diff command you used and the output of the command. | . (OPTIONAL) Combining commits . Git has the ability to combine multiple commits into a single commit. This process is called squashing. You may want to do this if you have work in progress commits that you want to combine into a single finished commit, or in our case, keeping git log for the master branch more digestable. | Pros: If you have a feature branch with fifty commits, you prevent inundating master’s history with fifty different commits when merging. When you squash, you can make a multi-line commit message where the first line is a summary of the feature, and subsequent lines are bullet points containing relevant individual commit messages from the individaul commits. | Cons: You lose the granularity of the history on master, making it more difficult if you want to partially roll back your feature. Git also doesn’t support having multiple authors for a single commit, so if you want to credit other contributors you need to add co-author credit somewhere in the commit message of your combined commit. | . First, make sure you’re on your dice branch using git checkout dice. We will be performing our squash using the command git rebase in interactive mode by passing the -i flag. This may seem a bit unusual that we can run rebase without a base branch, but rebase can not only sync branches, but also rewrite the history of our current branch. The format for the command of an interactive rebase is git rebase -i HEAD~# where # is the parent commit of the commit where we want to start our rebase. This will seem a bit unintuitive if you’ve followed how the HEAD~# pointer works: to work on our last three commits (HEAD, HEAD~1, and HEAD~2), we need to actually run git rebase -i HEAD~3. An easier way to remember this is if you want to rebase the last N commits, run git rebase -i HEAD~N. However, we may not always remember how many commits we made so its okay to give yourself a little more room/context by using a larger number. Let’s run git rebase -i HEAD~5. This will bring up a text editor with a file that we can modify to change the history of commits from HEAD~4 to HEAD. You’ll notice that the commits are in reverse order, starting with the oldest commit at the top and newest commit at the bottom. This is because git will use this text file as part of a script to replay those commits (with your rewritten changes) in chronological order. Your file will have different commit hashes and likely a different commit message on the first line than the example below: . pick 9f785bc Remove trailing whitespace pick 1f7a1e1 dice rolling WIP pick 26e0827 Add -s flag for number of sides on a die pick b193d44 Add dice rolling logic and output dice sum and sequence pick 554402e Restrict input range for dice iterations and sides # Rebase 7dac858..554402e onto b193d44 (5 commands) # ... As you can see, Git includes useful instructions on what you can do with commits in interactive mode in the commented-out section at the bottom of the file. We can combine, delete, reword, or even reorder our commits, along with many more options. In our case, we want to squash our two most recent commits into the third most recent commit in the list. To do this, replace the word pick with the word squash (or just s for short) on the last two lines. Do not squash the third line; that will take your three most recent commmits and meld them with the “dice rolling WIP” commit, which is a commit from master. Your file should look something like this: . pick 9f785bc Remove trailing whitespace pick 1f7a1e1 dice rolling WIP pick 26e0827 Add -s flag for number of sides on a die squash b193d44 Add dice rolling logic and output dice sum and sequence squash 554402e Restrict input range for dice iterations and sides # Rebase 7dac858..554402e onto b193d44 (5 commands) # ... Save and exit the file. Git will now rewrite the commit history as you specified. If you squash commits or do another action that may modify commit messages, Git will bring up another text editor for you to modify the commit message. Because you squashed, Git made a multi-line commit message by combining the three individual commit messages from before you squashed. Let’s add a useful one-line summary, “Add dice roll feature”, at the top of the file. You can also adjust the formatting to your liking; I like adding bullet points to the individual commit messages. Add dice roll feature # This is a combination of 3 commits. # This is the 1st commit message: - Add -s flag for number of sides on a die # This is the commit message #2: - Add dice rolling logic and output dice sum and sequence # This is the commit message #3: - Restrict input range for dice iterations and sides . Git and other tools use the first line of a commit message as a shortened version for certain display purposes. For example, try running git log --oneline. As another example, when Github displays the most recent commit message next to files and folders in the directory view, the first line of the message is shown. Save the file and exit. The rebase is now complete! Type git log and view your new squashed commit. If you didn’t already merge your three individual commits into master, you can run git merge master to merge in your combined commit. commit c0fa61ad59a76635701813472bfbc1c7f36bb857 (HEAD -&gt; dice) Author: Edric Xiang &lt;email redacted&gt; Date: Wed Aug 12 19:00:29 2020 -0700 Add dice roll feature - Add -s flag for number of sides on a die - Add dice rolling logic and output dice sum and sequence - Restrict input range for dice iterations and sides . Gradescope: There’s no separate Gradescope check for this optional section, but make sure you go back and complete the Gradescope check above in the previous section if you’ve chosen to do this part first! . Part 2: Pull Requests . One of the most common ways to contribute changes to a repository on Github (and other similar Git remote hosting services) is through a pull request (often shortened to “PR”). A pull request is basically a proposal to make changes to a repository that can be reviewed by others, commented on, and edited before the changes are actually approved to be merged into the repository. For example, when working on a large project with a team, you may want to submit a pull request with your new feature so that team members can review your code for bugs or code style mistakes. For projects on public repostitories that invite contributions from strangers, you can contribute a feature by forking the repository (making a copy of it that you own), implementing your feature, and then making a pull request to have your contribution merged into the official repository. First, read up on how to create a pull request from Github’s documentation. We’ve created a dummy repository at https://github.com/0xcf/decal-pr-practice for you to practice making a simple PR from a fork. You will be making a fork of the repo, writing your name in the Markdown file in the repo, and then making a PR to merge your change into the original repo. | Read about how to fork a repo from Github’s documentation. Make a fork of our dummy repository at https://github.com/0xcf/decal-pr-practice. | Clone your forked repository and create a new branch based on master called my-name. Open README.md and replace “Tux the Penguin” with your name. | Stage and commit your change with the commit message Add my name, and then git push. | Read about how to make a PR from a fork from Github’s documentation. Make a PR from your branch my-name on your forked repo &lt;Your Github username&gt;/decal-pr-practice to the branch master on the original repo 0xcf/decal-pr-practice. | . You’ve now made a pull request! Github has a lot of features for pull requests, feel free to check some of them out. This lab you’re reading right now was merged through a PR, which you can view at https://github.com/0xcf/decal-web/pull/216. | The main page for the pull request has a timeline of commits and any comments from reviewers. PRs can be continually updated by making and pushing new commits to your compare branch. Github will track any new changes pushed to the compare branch and update your PR. As you can see, I didn’t follow my own advice and messed up a rebase after trying to sync my fork, leaving duplicate commits in my commit history… . | The sidebar on the main page has several notable features. You can request other people to review your changes, assign others to work on the PR, and link an issue that your PR will resolve if it gets merged. Github repositories have an “Issues” tab where one can submit a report about a bug or request a feature (e.g. https://github.com/0xcf/decal-web/issues). The Github issue associated with the PR for this lab is at https://github.com/0xcf/decal-web/issues/184. | Go to the “Files Changed” tab to see a diff of the PR’s changes. Reviewers of your PR can leave inline comments on a specific line of code by hovering over the line and clicking the blue “+” button that pops up. | . Gradescope: Paste a link to the pull request you made so that it can be checked off for completion. Part 3: Questions . | What caused the merge conflict in the Git exercises you did? . | Why does Git require us to manually intervene in merge conflicts? . | What command would you use to sync a folder ~/Downloads/Linux_ISOs to the folder /usr/local/share/Calendar, while preserving file metadata? (hint: use rsync) . | How does rsync determine when to look for changes between files? Select from the following: . A. By calculating the checksum of each file and comparing them. B. By comparing the entire contents of each file for any differences. C. By seeing if the ‘last modified’ timestamp of the files are different. D. By seeing if the ‘created’ timestamp of the files are different. E. By seeing if the permissions of the files are different. | Consider a file str1 containing the string ‘abcd’. You rsync it to another file str2, and then replace ‘abcd’ with ‘aaaa’ on str1. If you run ‘rsync –append str1 str2’, what will the contents of str2 be? . | . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b9/#table-of-contents",
    "relUrl": "/labs/b9/#table-of-contents"
  },"232": {
    "doc": "Lab 9 - Version Control and Backups",
    "title": "Lab 9 - Version Control and Backups",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/labs/b9/",
    "relUrl": "/labs/b9/"
  },"233": {
    "doc": "Home",
    "title": "Linux System Administration Decal",
    "content": "A course covering the basics of setting up and administering a production-quality Linux server environment. ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#linux-system-administration-decal",
    "relUrl": "/#linux-system-administration-decal"
  },"234": {
    "doc": "Home",
    "title": "Week 12 Announcements",
    "content": "May 1 &middot; 1 min read . | Last Thursday’s guest lecture is now available on YouTube. | Regularly scheduled DeCal material has now concluded! Thank you for flying OCF, and we hope you enjoyed the course :D | Bonus lab 11 has been released and will be due on 5/9! Lab 11 is optional and may be used to replace an incomplete and/or late lab. Note that lab 0 does not count towards the required 10 labs. | End-of-semester notices: Unless you have requested a lab drop, please remember that 10 labs must be completed before the end-of-semester deadline of Sunday, 05/09. The optional 11th lab will be released next week and will be due on 5/9, for those who were not able to complete a regularly scheduled lab. | (For registered students) If you feel that you’ll need more time to complete labs, or have more than 2 late labs, fill out this form. | There will be no live lab this week. If you’d like support of any kind, or would like to chat with other students, #decal-general is always open! | . Announcements . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/",
    "relUrl": "/"
  },"235": {
    "doc": "Home",
    "title": "Weekly Schedule",
    "content": ". | 7:30 PM | 8:00 PM | 8:30 PM | 9:00 PM | 9:30 PM | 10:00 PM | . | ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#weekly-schedule",
    "relUrl": "/#weekly-schedule"
  },"236": {
    "doc": "Home",
    "title": "Monday",
    "content": "| ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/",
    "relUrl": "/"
  },"237": {
    "doc": "Home",
    "title": "Tuesday",
    "content": ". | Beginner Lab 8:00 PM–9:00 PM ocf.io/decalzoom | . | ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/",
    "relUrl": "/"
  },"238": {
    "doc": "Home",
    "title": "Wednesday",
    "content": "| ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/",
    "relUrl": "/"
  },"239": {
    "doc": "Home",
    "title": "Thursday",
    "content": ". | Advanced Lab 8:00 PM–9:00 PM ocf.io/decalzoom | . | ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/",
    "relUrl": "/"
  },"240": {
    "doc": "Home",
    "title": "Friday",
    "content": "| . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/",
    "relUrl": "/"
  },"241": {
    "doc": "Home",
    "title": "Calendar",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#calendar",
    "relUrl": "/#calendar"
  },"242": {
    "doc": "Home",
    "title": "Week 0: 1/25/2021",
    "content": "Infosession Infosessionocf.io/decalzoom Slides LabLab 0 Lab due Sat. 1/30 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-0-1252021",
    "relUrl": "/#week-0-1252021"
  },"243": {
    "doc": "Home",
    "title": "Week 1: 2/8/2021",
    "content": "Beginner Track LectureHistory of UNIX, intro to shell, FOSS Slides LabLab b1 (Solution) Lab due Sat. 2/13 Advanced Track LectureAdvanced Introduction to UNIX Slides LabLab a1 (Solution) Lab due Sat. 2/13 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-1-282021",
    "relUrl": "/#week-1-282021"
  },"244": {
    "doc": "Home",
    "title": "Week 2: 2/15/2021",
    "content": "Beginner Track LectureCore Shell Slides LabLab b2 (Solution) Lab due Sat. 2/20 Advanced Track LecturePackages Slides LabLab a2 (Solution) Lab due Sat. 2/20 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-2-2152021",
    "relUrl": "/#week-2-2152021"
  },"245": {
    "doc": "Home",
    "title": "Week 3: 2/22/2021",
    "content": "Beginner Track LectureShell Scripting Slides LabLab b3 (Solution) Lab due Sat. 2/27 Advanced Track LectureDIY Linux Pre-Install Slides LabLab a3 (Solution) Lab due Sat. 2/27 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-3-2222021",
    "relUrl": "/#week-3-2222021"
  },"246": {
    "doc": "Home",
    "title": "Week 4: 3/1/2021",
    "content": "Beginner Track LectureCompiling, Distros, and Packaging Slides LabLab b4 (Solution) Lab due Sat. 3/6 Advanced Track LectureLinux Post-Install Slides LabLab a4 (Solution) Lab due Sat. 3/6 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-4-312021",
    "relUrl": "/#week-4-312021"
  },"247": {
    "doc": "Home",
    "title": "Week 5: 3/8/2021",
    "content": "Beginner Track LectureNetworking 101 Slides LabLab b5 (Solution) Lab due Sat. 3/13 Advanced Track LectureProcesses and Services Slides LabLab a5 (Solution) Lab due Sat. 3/13 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-5-382021",
    "relUrl": "/#week-5-382021"
  },"248": {
    "doc": "Home",
    "title": "Week 6: 3/15/2021",
    "content": "Beginner Track LectureProcesses Slides LabLab b6 (Solution) Lab due Mon. 3/29 Advanced Track LectureNetworking 102 Slides LabLab a6 (Solution) Lab due Mon. 3/29 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-6-3152021",
    "relUrl": "/#week-6-3152021"
  },"249": {
    "doc": "Home",
    "title": "Week 7: 3/29/2021",
    "content": "Beginner Track LectureServices Slides LabLab b7 (Solution) Lab due Sat. 4/3 Advanced Track LectureNetworked Services Slides LabLab a7 (Solution) Lab due Sat. 4/3 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-7-3292021",
    "relUrl": "/#week-7-3292021"
  },"250": {
    "doc": "Home",
    "title": "Week 8: 4/5/2021",
    "content": "Beginner Track LectureSecurity Fundamentals Slides LabLab b8 (Solution) Lab due Sat. 4/10 Advanced Track LectureConfig Management Slides LabLab a8 (Solution) Lab due Sat. 4/10 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-8-452021",
    "relUrl": "/#week-8-452021"
  },"251": {
    "doc": "Home",
    "title": "Week 9: 4/12/2021",
    "content": "Beginner Track LectureVersion Control and Backups Slides LabLab b9 Lab due Sat. 4/17 Advanced Track LectureAdvanced Security Slides LabLab a9 Lab due Sat. 4/17 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-9-4122021",
    "relUrl": "/#week-9-4122021"
  },"252": {
    "doc": "Home",
    "title": "Week 10: 4/19/2021",
    "content": "Beginner Track LectureCloud, Containers, and Config Management Slides LabLab b10 Lab due Sat. 4/24 Advanced Track LectureVirtualization, Containers, Distributed Architecture Slides LabLab a10 Lab due Sat. 4/24 ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-10-4192021",
    "relUrl": "/#week-10-4192021"
  },"253": {
    "doc": "Home",
    "title": "Week 11",
    "content": "Extra Lab! (Optional) Lab Lab 11 Lab due Sun. 5/9 Special Guest Lecture Lecture Careers in Systems Administration (Slides) Thursday, 4/29 at 8:10pm, ocf.io/decalzoom ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/#week-11",
    "relUrl": "/#week-11"
  },"254": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/",
    "relUrl": "/"
  },"255": {
    "doc": "Staff",
    "title": "Staff",
    "content": " ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/staff/",
    "relUrl": "/staff/"
  },"256": {
    "doc": "Staff",
    "title": "Head Facilitators",
    "content": "Ben Cuan . contact@bencuan.me . Super Awesome Content . Xu Huang . xuhuang@berkeley.edu . Too young, too simple, sometimes naive. Kevin Mo . kmo@ocf.berkeley.edu . join the kmoverse, or else the kmoverse joins you . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/staff/#head-facilitators",
    "relUrl": "/staff/#head-facilitators"
  },"257": {
    "doc": "Staff",
    "title": "Facilitators",
    "content": "Ethan Smith . ethanhs@berkeley.edu . doer of things . Tony Lian . longlian@berkeley.edu . Tony is me. I am Tony. Will Minnis . aesthetic@berkeley.edu . Out here living our best lives &lt;3 . Samuel Berkun . sberkun@berkeley.edu . I like cheese . Vacuum Cleaner . me@example.com . Schedule an appointment . ",
    "url": "https://decal.ocf.berkeley.edu/archives/2021-spring/staff/#facilitators",
    "relUrl": "/staff/#facilitators"
  }
}
